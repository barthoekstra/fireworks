# (PART) Fireworks disturbance {-}

# Modelling fireworks disturbance

We have so far:

1. Pre-processed the radar data by removing clutter and applying the range-bias correction [@kranstauber2020].
2. Annotated the PPIs with land use proportions and indicators of disturbance, i.e. distance to inhabited urban areas and (human) population density.
3. Annotated the PPIs with the total biomass calculated from the Sovon counts.

With the dataset of annotated PPIs, we can start to explore the relation between fireworks disturbance and the birds measured aloft during NYE 2017-2018.

The following parameters we assume are important predictors for measured bird densities aloft:

1. The total radar cross-section of birds on the ground.
2. The take-off habitat of these birds.
3. The human population in the vicinity of birds.
4. The distance to the nearest inhabited urban area.

## Processing environment

```{r setup_modelling_environment, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(readr)
library(tidyr)
library(parallel)
library(ggridges)
library(pgirmess)
library(mboost)
library(leaflet)
library(leaflet.opacity)
library(leafem)
library(usdm)
library(mapview)
library(spdep)
library(stringr)
```

In the previous chapter, we have created some datasets encompassing all the data contained within the individual PPIs at different resolutions. We will determine the optimal resolution and then continue using this dataset for further modelling.

```{r load_data}
selected_scan <- load("data/processed/pvol_selection.RData")
scan_dt <- str_extract(basename(pvol_dhl_path), "[0-9]{12}")
resolutions <- file.path("data/processed/composite-ppis", c("500m", "1000m", "2000m"), paste0(scan_dt, ".RDS"))
data <- lapply(resolutions, function(x) readRDS(x)[["data"]]@data)
names(data) <- c("500m", "1000m", "2000m")
```

## Preparing a dataset for modelling

As we're mostly interested in the moment of en masse take-off of birds, and we want to limit the effects of dispersal, we will limit our analysis to the first 5 minutes after 00:05 on January 1st, 2018 (or 23:05 on December 31st, 2017 in UTC), as both radar sites (Den Helder and Herwijnen) show a low `VIR` prior to and a rapid increase in `VIR` for that period (see [Identifying moment of take-off]). Making sure birds are thus still sufficiently 'linked' to the take-off sites requires that we limit our analysis to only this one scan.

Furthermore, we want to make sure that:

1. the area is 'covered' by at least 1 radar,
1. we have an estimate of `total_rcs` (and thus `total_biomass`) for these sites,
1. the proportion of urban area (`urban`) in the PPI pixel is less than .1,
1. `VIR` is > 0 (otherwise log-conversion will return `-Inf`), so we replace 0-values with 1e-3,
1. the radar beam does not overshoot birds too much based on the `vp`.

```{r prepare_modelling_dataset}
clean_data <- function(data, max_distance) {
  mdl_variables <- c("VIR", "dist_radar", "total_biomass", "total_crs",
                     "agricultural", "semiopen", "forests", "wetlands", "waterbodies", "urban",
                     "dist_urban", "human_pop", "disturb_pot", "pixel", "coverage", "class", "x", "y")
  log10_variables <- c("dist_urban", "human_pop", "total_biomass", "dist_urban", "disturb_pot")
  
  data %>%
    dplyr::filter(coverage > 0,
                  class != 1,
                  total_biomass > 0,
                  dist_radar < max_distance,
                  urban < 0.1) %>%
    mutate(VIR = replace_na(VIR, 0.1),
           VIR = if_else(VIR == 0, 0.1, VIR),
           VIR = log10(VIR),
           disturb_pot = human_pop / dist_urban,
           total_biomass = total_biomass / 1000) %>%
    dplyr::select(all_of(mdl_variables)) %>%
    filter_all(all_vars(is.finite(.))) %>%
    rename(total_rcs = total_crs) %>%
    identity() -> data_cleaned
  
  data_cleaned
}

data_cleaned <- lapply(data, function(x) clean_data(x, 66000))
rm(data)
```

## Determine model resolution based on performance in simple `total_crs` model

As we want to account for the influence of `total_rcs` on the measured response by the radars, we will test the performance of a simple model using just `dist_radar` to correct for range-biased measurement error and `total_rcs` for the resolutions we have generated composte PPIs for so far (500m, 1000m and 2000m).

Let's start with a calculation of the RMSE.

```{r create_resolution_models, eval=full_repro}
resolution_models <- lapply(data_cleaned, function(x) mboost(VIR ~ bbs(dist_radar) + bbs(total_rcs), 
                                                             data = x, control = boost_control(mstop = 10000, trace = TRUE)))
saveRDS(resolution_models, file = "data/models/resolution_models.RDS")
```
```{r determine_model_resolution}
resolution_models <- readRDS("data/models/resolution_models.RDS")
RMSE <- function(error) { sqrt(mean(error^2)) }
sapply(resolution_models, function(x) RMSE(residuals(x)))
```

We can also use percentage of [deviance explained](https://doi.org/10.1016/S0304-3800(00)00354-9)

```{r resolution_model_deviance_explained}
deviance_explained <- function(observed, predicted) {
  p <- predicted
  o <- observed
  i <- rep(mean(observed), length(observed))  # Intercept
  total.deviance <- sum((o - i) * (o - i)) / length(observed)  # Deviance from an intercept-only model
  resid.deviance <- sum((o - p) * (o - p)) / length(observed)  # Deviance from the fitted model
  (total.deviance - resid.deviance) / total.deviance
}

mapply(function(data, model) { deviance_explained(data$VIR, predict(model))}, data = data_cleaned, model = resolution_models)
```

Turns out most models perform quite similarly. However, to make the link between birds and the habitat they take off from as strong as possible, it makes sense to continue just with the 500m model.

```{r set_final_resolution}
data_cleaned <- data_cleaned$`500m`
saveRDS(data_cleaned, file = "data/models/data_cleaned.RDS")
rm(resolution_models)
```

## Check for correlations among predictors

We have to see if variables are strongly correlated and thus unfit for being included in the same model, so we calculate Spearman correlation coefficients for all numerical predictors. As this is ecological data, some degree of correlation is of course inevitable for most variables.

```{r check_for_correlations, warning=FALSE, out.width='100%', message=FALSE}
mdl_variables <- c("VIR", "dist_radar", "datetime", "total_biomass", "total_rcs", "agricultural", "semiopen", "forests", "wetlands", "waterbodies",
                   "urban", "dist_urban", "human_pop", "disturb_pot", "pixel", "coverage", "class")
predictors <- mdl_variables[!mdl_variables %in% c("VIR", "datetime", "pixel", "x", "y", "coverage", "class")]
corr_radar <- ggstatsplot::ggcorrmat(data_cleaned, output = "plot", type = "spearman", cor.vars = all_of(predictors), colors = c("#2166AC", "#F7F7F7", "#B2182B"))
corr_radar
```

So obviously there is correlation between the disturbance proxies and between `agricultural` and other land use proportions. For the disturbance proxies it would make sense to determine which is most performant (including all does not make sense), but we can continue using the `agricultural` predictor as boosted models do not suffer from multicollinearity problems like traditional (e.g.) GAMs.

## Correlated land use proportions

While we're at it, let's see what the distributions of values are for the different land use proportions.

```{r show_correlated_land_use, message=FALSE}
data_cleaned %>%
  dplyr::select(agricultural, semiopen, forests, wetlands, waterbodies) %>%
  pivot_longer(cols = everything(), names_to = "landuse", values_to = "value") %>%
  ggplot(aes(x = value, y = landuse, fill = stat(x))) +
  geom_density_ridges_gradient(scale = 1, rel_min_height = 0.0) +
  scale_fill_viridis_c(name = "LU Prop.", option = "C") +
  labs(title = "Distribution of land use proportions in modelling dataset") +
  xlab("Land use proportion") +
  ylab("Land use class")
```

As can be expected in The Netherlands, the dominant land use class is clearly `agricultural` with the most prominent peak at full PPI  pixel coverage (values close to 1) and all other land use classes peaking very strongly at low proportions. This essentially means that when one of the other land use classes increases in proportion, this will almost always come at the cost of the proportion of `agricultural` and vice versa.

## Determine the most suitable proxy for disturbance

Now we will compare the disturbance proxies in a similar fashion to how we compared the performance of the model using different PPI resolutions, by calculating deviance explained and RMSE.

```{r compare_proxies_for_disturbance, eval=full_repro}
fm_dist_urban <- VIR ~ bbs(dist_radar) + bbs(total_rcs) + bbs(semiopen) + bbs(forests) + bbs(wetlands) + bbs(waterbodies) +
  bbs(agricultural) + bbs(dist_urban)
fm_human_pop <- VIR ~ bbs(dist_radar) + bbs(total_rcs) + bbs(semiopen) + bbs(forests) + bbs(wetlands) + bbs(waterbodies) + 
  bbs(agricultural) + bbs(human_pop)
fm_disturb_pot <- VIR ~ bbs(dist_radar) + bbs(total_rcs) + bbs(semiopen) + bbs(forests) + bbs(wetlands) + bbs(waterbodies) + 
  bbs(agricultural) + bbs(disturb_pot)
formulas <- list(fm_dist_urban, fm_human_pop, fm_disturb_pot)

disturbance_models <- lapply(formulas, function(formula) mboost(formula, data = data_cleaned, control = boost_control(mstop = 10000, trace = TRUE)))
names(disturbance_models) <- c("dist_urban", "human_pop", "disturb_pot")
saveRDS(disturbance_models, file = "data/models/disturbance_models.RDS")
```
```{r calculate_disturbance_model_performance}
disturbance_models <- readRDS("data/models/disturbance_models.RDS")
RMSE <- function(error) { sqrt(mean(error^2)) }
rmse <- sapply(disturbance_models, function(x) RMSE(residuals(x)))
d2 <- mapply(function(model) { deviance_explained(data_cleaned$VIR, predict(model))}, model = disturbance_models)
perf_original <- as.data.frame(list("RMSE" = as.matrix(rmse), "Dev.Exp" = as.matrix(d2)))
perf_original
```

It is clear `dist_urban` performs the best, though just by a slight margin. As it is probably the most interpretable proxy from a policy perspective, we can thus continue using it without any regrets.

```{r set_final_disturbance_proxy}
model <- disturbance_models$dist_urban
saveRDS(model, file = "data/models/model.RDS")
rm(disturbance_models)
```

## Determine the optimal number of boosting steps

The main hyperparameter to be tuned for the boosted GAMs using `mboost` is the number of boosting iterations/steps. By stopping boosting before model performance (measured using cross-validation) worsens, we can avoid overfitting. We limit this test of model performance for a maximum of 50,000 boosts.

```{r train_model_50000_boosts, eval=full_repro}
model_boosts <- mboost(fm_dist_urban, data = data_cleaned, control = boost_control(mstop = 1000, trace = FALSE))
saveRDS(model_boosts, file = "data/models/model_boosts.RDS")

grid <- c(1.68^(1:20), 50000)  # Generate a non-linear grid of mstop values to avoid slow convergence

cv10f <- mboost::cv(model.weights(model_boosts), type = "kfold")
saveRDS(cv10f, file = "data/models/boost_cv10f.RDS")

cvm <- cvrisk(model_boosts, folds = cv10f, grid = grid, papply = lapply)
saveRDS(cvm, file = "data/models/cvm_boosts.RDS")
```

```{r plot_boosting_steps, out.width='100%'}
cvm <- readRDS("data/models/cvm_boosts.RDS")
class(cvm) <- NULL
as.data.frame(cvm) %>%
  tibble::rownames_to_column(var = "fold") %>%
  pivot_longer(-c(fold), names_to = "boosts", values_to = "risk") %>%
  mutate(boosts = as.numeric(boosts),
         fold = as.factor(fold)) %>%
  identity() %>%
  ggplot(aes(x = boosts, y = risk, group = fold, color = fold)) +
    geom_line() +
    labs(title = paste0(attr(cvm, "type")), x = "boosts (mstop)", y = attr(cvm, "risk")) +
  scale_x_continuous(trans = "log10")
```

We can see that model performance improves very little beyond a few thousand boosting iterations. As we have to quantify model uncertainty using bootstrapping techniques, it makes little computational sense to push much beyond 10000 boosts, as that would just make the bootstrapping procedure last much longer.

## Variable importance

We can quantify the importance of variables within our model using the `varimp` function which returns variable importance, a measure of the total improvement to model deviance a variable is responsible for.

```{r variable importance}
plot(varimp(model))
```

## Model marginal effects

Let's quickly visualise marginal effects of this model, showing how individual variables influence model outcome with all other variables held constant.

```{r show_marginal_effects}
par(mfrow = c(2, 4))
plot(model)
```


```{r}
# data_cleaned %>% 
#   slice_sample(n = 1000) %>% 
#   ggplot(aes(x = dist_urban, y = VIR, size = semiopen), alpha = 0.5) +
#   geom_pointdensity() +
#   scale_color_viridis_c(trans = "log10")
# data_cleaned$pred <- predict(model, type = "response")
landuse_classes <- c("agricultural", "semiopen", "forests", "wetlands", "waterbodies")

data_cleaned["domclass"] <- names(data_cleaned)[which(names(data_cleaned) %in% landuse_classes)][max.col(data_cleaned[landuse_classes], "first")]
data_cleaned["domprop"] <- data_cleaned[, ]
data_cleaned["wetland"] <- data_cleaned$domclass == "wetlands"

data_cleaned$VIR[data_cleaned$VIR < -1] <- -1

baseline_all <- bind_rows(baseline_ppis)

alpha_baseline <- 0.5
alpha_ribbon <- 0.3

data_cleaned %>%
  # slice_sample(n = 2000) %>%
  # filter(dist_urban < 10000) %>%
  identity() %>%
  ggplot() +
  geom_pointdensity(aes(x = dist_urban, y = VIR, size = total_rcs), alpha = 0.05) +
  # geom_point(aes(x = dist_urban, y = VIR, size = total_rcs), color = "gray80", shape = 1, alpha = 0.8,
  #            data = data_cleaned %>% slice_sample(n = 10000)) +
  # Horizontal lines
  geom_hline(yintercept = disturbance_baseline, color = "blue", linetype = "dashed") +
  geom_hline(yintercept = mean(data_cleaned$VIR), color = "red", linetype = "dashed") +
  # Smooths Undisturbed
  geom_ribbon(aes(x = dist_urban, y = VIR), data = baseline_ppis[[1]], method = "gam", stat = "smooth",
              fill = "lightblue", alpha = alpha_ribbon) +
  geom_line(aes(x = dist_urban, y = VIR), data = baseline_ppis[[1]], method = "gam", stat = "smooth", color = "blue", alpha = alpha_baseline) +
  geom_ribbon(aes(x = dist_urban, y = VIR), data = baseline_ppis[[2]], method = "gam", stat = "smooth",
              fill = "lightblue", alpha = alpha_ribbon) +
  geom_line(aes(x = dist_urban, y = VIR), data = baseline_ppis[[2]], method = "gam", stat = "smooth", color = "blue", alpha = alpha_baseline) +
  geom_ribbon(aes(x = dist_urban, y = VIR), data = baseline_ppis[[3]], method = "gam", stat = "smooth",
              fill = "lightblue", alpha = alpha_ribbon) +
  geom_line(aes(x = dist_urban, y = VIR), data = baseline_ppis[[3]], method = "gam", stat = "smooth", color = "blue", alpha = alpha_baseline) +
  geom_ribbon(aes(x = dist_urban, y = VIR), data = baseline_ppis[[4]], method = "gam", stat = "smooth",
              fill = "lightblue", alpha = alpha_ribbon) +
  geom_line(aes(x = dist_urban, y = VIR), data = baseline_ppis[[4]], method = "gam", stat = "smooth", color = "blue", alpha = alpha_baseline) +
  geom_ribbon(aes(x = dist_urban, y = VIR), data = baseline_ppis[[5]], method = "gam", stat = "smooth",
              fill = "lightblue", alpha = alpha_ribbon) +
  geom_line(aes(x = dist_urban, y = VIR), data = baseline_ppis[[5]], method = "gam", stat = "smooth", color = "blue", alpha = alpha_baseline) +
  # geom_ribbon(aes(x = dist_urban, y = VIR), data = baseline_all, method = "gam", stat = "smooth",
  #             fill = "lightblue", alpha = alpha_ribbon) +
  # geom_line(aes(x = dist_urban, y = VIR), data = baseline_all, method = "gam", stat = "smooth", color = "blue", alpha = alpha_baseline) +
  # Smooths disturbed
  geom_ribbon(aes(x = dist_urban, y = VIR), method = "gam", stat = "smooth", fill = "red", alpha = 0.2) +
  geom_line(aes(x = dist_urban, y = VIR), method = "gam", stat = "smooth", color = "red", alpha = 1) +
  annotate("text", x = 15500, y = disturbance_baseline - 0.4, label = "Normal nights", hjust = 1, color = "blue", fontface = "bold") +
  annotate("text", x = 15500, y = mean(data_cleaned$VIR) + 0.4, label = "NYE", hjust = 1, color = "red", fontface = "bold") +
  scale_color_viridis_c(option = "inferno") +
  # scale_color_grey() +
  # scale_color_distiller(palette = "Greys", trans = "log10", direction = 1, values = c(0, 0.8)) +
  # scale_color_gradient(low = "#C3C3C3", high = "#747474") +
  # scale_color_discrete()
  scale_y_continuous(labels = function(x) {10^x}, breaks = c(-1, 0, 1, 2, 3, 4, 5, 6)) +
  scale_x_continuous(breaks = c(0, 5000, 10000, 15000)) +
  # facet_wrap(vars(wetland)) +
  theme_bw() +
  labs(x = "Distance to residential area (m)", y = "VIR") +
  guides(color = guide_colorbar("Density"),
         size = guide_legend("Total RCS (cm2)")) +
  coord_cartesian(expand = FALSE, ylim = c(-1, 6)) +
  theme(legend.position = "bottom") -> p_response

p_response
```

```{r}
data_cleaned %>%
  dplyr::select(agricultural:urban, domclass, dist_urban) %>%
  pivot_longer(cols = -c(domclass, dist_urban)) %>%
  filter(domclass == name) %>%
  # ggplot() +
  # geom_density(aes(x = dist_urban, group = domclass, fill = domclass), alpha = 0.5)
  ggplot(aes(x = dist_urban, y = fct_reorder(domclass, dist_urban, .fun = median, .desc = TRUE),
             fill = domclass)) +
  geom_density_ridges(scale = 4, rel_min_height = .005, color = "#ffffff") +
  scale_fill_manual(values = c("#73AF48", "#0F8554", "#EDAD08", "#1D6996", "#38A6A5")) +
  scale_color_manual(values = c("#73AF48", "#0F8554", "#EDAD08", "#1D6996", "#38A6A5")) +
  scale_x_continuous(limits = c(0, max(data_cleaned$dist_urban)), breaks = c(0, 5000, 10000, 15000)) +
  scale_y_discrete(position = "left") +
  coord_cartesian(expand = FALSE) +
  theme_bw() +
  theme(legend.position = "none") + 
  labs(x = "Distance to residential area (m)", y = "Occurrence") -> p_landuse

p_landuse
```

```{r}
p_landuse / p_response +
  plot_layout(heights = c(1, 2.5))
```



```{r}
ggsave("data/plots/distance_effect_combined.pdf", width = 7, height = 6)
```


```{r}
data_cleaned %>%
  mutate(VIR = 10^VIR,
         prop_flight = VIR / total_rcs,
         # prop_flight = if_else(prop_flight < 0.01, 0.01, prop_flight),
         prop_flight = log10(prop_flight)) %>%
  identity() %>%
  ggplot() +
  geom_pointdensity(aes(x = dist_urban, y = prop_flight), alpha = 0.2) +
  geom_smooth(aes(x = dist_urban, y = prop_flight), method = "gam") +
  # scale_y_continuous(trans = "log", breaks = c(0, 0.25, 0.5, 0.75, 1, 10, 100, 1000))
  # geom_pointdensity(aes(x = dist_urban, y = VIR, size = total_rcs), alpha = 0.2, position = position_jitter()) +
  # # Horizontal lines
  # geom_hline(yintercept = disturbance_baseline, color = "blue", linetype = "dashed") +
  # geom_hline(yintercept = mean(data_cleaned$VIR), color = "red", linetype = "dashed") +
  # # Smooths Undisturbed
  # geom_ribbon(aes(x = dist_urban, y = VIR), data = baseline_ppis[[1]], method = "gam", stat = "smooth", 
  #             fill = "lightblue", alpha = alpha_ribbon) +
  # geom_line(aes(x = dist_urban, y = VIR), data = baseline_ppis[[1]], method = "gam", stat = "smooth", color = "blue", alpha = alpha_baseline) +
  # geom_ribbon(aes(x = dist_urban, y = VIR), data = baseline_ppis[[2]], method = "gam", stat = "smooth", 
  #             fill = "lightblue", alpha = alpha_ribbon) +
  # geom_line(aes(x = dist_urban, y = VIR), data = baseline_ppis[[2]], method = "gam", stat = "smooth", color = "blue", alpha = alpha_baseline) +
  # geom_ribbon(aes(x = dist_urban, y = VIR), data = baseline_ppis[[3]], method = "gam", stat = "smooth", 
  #             fill = "lightblue", alpha = alpha_ribbon) +
  # geom_line(aes(x = dist_urban, y = VIR), data = baseline_ppis[[3]], method = "gam", stat = "smooth", color = "blue", alpha = alpha_baseline) +
  # geom_ribbon(aes(x = dist_urban, y = VIR), data = baseline_ppis[[4]], method = "gam", stat = "smooth", 
  #             fill = "lightblue", alpha = alpha_ribbon) +
  # geom_line(aes(x = dist_urban, y = VIR), data = baseline_ppis[[4]], method = "gam", stat = "smooth", color = "blue", alpha = alpha_baseline) +
  # geom_ribbon(aes(x = dist_urban, y = VIR), data = baseline_ppis[[5]], method = "gam", stat = "smooth", 
  #             fill = "lightblue", alpha = alpha_ribbon) +
  # geom_line(aes(x = dist_urban, y = VIR), data = baseline_ppis[[5]], method = "gam", stat = "smooth", color = "blue", alpha = alpha_baseline) +
  # # Smooths disturbed
  # geom_ribbon(aes(x = dist_urban, y = VIR), method = "gam", stat = "smooth", fill = "red", alpha = 0.2) +
  # geom_line(aes(x = dist_urban, y = VIR), method = "gam", stat = "smooth", color = "red", alpha = 1) +
  # annotate("text", x = 15500, y = disturbance_baseline - 0.4, label = "Normal nights", hjust = 1, color = "blue", fontface = "bold") +
  # annotate("text", x = 15500, y = mean(data_cleaned$VIR) + 0.4, label = "NYE", hjust = 1, color = "red", fontface = "bold") +
  # scale_color_viridis_c() +
  # # scale_color_discrete()
  scale_y_continuous(labels = function(x) {10^x}, breaks = c(-6, -5, -4, -3, -2, -1, 0, 1, 2, 3))
  # scale_x_continuous(breaks = c(0, 5000, 10000, 15000)) +
  # # facet_wrap(vars(wetland)) +
  # theme_bw() +
  # labs(x = "Distance to residential area (m)", y = "VIR") +
  # guides(color = guide_colorbar("Density (#)"),
  #        size = guide_legend("Total RCS (cm2)")) +
  # coord_cartesian(expand = FALSE)
```

```{r}
add_prop_flight <- function(x) {
  x %>%
    mutate(VIR = 10^VIR,
           prop_flight = VIR / total_rcs,
           # prop_flight = if_else(prop_flight < 0.01, 0.01, prop_flight),
           # prop_flight = log10(prop_flight),
           VIR = log10(VIR)) %>%
    identity()
}

baseline_ppis <- bind_rows(baseline_ppis)

baseline_ppis <- add_prop_flight(baseline_ppis)


data_cleaned %>%
  mutate(VIR = 10^VIR,
         prop_flight = VIR / total_rcs,
         # prop_flight = if_else(prop_flight < 0.01, 0.01, prop_flight),
         # prop_flight = log10(prop_flight),
         VIR = log10(VIR)) %>%
  identity() %>%
  ggplot() +
  geom_pointdensity(aes(x = dist_urban, y = prop_flight, size = total_rcs), alpha = 0.05) +
  # geom_point(aes(x = dist_urban, y = VIR, size = total_rcs), color = "gray80", shape = 1, alpha = 0.8,
  #            data = data_cleaned %>% slice_sample(n = 10000)) +
  # Horizontal lines
  # geom_hline(yintercept = disturbance_baseline, color = "blue", linetype = "dashed") +
  # geom_hline(yintercept = mean(data_cleaned$prop_flight), color = "red", linetype = "dashed") +
  # Smooths Undisturbed
  geom_ribbon(aes(x = dist_urban, y = prop_flight, group = dt), data = baseline_ppis, method = "gam", stat = "smooth",
              fill = "lightblue", alpha = alpha_ribbon) +
  geom_line(aes(x = dist_urban, y = prop_flight, group = dt), data = baseline_ppis, method = "gam", stat = "smooth",
            color = "blue", alpha = alpha_baseline) +
  # Smooths disturbed
  geom_ribbon(aes(x = dist_urban, y = prop_flight), method = "gam", stat = "smooth", fill = "red", alpha = 0.2) +
  geom_line(aes(x = dist_urban, y = prop_flight), method = "gam", stat = "smooth", color = "red", alpha = 1) +
  # annotate("text", x = 15500, y = disturbance_baseline - 0.4, label = "Normal nights", hjust = 1, color = "blue", fontface = "bold") +
  # annotate("text", x = 15500, y = mean(data_cleaned$prop_flight) + 0.4, label = "NYE", hjust = 1, color = "red", fontface = "bold") +
  scale_color_viridis_c(option = "inferno") +
  # scale_color_grey() +
  # scale_color_distiller(palette = "Greys", trans = "log10", direction = 1, values = c(0, 0.8)) +
  # scale_color_gradient(low = "#C3C3C3", high = "#747474") +
  # scale_color_discrete()
  # scale_y_continuous(labels = function(x) {10^x}) +
  scale_y_continuous(trans = "log10") +
  # scale_y_continuous(trans = "log10") +
  # scale_x_continuous(breaks = c(0, 5000, 10000, 15000)) +
  # facet_wrap(vars(wetland)) +
  theme_bw() +
  labs(x = "Distance to residential area (m)", y = "Measured / Potential VIR (Total RCS)") +
  guides(color = guide_colorbar("Density"),
         size = guide_legend("Total RCS (cm2)")) +
  coord_cartesian(expand = FALSE) +
  theme(legend.position = "bottom") -> p_response

p_response
```


## Spatial autocorrelation

Model residuals should not show strong autocorrelation as then the independency of errors assumption is violated (see for example [this](https://doi.org/10.1186/s41610-019-0118-3)). Additionally, a model with strong autocorrelation in the residuals suggests that it lacks a spatial component within the predictors. As it is computationally too difficult to calculate the spatial autocorrelation for the entire dataset at once, we subsample 20% of datapoints for these calculations. Results may thus vary to some degree.

```{r calculate_model_residual_autocorrelation, eval=full_repro}
df <- data_cleaned
df$residual <- resid(model)

df %>%
  filter(dist_radar < 66000) %>%
  slice_sample(prop = 0.20) -> df_sample

correlogram <- correlog(df_sample[, c("x", "y")], df_sample[, "residual"], method = "Moran", nbclass = NULL)
saveRDS(correlogram , file = "data/models/correlogram.RDS")
```
```{r plot_model_residual_autocorrelation}
correlogram <- readRDS("data/models/correlogram.RDS")
plot(correlogram)
```

This shows there's some spatial autocorrelation in residuals remaining. We use a plot of residuals to assess where this occurs and if this indicates our model is missing some important spatial effect, or if there is another explanation.

*Unfortunately, due to [the way `leaflet` stores maps it produces](https://github.com/rstudio/bookdown/issues/15#issuecomment-573776659), we cannot plot them here using K-M knitting to generate this document. Run these chunks interactively and they should work fine.* So, here we'll have to resort to a static representation of the model residuals.

```{r plot_model_residuals_in_space}
df <- data_cleaned
df$residual <- resid(model)
df$preds <- predict.mboost(model, newdata = data_cleaned)
ppi <- readRDS("data/processed/composite-ppis/500m/201712312305.RDS")
 
ppi$data@data %>%
  left_join(dplyr::select(df, pixel, preds, residual), by = "pixel") -> ppi$data@data
ppi$data@data$VIR_log <- log10(ppi$data@data$VIR)
ppi$data@data$total_biomass_log <- log10(ppi$data@data$total_biomass / 1000)

pal_resid <- colorspace::diverging_hcl(50, "Blue-Red 3", power = 2)
z_lims_resid <- c(-3, 3)
palette_resid <- colorNumeric(pal_resid, na.color = "#00000005", domain = z_lims_resid)
raster_resid <- as(ppi$data["residual"], "RasterLayer")
raster_resid[raster_resid <= z_lims_resid[1]] <- z_lims_resid[1]
raster_resid[raster_resid >= z_lims_resid[2]] <- z_lims_resid[2]
```
```{r plot_model_residuals_interactive, eval=FALSE}
leaflet() %>%
  addTiles(group = "OSM (default)") %>%
  addRasterImage(raster_resid, colors = palette_resid, layerId = "resid", group = "resid") %>%
  addImageQuery(raster_resid, layerId = "resid") %>%
  addLegend(pal = palette_resid, values = z_lims_resid) %>%
  addOpacitySlider(layerId = "resid") %>%
  identity()
```
```{r plot_model_residuals_static, out.width='100%'}
as.data.frame(raster_resid, xy = TRUE) %>%
  drop_na() %>%
  ggplot() +
  geom_raster(aes(x = x, y = y, fill = residual)) +
  scale_fill_distiller(type = "div", palette = "RdBu") +
  theme_dark()
```

### Correct for residual spatial autocorrelation

The correlogram and spatial plots of residuals show clearly that residuals are spatially autocorrelated. We will correct for this effect using Crase et al. [-@crase2012], by calculating an autocovariate (distance weighted mean) of the residuals using a 1500m neighborhood radius. If we look at the correlogram above, we can see that spatial autocorrelation is still visible at distances of 30-50km, but calculating an autocovariate for such neighborhoods would be too computationally intensive. Some points won't have neighborhoods at all, but that is fine.

```{r calculate_autocovariate}
nbs <- 1500  # Kilometers if longlat = TRUE
acov <- autocov_dist(resid(model), as.matrix(cbind(data_cleaned$x, data_cleaned$y)), nbs = nbs, zero.policy = TRUE)
data_cleaned$acov <- acov
```

Having calculated the autocovariate and included it in our dataset, we can retrain a model, this time with the inclusion of the `autocov` parameter.

```{r retrain_model_with_autocovariate, eval=full_repro}
formula <- VIR ~ bbs(dist_radar) + bbs(total_rcs) + bbs(semiopen) + bbs(forests) + bbs(wetlands) + bbs(waterbodies) +
  bbs(agricultural) + bbs(dist_urban) + bbs(acov)
model_rac <- mboost(formula, data = data_cleaned, control = boost_control(mstop = 10000, trace = TRUE))
saveRDS(model_rac, file = "data/models/model_rac.RDS")
```

Let's plot model variable importance and modelled effects again for this newly trained model.

```{r plot_varimp_model_rac, out.width='100%'}
model_rac <- readRDS("data/models/model_rac.RDS")
plot(varimp(model_rac))
```

```{r plot_model_rac, out.width='100%'}
par(mfrow = c(3, 4))
plot(model_rac)
```

And recalculate Moran's I for the new model residuals.

```{r recalculate_moran_i_rac_model, eval=full_repro}
df <- data_cleaned
df$residual <- resid(model_rac)

df %>%
  filter(dist_radar < 66000) %>%
  slice_sample(prop = 0.2) -> df_sample

correlogram <- correlog(df_sample[, c("x", "y")], df_sample[, "residual"], method = "Moran", nbclass = NULL)
saveRDS(correlogram , file = "data/models/correlogram_rac.RDS")
```
```{r plot_correlogram_again, out.width='100%'}
correlogram <- readRDS("data/models/correlogram_rac.RDS")
plot(correlogram)
```

That looks much better! Residual spatial autocorrelation is still present and significant (red circles in plot above), but has now decreased from ~0.3 to ~0.02. So it is now pretty much negligible.

For completeness, let's make the residuals spatially explicit again

```{r plot_rac_model_residuals}
df <- data_cleaned
df$residual <- resid(model_rac)
df$preds <- predict.mboost(model_rac, newdata = data_cleaned)
ppi <- readRDS("data/processed/composite-ppis/500m/201712312305.RDS")
 
ppi$data@data %>%
  left_join(dplyr::select(df, pixel, preds, residual), by = "pixel") -> ppi$data@data
ppi$data@data$VIR_log <- log10(ppi$data@data$VIR)
ppi$data@data$total_biomass_log <- log10(ppi$data@data$total_biomass / 1000)

pal_resid <- colorspace::diverging_hcl(50, "Blue-Red 3", power = 2)
z_lims_resid <- c(-3, 3)
palette_resid <- colorNumeric(pal_resid, na.color = "#00000005", domain = z_lims_resid)
raster_resid <- as(ppi$data["residual"], "RasterLayer")
raster_resid[raster_resid <= z_lims_resid[1]] <- z_lims_resid[1]
raster_resid[raster_resid >= z_lims_resid[2]] <- z_lims_resid[2]
```
```{r plot_model_residuals_interactive_rac, eval=FALSE}
leaflet() %>%
  addTiles(group = "OSM (default)") %>%
  addRasterImage(raster_resid, colors = palette_resid, layerId = "resid", group = "resid") %>%
  addImageQuery(raster_resid, layerId = "resid") %>%
  addLegend(pal = palette_resid, values = z_lims_resid) %>%
  addOpacitySlider(layerId = "resid") %>%
  identity()
```
```{r plot_model_residuals_static_rac, out.width='100%'}
as.data.frame(raster_resid, xy = TRUE) %>%
  drop_na() %>%
  ggplot() +
  geom_raster(aes(x = x, y = y, fill = residual)) +
  scale_fill_distiller(type = "div", palette = "RdBu") +
  theme_dark()
```

And finally we can recalculate the model performance and compare it with the original model.

```{r compare_model_performance_rac}
RMSE <- function(error) { sqrt(mean(error^2)) }
rmse <- RMSE(residuals(model_rac))
de <- deviance_explained(data_cleaned$VIR, predict(model_rac))
perf_rac <- as.data.frame(list("RMSE" = as.matrix(rmse), "Dev.Exp" = as.matrix(de)))

perf <- bind_rows(perf_original["dist_urban", ], perf_rac)
rownames(perf) <- c("dist_urban_original", "dist_urban_rac")
perf
```
