# (PART) Fireworks disturbance {-}

# Modelling fireworks disturbance

We have so far:

1. Pre-processed the radar data by removing clutter and applying the range-bias correction [@kranstauber2020].
2. Annotated the PPIs with land use proportions and indicators of disturbance, i.e. distance to inhabited urban areas and (human) population density.
3. Annotated the PPIs with the calculated total biomass calculated from the Sovon counts.

With the dataset of annotated PPIs, we can start to explore the relation between fireworks disturbance and the birds measured aloft during NYE 2017-2018.

The following parameters we assume are important predictors for measured bird densities aloft:

1. The total biomass of birds on the ground.
2. The take-off habitat of these birds.
3. The human population in the vicinity of birds.
4. The distance to the nearest inhabited urban area.

## Setting-up the environment

Load the required packages.

```{r setup_modelling_environment}
library(ggstatsplot)
library(ggplot2)
library(dplyr)
library(readr)
library(tidyr)
library(gbm)
library(dismo)
library(ggBRT)
library(patchwork)
library(pdp)
library(parallel)
```

In the previous chapter, we have created a dataset encompassing all the data contained within the individual PPIs. We will use this for further modelling.

```{r load_data}
data <- readRDS("data/processed/all.RDS")
```

## Preparing a dataset for modelling

As we're mostly interested in the moment of en masse take-off of birds, and we want to limit the effects of dispersal, we will limit our analysis to the first 5 minutes after 00:05 on January 1st, 2018 (or 23:05 on December 31st, 2017 in UTC), as both radar sites (Den Helder and Herwijnen) show a low `VIR` prior to and a rapid increase in `VIR` for that period (see [Identifying moment of take-off]). Making sure birds are thus still sufficiently 'linked' to the take-off sites requires that we limit our analysis to only this one scan.

Furthermore, we want to make sure that:
1. the area is 'covered' by at least 1 radar,
2. we have an estimate of `total_biomass`for these sites,
3. the proportion of urban area (`urban`) in the PPI pixel is less than .25,
4. `VIR` is > 0 (otherwise log-conversion will return `-Inf`).

```{r prepare_modelling_dataset}
dt_start <- as.POSIXct("2017-12-31 23:05:00", tz = "UTC")
dt_end <- as.POSIXct("2017-12-31 23:10:00", tz = "UTC")

mdl_variables <- c("VIR", "dist_radar", "datetime", "total_biomass", "urban", "agricultural", "semiopen", "forests", "wetlands", "waterbodies", 
                   "dist_urban", "human_pop", "disturb_pot", "pixel")
log10_variables <- c("dist_urban", "human_pop", "total_biomass", "dist_urban", "disturb_pot")

data %>%
  filter(coverage > 0,
         datetime >= dt_start & datetime < dt_end,
         total_biomass > 0,
         dist_radar < 80000,
         urban < 0.25) %>%
  mutate(VIR = log10(VIR),
         disturb_pot = human_pop / dist_urban,
         total_biomass = total_biomass / 1000) %>%
  dplyr::select(all_of(mdl_variables)) %>%
  filter_all(all_vars(is.finite(.))) %>%
  identity() -> data_cleaned
```

## Check for correlations among predictors

We have to see if variables are strongly correlated and thus unfit for being included in the same model, so we calculate Spearman correlation coefficients for all numerical predictors. As this is ecological data, some degree of correlation is of course inevitable for most variables.

```{r check_for_correlations, warning=FALSE, fig.width=10}
predictors <- mdl_variables[!mdl_variables %in% c("VIR", "datetime", "pixel", "x", "y")]
corr_radar <- ggcorrmat(data_cleaned, output = "plot", type = "spearman", cor.vars = all_of(predictors), colors = c("#2166AC", "#F7F7F7", "#B2182B"))
corr_radar
```

## Determine the most suitable proxy for disturbance

As could be expected, the three 'disturbance parameters' (`dist_urban`, `human_pop`, `disturb_pot`) are highly correlated, so we should see which of these is most suitable to include in our model, as it makes no sense to include all. To assess that, we will simply compare the performance of each of the models trained with a single disturbance parameter.

```{r compare_disturbance_proxies, results='hold'}
lr <- 0.03
silence <- FALSE

base_model <- c("dist_radar", "total_biomass", "urban", "agricultural", "semiopen", "forests", "wetlands", "waterbodies")
disturbance_proxies <- c("dist_urban", "human_pop", "disturb_pot")
x_vars <- lapply(disturbance_proxies, function(x) match(c(base_model,x), colnames(data_cleaned)))

disturbance_models <- mclapply(x_vars, function(x) gbm.step(data = data_cleaned, gbm.y = 1, gbm.x = x, bag.fraction = 0.75, family = "gaussian", tree.complexity = 2, learning.rate = lr, silent = silence))

ggPerformance("dist_urban" = disturbance_models[[1]], "human_pop" = disturbance_models[[2]], "disturb_pot" = disturbance_models[[3]])
```

It turns out performance is more similar than dissimilar across these disturbance proxies, though results may vary due to the non-deterministic behaviour of gradient-boosted machines. So we will stick with the model containing a disturbance proxy that is least correlated with the other predictor variables.

```{r determine_least_correlated_disturbance_proxy}
corr_radar_df <- ggcorrmat(data_cleaned, output = "dataframe", type = "spearman", col.vars = all_of(predictors))
corr_radar_df %<>% filter(parameter1 %in% disturbance_proxies | parameter2 %in% disturbance_proxies)
  
swap_vars <- function(x, first_col) {
  if (!x["parameter1"] %in% first_col) {
    x_param1 <- x["parameter1"]
    x_param2 <- x["parameter2"]
    x["parameter1"] <- x_param2
    x["parameter2"] <- x_param1
    x
  } else {
    x
  }
}

corr_radar_df[, c("parameter1", "parameter2")] <- t(apply(corr_radar_df[, c("parameter1", "parameter2")], 1, swap_vars, disturbance_proxies))

corr_radar_df %>%
  filter(!parameter2 %in% c(disturbance_proxies, "VIR")) %>%
  group_by(parameter1) %>%
  rename(parameter = parameter1) %>%
  summarise(sum_corr = sum(rho^2), .groups = "drop_last") %>%  # Sum of squares to add 'punish' extra for high correlations
  identity() -> sum_corr

least_correlated <- sum_corr[which.min(sum_corr$sum_corr), ]
sum_corr
```

So, the 'least correlated' variable is `r least_correlated$parameter` and we will therefore continue using the model trained with this proxy for disturbance.

```{r save_model}
models <- disturbance_models[match(least_correlated$parameter, disturbance_proxies)]

saveRDS(models, file = "data/models/brt_models.RDS")
```

## Relative influence of variables

We can now also compare the relative influence of the variables used in this model.

```{r determine_relatieve_influence_of_predictors, results='hold'}
relinf <- ggInfluence(models[[1]], show.signif = FALSE, main = "Relative influence of predictor variables on log(VIR)")
relinf
```

The high relative importance of `total_biomass` (`r round(relinf["total_biomass", ], digits = 1)`%) suggests a clear link between birds counted on the ground (by Sovon's observers) and what is measured aloft, exactly what one would expect if birds are still sufficiently 'tied' to their take-off habitat.

## Partial dependence

Partial dependence plots (PDP) can visualise the modelled marginal effect a feature has on the predicted output of a model. For exploratory purposes, we will create a quick visualisation of the PDPs for the trained model, before we start with a bootstrapping procedure to test the robustness of these results.

```{r visualise_partial_dependencies, warning=FALSE, message=FALSE, results='hold'}
plot_pdp <- function(model, predictor) {
  p <- partial(model, train = model$gbm.call$dataframe, pred.var = predictor, type = "regression", plot = TRUE, plot.engine ="ggplot2",
               smooth = TRUE, rug = TRUE, n.trees = model$n.trees)
  p
}
modelnames <- names(models)
i <- 1

for (model in models) {
  plots <- lapply(rownames(relinf), function(x) {
    plot_pdp(model = model, predictor = x) + 
      xlab(paste(x, " (", round(relinf[x, i]), "%)", sep = "")) +
      ylab("log(VIR)")
    })
  print(wrap_plots(plots) + plot_annotation(title = modelnames[i]))
  i <- i + 1
}
```


