[
["index.html", "Fireworks Preface Abstract How to use this document", " Fireworks Bart Hoekstra 2020-10-12 Preface Abstract How to use this document Knit it Use the following line in the console or click Build Book in RStudio. bookdown::render_book(input = &quot;index.Rmd&quot;, output_format = &quot;bookdown::gitbook&quot;, clean = TRUE) Full-reproduction mode In the spirit of reproducibility, the entire analysis, which happens to be contained in this book, can theoretically be reproduced at the push of a button. To facilitate faster reproduction, some code chunks are only run when full-reproduction mode is switched on. This can be done by setting the R variable full_repro to TRUE in build_bookdown.R. "],
["01.Selecting-take-off-moments.html", "1 Selecting firework take-off moment 1.1 Processing environment 1.2 Calculate the vertical profiles 1.3 Generate time series of vertical profiles 1.4 Identifying moment of take-off 1.5 Determining maximum range from radar to detect birds", " 1 Selecting firework take-off moment For this study we select the moment of ‘en masse’ take-off of birds at the turn of the year. To make sure birds are still fairly ‘close’ to the take-off habitat, we therefore focus on the period where the increase in VIR (Vertically Integrated Reflectivity) is the highest. Based on experience, one would expect this to occur between 00:05 and 00:15 on January 1st, as people tend to light the fireworks right after they have shared New Year’s wishes with each other. 1.1 Processing environment We use vol2bird included in the bioRad package (Dokter et al. 2019) to calculate the vertical profiles of reflectivity, from which we determine the exact take off moment of birds. This implies we assume birds take to the skies everywhere simultaneously, but that seems a realistic assumption given that the lighting of fireworks is synchronised by the national time, rather than the local time of sunset/sunrise. library(bioRad) library(ggplot2) library(dplyr) library(tidyr) Sys.setenv(TZ = &quot;UTC&quot;) 1.2 Calculate the vertical profiles We calculate vertical profiles for the period between December 31st, 2017 22:00 and 01:00 UTC on January 1st, 2018, which corresponds with 23:00 til 02:00 local Amsterdam time (UTC + 1). It is not necessary to generate so many vp files, but it gives a better temporal overview of the event if we add some ‘temporal padding’ around the fireworks event. Beware: to calculate the vertical profiles, a running instance of Docker is required. This code chunk will only run in full-reproduction mode. See the appendix on [generating VPs for Den Helder][generating-vps-for-den-helder-radar] for a more detailed explanation why we limit vp generation of Den Helder to certain azimuths. fireworks_scans &lt;- Sys.glob(file.path(&quot;data/raw/pvol/fireworks-2017-2018&quot;, &quot;*_ODIM.h5&quot;)) cat(&quot;Files left to process: &quot;, length(fireworks_scans), &quot;\\n&quot;) i &lt;- 1 for (scan in fireworks_scans) { if (i %% 5 == 0) { cat(i, &quot;... &quot;) } vpfile_out &lt;- sub(&quot;raw/pvol/fireworks-2017-2018&quot;, &quot;processed/vp/fireworks-2017-2018&quot;, scan) if (grepl(&quot;RAD_NL61&quot;, vpfile_out)) { try(calculate_vp(scan, vpfile = vpfile_out, verbose = FALSE, mount = dirname(fireworks_scans[1]), azim_min = 90, azim_max = 200, h_layer = 50, n_layer = 80)) } else { try(calculate_vp(scan, vpfile = vpfile_out, verbose = FALSE, mount = dirname(fireworks_scans[1]), h_layer = 50, n_layer = 80)) } i &lt;- i + 1 } 1.3 Generate time series of vertical profiles We can now generate a time series of vertical profiles (a VPTS) and plot the bird densities to get an idea of what was going on during NYE of 2017-2018. fw_hrw_vpts &lt;- Sys.glob(file.path(&quot;data/processed/vp/fireworks-2017-2018&quot;, &quot;*NL62*&quot;)) %&gt;% read_vpfiles() %&gt;% bind_into_vpts() %&gt;% regularize_vpts(interval = &quot;auto&quot;) fw_dhl_vpts &lt;- Sys.glob(file.path(&quot;data/processed/vp/fireworks-2017-2018&quot;, &quot;*NL61*&quot;)) %&gt;% read_vpfiles() %&gt;% bind_into_vpts() %&gt;% regularize_vpts(interval = &quot;auto&quot;) start &lt;- as.POSIXct(&quot;2017-12-31 22:00:00&quot;) end &lt;- as.POSIXct(&quot;2018-01-01 01:00:00&quot;) indexes_hrw &lt;- which(fw_hrw_vpts$datetime &gt;= start &amp; fw_hrw_vpts$datetime &lt;= end) indexes_dhl &lt;- which(fw_dhl_vpts$datetime &gt;= start &amp; fw_dhl_vpts$datetime &lt;= end) # Should mostly be identical title_hrw &lt;- expression(&quot;Herwijnen: volume density [#/km&quot;^3 * &quot;]&quot;) title_dhl &lt;- expression(&quot;Den Helder: volume density [#/km&quot;^3 * &quot;]&quot;) plot(fw_hrw_vpts[indexes_hrw], main = title_hrw) plot(fw_dhl_vpts[indexes_dhl], main = title_dhl) ## projecting on 300 seconds interval grid... ## projecting on 300 seconds interval grid... Both plots for Herwijnen and Den Helder show exactly what we would expect: comparatively low densities of birds aloft leading up to midnight (23:00 CET), then suddenly a strong increase of birds right after midnight. For Den Helder this peak appears much more pronounced, whereas for Herwijnen the period of disturbance seems to take considerably longer. This is probably due to the vastly different environment around the radar site: Herwijnen is located solidly in the center of the country, whereas Den Helder is located close to the coast on a ‘peninsula’ with much less land in the surroundings, pronounced by vol2bird only taking the rangegates within 5-35km of the radar into account. 1.4 Identifying moment of take-off We integrate the time series of vertical profiles, so we can calculate the VIR derivatives and determine in what volume scan birds really take to the skies for each radar separately. integrated_hrw &lt;- integrate_profile(fw_hrw_vpts) integrated_dhl &lt;- integrate_profile(fw_dhl_vpts) integrated_hrw$vir_deriv &lt;- c(NA, diff(integrated_hrw$vir, 1)) integrated_dhl$vir_deriv &lt;- c(NA, diff(integrated_dhl$vir, 1)) integrated_hrw$radar &lt;- &quot;Herwijnen&quot; integrated_dhl$radar &lt;- &quot;Den Helder&quot; integrated &lt;- rbind(integrated_hrw, integrated_dhl) integrated_l &lt;- integrated %&gt;% pivot_longer(-c(&quot;datetime&quot;, &quot;radar&quot;), names_to = &quot;variable&quot;, values_to = &quot;value&quot;) %&gt;% filter(variable == &quot;vir&quot; | variable == &quot;vir_deriv&quot;) %&gt;% filter(datetime &gt;= start &amp; datetime &lt;= end) max_vir_deriv &lt;- integrated_l %&gt;% filter(variable == &quot;vir_deriv&quot;) %&gt;% drop_na() %&gt;% group_by(radar) %&gt;% summarize(max_value = max(value), datetime = datetime[which.max(value)], .groups = &quot;drop_last&quot;) theme_set(theme_bw()) ggplot(integrated_l, aes(x = datetime)) + geom_line(aes(y = value, colour = radar, linetype = variable)) + scale_x_datetime(breaks = &quot;10 min&quot;, date_labels = &quot;%H:%M&quot;, expand = c(0, 0)) + scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;)) + scale_linetype_discrete(name = &quot;Line type&quot;, labels = c(&quot;VIR&quot;, expression(paste(Delta,&quot;VIR/scan&quot;)))) + labs(title = &quot;Time series of Vertically Integrated Reflectivities (VIR)&quot;, subtitle = &quot;NYE 2017-2018&quot;, x = &quot;Time (CET)&quot;, y = &quot;VIR&quot;, colour = &quot;Radar&quot;, linetype = &quot;Linetype&quot;) + theme(axis.text.x = element_text(angle = -90), panel.grid.minor = element_blank()) The plot shows a rapid increase in VIR in the first 15 and 20 minutes after midnight (23:00 CET) for the Den Helder and Herwijnen radar respectively. After that period, VIR starts to drop, faster for Den Helder than for Herwijnen, possibly as a result of birds dispersing from the North Holland mainland towards the IJsselmeer area, which we have deliberately excluded from the generation of the vertical profiles (by selecting azimuths that are above land). To reduce the effect of bird dispersal on our analysis, we will focus only on the first 5 minute-scan during which VIR grows rapidly. That is from 23:05 CET until 23:10 CET. pvol_folder &lt;- &quot;data/raw/pvol/fireworks-2017-2018/&quot; scan_timestamp &lt;- lubridate::ymd_hm(&quot;2017-12-31 23:05&quot;) pvol_hrw_path &lt;- paste(pvol_folder, &quot;RAD_NL62_VOL_NA_&quot;, format(scan_timestamp, &quot;%Y%m%d%H%M&quot;), &quot;_ODIM.h5&quot;, sep = &quot;&quot;) pvol_dhl_path &lt;- paste(pvol_folder, &quot;RAD_NL61_VOL_NA_&quot;, format(scan_timestamp, &quot;%Y%m%d%H%M&quot;), &quot;_ODIM.h5&quot;, sep = &quot;&quot;) save(pvol_hrw_path, pvol_dhl_path, file = &quot;data/processed/pvol_selection.RData&quot;) So we will mainly focus on working with the following polar volume files: Herwijnen: RAD_NL62_VOL_NA_201712312305_ODIM.h5 Den Helder: RAD_NL61_VOL_NA_201712312305_ODIM.h5 1.5 Determining maximum range from radar to detect birds We can assume that the flight altitudes derived from vol2bird are representative for flight altitudes throughout the country. Given that most of the disturbance happens at comparatively low altitudes, the radar is likely to ‘overshoot’ this entirely at substantial distances away from the radar where compensating for range-effects (e.g. using Kranstauber et al. (2020)) will thus have undesired consequences. Therefore we need to determina a maximum range at which we could still feasibly measure birds aloft. We can do so by inspecting the vpts plots from before, but now focussing on the lowest 1km. Notice how we are generating VPTSs with 50m height bins vs. the standard 100m height bins, so we can pinpoint more precisely at what altitude densities drop off. plot(fw_hrw_vpts[indexes_hrw], ylim = c(0, 1000)) plot(fw_dhl_vpts[indexes_dhl], ylim = c(0, 1000)) We can now see that above 600m ASL or so the density starts to drop substantially, so we will set this as the altitudinal cutoff to determine the range up to which we will be using the data coming from the range-bias correction (Kranstauber et al. 2020). Although birds are somewhat lower in height overall in Den Helder than Herwijnen, this is an acceptable threshold as Herwijnen anyways covers much more land area within our study domain than Den Helder, and thus a more representative range-bias correction for Herwijnen is more important than Den Helder. Now we can calculate the distance at which that height (600m) is the height of the lowest elevation (0.3 degrees) and round to the nearest kilometer. altitude_cutoff &lt;- 600 ranges &lt;- seq(0, 180000, 100) beamheights &lt;- beam_height(ranges, 0.3) nearest_index &lt;- which(abs(beamheights - altitude_cutoff) == min(abs(beamheights - altitude_cutoff))) slantrange &lt;- ranges[nearest_index] distance_cutoff &lt;- plyr::round_any(beam_distance(slantrange, 0.3), 1000) distance_cutoff ## [1] 66000 So at roughly 66 kilometers from the radar, the lowest elevation scan pierces the sky at an altitude of 600m. References "],
["02.Radar-data-preprocessing.html", "2 Radar Data Preprocessing 2.1 Processing environment 2.2 Removing electromagnetic interference 2.3 Filter meteorology using the depolarization ratio 2.4 Remove classified precipitation from polar volumes 2.5 Filter ground clutter 2.6 Range-bias correction 2.7 Keep biology/meteorology classification 2.8 Distance to radar 2.9 Spatial coordinates 2.10 Visualising range-bias correction 2.11 Preprocess additional scans", " 2 Radar Data Preprocessing Weather radar data of the firework events at the turns of the years usually contain some degree of precipitation clutter. To filter out precipitation advanced algorithms such as MistNet have been developed, but as we are dealing with dual-polarization radar data here, we can use a simpler and yet robust method using the depolarization ratio (Kilambi, Fabry, and Meunier 2018). To make sure our processed weather radar data does not contain any significant proportions of precipitation or ground clutter anymore, we process the data as follows: We remove electromagnetic interference based on a visual inspection of the scans and throw out all data of affected rays. We calculate the depolarization ratio (Kilambi, Fabry, and Meunier 2018) and separate biology from meteorology by classifying all range gates with a depolarization ratio \\(&gt;-12dB\\) as biology. We subsequently ‘despeckle’ this, to remove obvious misclassifications. We average reflectivity over a number of scans before the time of the fireworks event and throw out the range-gates with highest average reflectivities. All these steps can be undertaken directly on the polar volume data, so we can subsequently plug the cleaned up volume into the range-bias correction. 2.1 Processing environment As usual, most of the processing takes place using bioRad (Dokter et al. 2019). library(bioRad) library(plotly) library(gridExtra) library(ggpubr) library(mapview) library(viridis) library(raster) library(dplyr) library(magrittr) 2.2 Removing electromagnetic interference We have determined in which scans birds are taking off based on the maximum increase in reflectivity in the scan for each of the involved radars. Let’s now look at these scans to see how much filtering for electromagnetic interference we need to do. The easiest way to determine which rays are subject to this interference is by plotting the scans in polar coordinates \\((r, \\alpha)\\), so interference stands out as horizontal lines of more or less constant, or very gradually changing reflectivities. Plotting using plotly makes it easier to identify the specific problematic rays as one can zoom in to identify the exact azimuths \\(\\alpha\\) at which this interference occurs. The scans we will be using: Herwijnen: RAD_NL62_VOL_NA_201712312305_ODIM.h5 Den Helder: RAD_NL61_VOL_NA_201712312305_ODIM.h5 For illustrative purposes we will only illustrate removal of EM interference for the Herwijnen radar, as the procedure for Den Helder is exactly identical, but this scan contains very little of said clutter. pvol_hrw &lt;- read_pvolfile(pvol_hrw_path, param = &quot;all&quot;) pvol_dhl &lt;- read_pvolfile(pvol_dhl_path, param = &quot;all&quot;) scan &lt;- plot(pvol_hrw$scans[[1]], param = &quot;DBZH&quot;, xlim = c(0, 180000)) + theme_dark() ggplotly(scan) Right away we can see that rays at two places in the scan are subject to electromagnetic interference. This is probably most problematic in the lowest elevations of the volume scan, but nevertheless each of the 16 scans have to be checked manually. Doing so results in the identification of the following rays that contain electromagnetic interference (ei_rays), organised in a list with the scan numbers (organised ascendingly per elevation angle) as keys. Admittedly: there is another ray that seems to contain interference in the first scan, but this is so far away from the radar (150km+) it should not affect our results as no meaningful numbers of birds can be detected at that range anyways and we thus exclude it from our analysis. Similarly, there are similar patterns of interference/clutter in higher elevation scans, but these too should not affect our results. ei_rays_hrw &lt;- list(c(201, 202, 214, 215), # scan 1 c(201, 202, 214, 215), # scan 2 c(201, 202, 214, 215), # scan 3 c(202, 214, 215)) # scan 4 names(ei_rays_hrw) &lt;- c(1, 2, 3, 4) ei_rays_dhl &lt;- list(c(60, 61)) # scan 1 names(ei_rays_dhl) &lt;- c(1) We can now remove the data for the affected rays in the corresponding scans by setting the values to NA (see R/remove_rays.R). source(&quot;R/remove_rays.R&quot;) pvol_hrw &lt;- remove_rays(pvol_hrw, rays = ei_rays_hrw) pvol_dhl &lt;- remove_rays(pvol_dhl, rays = ei_rays_dhl) 2.2.1 Verify removal of rays with EM interference If removal is correct, the \\((r,\\alpha)\\) plots should not show clear horizontal structures anymore. i = 1 plot(pvol_hrw$scans[[i]], param = &quot;DBZH&quot;, xlim = c(0, 180000)) + theme_dark() + labs(title = &quot;Herwijnen: Cleaned from EM interference&quot;, subtitle = paste(&quot;Elevation:&quot;, round(pvol_hrw$scans[[i]]$attributes$where$elangle, 1))) plot(pvol_dhl$scans[[i]], param = &quot;DBZH&quot;, xlim = c(0, 180000)) + theme_dark() + labs(title = &quot;Den Helder: Cleaned from EM interference&quot;, subtitle = paste(&quot;Elevation:&quot;, round(pvol_dhl$scans[[i]]$attributes$where$elangle, 1))) That seems to work nicely. 2.3 Filter meteorology using the depolarization ratio Meteorology can be filtered using the depolarization ratio following Kilambi et al. (2018). We calculate the depolarization ratio for the raw pvol data after EM interference has been removed and subsequently ‘despeckle’ the results to improve the classification. Despeckling works by comparing the classification of the majority of the neighbourhood rangegates with the classification of the center rangegate, and changing the latter to reflect the majority of the neighbourhood classification if there is a difference. We define the ‘neighbourhood’ as a \\(3^{\\circ}\\) by \\(3 \\times rscale\\) area centered around a focal rangegate (3 rangegates in azimuth \\(\\times\\) 3 rangegates in range). Selecting the rangegates while taking the sphericity of the radar scan into account (e.g. ray 360 should be directly adjacent to ray 1) is made easier with the R/window_coords.R function. The despeckling is implemented in R/despeckle_scan_logical.R. With the despeckling algorithm in place, we can: Calculate the depolarization ratio (DPR). Classify biology as rangegates where DPR &gt; -12 and store this classification as BIOLR (Biology Raw) scan parameter in the pvol object. Despeckle the classification and store the outcome in the BIOLD (Biology Despeckled) scan parameter in the pvol object. source(&quot;R/window_coords.R&quot;) source(&quot;R/despeckle_scan_logical.R&quot;) # Calculate depolarization ratio, classify and despeckle biology classifications for the entire volume calculate_dpr &lt;- function(pvol){ for (i in seq_along(pvol$scans)) { # Calculate ZDR as ZDR = DBZH - DBZV pvol$scans[[i]]$params$ZDR &lt;- pvol$scans[[i]]$params$DBZH - pvol$scans[[i]]$params$DBZV attributes(pvol$scans[[i]]$params$ZDR)$param &lt;- &quot;ZDR&quot; # Calculate depolarization ratio zdr_linear &lt;- 10 ** (pvol$scans[[i]]$params$ZDR / 10) dpr_linear &lt;- (zdr_linear + 1 - 2 * sqrt(zdr_linear) * pvol$scans[[i]]$params$RHOHV) / (zdr_linear + 1 + 2 * sqrt(zdr_linear) * pvol$scans[[i]]$params$RHOHV) pvol$scans[[i]]$params$DPR &lt;- 10 * log10(dpr_linear) attributes(pvol$scans[[i]]$params$DPR)$param &lt;- &quot;DPR&quot; # Classify based on depolarization ratio biology &lt;- (pvol$scans[[i]]$params$DPR &gt; -12) * 1 # multiply by 1 to convert TRUE/FALSE to 1/0 class(biology) &lt;- c(&quot;param&quot;, &quot;matrix&quot;) attributes(biology) &lt;- attributes(pvol$scans[[i]]$params$DPR) # copy attributes from DPR attributes(biology)$param &lt;- &quot;BIOLR&quot; pvol$scans[[i]]$params$BIOLR &lt;- biology # Despeckle biology classification pvol$scans[[i]]$params$BIOLD &lt;- pvol$scans[[i]]$params$BIOLR pvol$scans[[i]]$params$BIOLD &lt;- despeckle_scan_logical(pvol$scans[[i]]$params$BIOLD) attributes(pvol$scans[[i]]$params$BIOLD)$param &lt;- &quot;BIOLD&quot; } return(pvol) } pvol_hrw &lt;- suppressWarnings(calculate_dpr(pvol_hrw)) # Will throw NaN warnings if not suppressed pvol_dhl &lt;- suppressWarnings(calculate_dpr(pvol_dhl)) 2.3.1 Verify DPR-based classification Now let’s plot some PPIs to verify the accuracy of DPR-based classification and the subsequent despeckling, by plotting DBZH, VRADH, DPR, BIOLR and BIOLD. source(&quot;R/side_by_side_ppi.R&quot;) side_by_side_ppi(pvol_hrw, pvol_dhl, &quot;Herwijnen&quot;, &quot;Den Helder&quot;, params = c(&quot;DBZH&quot;, &quot;VRADH&quot;, &quot;DPR&quot;, &quot;BIOLR&quot;, &quot;BIOLD&quot;)) The plots show accurate classification of the obvious precipitation zones, except at the edges of these echoes, where BIOLD is a vast improvement over BIOLR, showing the value of despeckling. Similarly, there is a lot of ‘noise’ where birds should be, but despeckling takes care of most of that quite nicely as well. Additionally, it shows a pattern we would expect to see: at closer distances to the radar most ‘speckles’ that are not near to precipitation zones are turned into biology, and at distances further from the radar they are more often ‘flipped’ to meteorology. This method may not be perfect, but it classifies birds quite conservatively. The few misclassifications that remain should not affect the results so much, as they are few in number and do not occur at the centers of precipitation echoes, so they are not likely to turn into numerical outliers. 2.4 Remove classified precipitation from polar volumes Now that we have accurate classifications of the rangegates based on depolarization ratios, we can start to remove the precipitation from the polar volumes, to retain a scan that comprises of only birds (with a few occasional misclassifications). As there are areas where DPR and DBZH do not overlap, we also have to remove all rangegates that are not classified. source(&quot;R/remove_precipitation.R&quot;) pvol_hrw &lt;- remove_precipitation(pvol_hrw) pvol_dhl &lt;- remove_precipitation(pvol_dhl) Plotting the same PPIs as before should now show a cleaned-up/precipitation-free scan next to the classifications. side_by_side_ppi(pvol_hrw, pvol_dhl, &quot;Herwijnen&quot;, &quot;Den Helder&quot;, params = c(&quot;DBZH&quot;, &quot;VRADH&quot;)) That looks very good for both Herwijnen and Den Helder radars, but for the latter we have a lot of sea clutter that still needs to be removed, which is next on the list when filtering ground clutter. 2.5 Filter ground clutter We will filter out ground clutter by calculating summary statistics of the rangegate reflectivities over: The 36 scans preceding the scans selected for the study of the fireworks event (= 3 hours worth of scans). A day of clear weather closest to the 31st of December 2017. For each we will filter ground clutter based on the mean DBZH values. Using the variance and mad of the DBZH was tested, but has a few difficulties: variance is very sensitive to the outliers caused by rangegates with NA values (detection below the ‘mds’, the minimum detectable signal) occasionally flipping over to a noisy measurement, resulting in very high variances. mad is much more robust to outliers, but to compute these values we need to set NA cells to the ‘mds’ (minimum detectable signal), which will result in mad values close to, or exactly 0 for cells that never reflected as well as true static clutter, so it’s difficult to separate those. Finally, a visual inspection showed the mean and mad of DBZH (assuming one could overcome the aforementioned problem with the latter) do not differ much, but the mean is somewhat more ‘aggressive’ in filtering, which in this case is quite good. Combining the clutter removal based on a clear day as well as the 36 preceding scans lets us account for both truly static clutter (e.g. buildings) as well as clutter that is more dynamic such as sea and wind park clutter, without also requiring us to resort to filtering of dynamic clutter using a VRADH threshold. The quality of filtering is assessed visually. 2.5.1 Dynamic clutter We select 36 (3 hours worth of scans) preceding the start of the fireworks (23:00 UTC) and add an additional margin of 3 scans (15 minutes of scans) as the VIR plots in the previous chapter have shown numbers of birds aloft are very low and stable up to that period. available_scans_hrw &lt;- Sys.glob(file.path(&quot;data/raw/pvol/clutter-removal-20171231&quot;, &quot;*NL62*20171231*&quot;)) available_scans_dhl &lt;- Sys.glob(file.path(&quot;data/raw/pvol/clutter-removal-20171231&quot;, &quot;*NL61*20171231*&quot;)) fw_start_hrw_pvol_path &lt;- &quot;data/raw/pvol/fireworks-2017-2018/RAD_NL62_VOL_NA_201712312300_ODIM.h5&quot; fw_start_dhl_pvol_path &lt;- &quot;data/raw/pvol/fireworks-2017-2018/RAD_NL61_VOL_NA_201712312300_ODIM.h5&quot; selected_scan_hrw &lt;- sub(&quot;fireworks-2017-2018&quot;, &quot;clutter-removal-20171231&quot;, fw_start_hrw_pvol_path) selected_scan_dhl &lt;- sub(&quot;fireworks-2017-2018&quot;, &quot;clutter-removal-20171231&quot;, fw_start_dhl_pvol_path) selected_scan_id_hrw &lt;- match(selected_scan_hrw, available_scans_hrw) selected_scan_id_dhl &lt;- match(selected_scan_dhl, available_scans_dhl) usable_scans_hrw &lt;- available_scans_hrw[(selected_scan_id_hrw-dynamic_time_margin-dynamic_nr_preceding_scans+1): (selected_scan_id_hrw-dynamic_time_margin)] usable_scans_dhl &lt;- available_scans_dhl[(selected_scan_id_dhl-dynamic_time_margin-dynamic_nr_preceding_scans+1): (selected_scan_id_dhl-dynamic_time_margin)] We can now loop over the files one by one and stack reflectivity data (DBZH) — after filtering out precipitation — in a multidimensional array. Note: the following code chunk will only run in full-reproduction mode as it takes quite a lot of time. Results are saved, so the next iteration this chunk can be skipped. source(&quot;R/stack_rainfree_reflectivities.R&quot;) stack_rainfree_reflectivities(usable_scans_hrw, outputfile = &quot;data/processed/clutter_dynamic_hrw.RDS&quot;) stack_rainfree_reflectivities(usable_scans_dhl, outputfile = &quot;data/processed/clutter_dynamic_dhl.RDS&quot;) With all DBZH compiled in a single multidimensional array, we can calculate mean reflectivity, which we store as DBZH_AVG in a pvol that now contains the dynamic clutter map. pvol_clutter_dynamic_hrw &lt;- readRDS(&quot;data/processed/clutter_dynamic_hrw.RDS&quot;) pvol_clutter_dynamic_dhl &lt;- readRDS(&quot;data/processed/clutter_dynamic_dhl.RDS&quot;) source(&quot;R/calculate_reflectivity_stack_mean.R&quot;) pvol_clutter_dynamic_hrw &lt;- calculate_reflectivity_stack_mean(pvol_clutter_dynamic_hrw, mds) pvol_clutter_dynamic_dhl &lt;- calculate_reflectivity_stack_mean(pvol_clutter_dynamic_dhl, mds) saveRDS(pvol_clutter_dynamic_hrw, &quot;data/processed/clutter_dynamic_hrw_avg.RDS&quot;) saveRDS(pvol_clutter_dynamic_dhl, &quot;data/processed/clutter_dynamic_dhl_avg.RDS&quot;) pvol_clutter_dynamic_hrw &lt;- readRDS(&quot;data/processed/clutter_dynamic_hrw_avg.RDS&quot;) pvol_clutter_dynamic_dhl &lt;- readRDS(&quot;data/processed/clutter_dynamic_dhl_avg.RDS&quot;) 2.5.1.1 Verify dynamic clutter map Let’s see what that looks like on a basemap, using a DBZH_AVG threshold of \\(-10dbZ\\), following (Dokter et al. 2011). scan_hrw &lt;- pvol_clutter_dynamic_hrw$scans[[1]] scan_dhl &lt;- pvol_clutter_dynamic_dhl$scans[[1]] side_by_side_ppi(pvol_clutter_dynamic_hrw, pvol_clutter_dynamic_dhl, &quot;Herwijnen dynamic clutter&quot;, &quot;Den Helder dynamic clutter&quot;, params = &quot;DBZH_AVG&quot;, range_max = 50000, scan_id = 1, basemap = TRUE, zlim = c(-11, -10)) Visually assessing this clutter map shows that it works quite well, selecting e.g. areas with wind parks, sea clutter, high buildings, industry, etc. Exactly what we hoped to achieve. 2.5.2 Static clutter Now, let’s retry exactly the same procedure, but this time selecting a day with no precipitation, which can be done using this tool by KNMI, so we can filter for truly static clutter. We select the following days: Herwijnen: December 29th, 2017 Den Helder: December 25th, 2017 Note: the following code chunk will only run in full-reproduction mode as it takes a lot of time to run. Results are saved, so the next iteration this chunk can be skipped. source(&quot;R/stack_rainfree_reflectivities.R&quot;) available_scans_hrw &lt;- Sys.glob(file.path(&quot;data/raw/pvol/clutter-removal-20171229-hrw&quot;, &quot;*NL62*20171229*&quot;)) available_scans_dhl &lt;- Sys.glob(file.path(&quot;data/raw/pvol/clutter-removal-20171225-dhl&quot;, &quot;*NL61*20171225*&quot;)) stack_rainfree_reflectivities(available_scans_hrw, outputfile = &quot;data/processed/clutter_static_hrw.RDS&quot;) stack_rainfree_reflectivities(available_scans_dhl, outputfile = &quot;data/processed/clutter_static_dhl.RDS&quot;) And we calculate mean DBZH values (DBZH_AVG). pvol_clutter_static_hrw &lt;- readRDS(&quot;data/processed/clutter_static_hrw.RDS&quot;) pvol_clutter_static_dhl &lt;- readRDS(&quot;data/processed/clutter_static_dhl.RDS&quot;) source(&quot;R/calculate_reflectivity_stack_mean.R&quot;) # Source because full_repro may be set to FALSE pvol_clutter_static_hrw &lt;- calculate_reflectivity_stack_mean(pvol_clutter_static_hrw, mds) pvol_clutter_static_dhl &lt;- calculate_reflectivity_stack_mean(pvol_clutter_static_dhl, mds) saveRDS(pvol_clutter_static_hrw, &quot;data/processed/clutter_static_hrw_avg.RDS&quot;) saveRDS(pvol_clutter_static_dhl, &quot;data/processed/clutter_static_dhl_avg.RDS&quot;) pvol_clutter_static_hrw &lt;- readRDS(&quot;data/processed/clutter_static_hrw_avg.RDS&quot;) pvol_clutter_static_dhl &lt;- readRDS(&quot;data/processed/clutter_static_dhl_avg.RDS&quot;) 2.5.2.1 Verify static clutter map Once again, let’s see what that looks like on a basemap, using a DBZH_AVG threshold of \\(-10dbZ\\), following (Dokter et al. 2011). scan_hrw &lt;- pvol_clutter_static_hrw$scans[[1]] scan_dhl &lt;- pvol_clutter_static_dhl$scans[[1]] side_by_side_ppi(pvol_clutter_static_hrw, pvol_clutter_static_dhl, &quot;Herwijnen static clutter&quot;, &quot;Den Helder static clutter&quot;, params = &quot;DBZH_AVG&quot;, range_max = 50000, scan_id = 1, basemap = TRUE, zlim = c(-11, -10)) 2.5.3 Remove dynamic and static clutter Now that we have identified both dynamic and static clutter, we can create the final cleaned up polar volume. source(&quot;R/remove_groundclutter.R&quot;) pvol_hrw &lt;- remove_groundclutter(remove_groundclutter(pvol_hrw, pvol_clutter_dynamic_hrw), pvol_clutter_static_hrw) pvol_dhl &lt;- remove_groundclutter(remove_groundclutter(pvol_dhl, pvol_clutter_dynamic_dhl), pvol_clutter_static_dhl) saveRDS(pvol_hrw, file = &quot;data/processed/pvol_clean_hrw.RDS&quot;) saveRDS(pvol_dhl, file = &quot;data/processed/pvol_clean_dhl.RDS&quot;) 2.6 Range-bias correction With all identifiable sources of clutter removed from the raw polar volume, we can apply the range-bias correction (Kranstauber et al. 2020). For this it is necessary to calculate the local vertical profile for each of the radars. Ideally, this would be done using the filtered pvol we have now generated, but the vol2bird algorithm (Dokter et al. 2011) only takes pvol files as input, rather than R objects. As there is no implementation of a converter yet, for now a vp of the raw pvol files will have to do. As there is no precipitation within the relevant distance to the radars (5-35km), the calculated vp based on the raw pvol files should not differ wildly from that of the filtered pvol R object we have generated in the previous steps. For the Den Helder radar we calculate the vp by setting azimuthal limits to cover the mainland of North Holland, rather than the whole radar domain, as the latter will result in vps that underestimate the true density of birds aloft. See [the corresponding appendix][generating-vps-for-den-helder-radar] for a more detailed explanation. vp_hrw &lt;- calculate_vp(file = pvol_hrw_path, vpfile = paste(&quot;data/processed/vp/&quot;, basename(pvol_hrw_path), sep = &quot;&quot;), verbose = FALSE) vp_dhl &lt;- calculate_vp(file = pvol_dhl_path, vpfile = paste(&quot;data/processed/vp/&quot;, basename(pvol_dhl_path), sep = &quot;&quot;), verbose = FALSE, azim_min = 90, azim_max = 200) corrected_ppi_hrw &lt;- integrate_to_ppi(pvol_hrw, vp_hrw, res = 500, xlim = c(-150000, 150000), ylim = c(-150000, 150000)) corrected_ppi_dhl &lt;- integrate_to_ppi(pvol_dhl, vp_dhl, res = 500, xlim = c(-150000, 150000), ylim = c(-150000, 150000)) saveRDS(corrected_ppi_hrw, file = &quot;data/processed/corrected_ppi_hrw.RDS&quot;) saveRDS(corrected_ppi_dhl, file = &quot;data/processed/corrected_ppi_dhl.RDS&quot;) We can now plot the final range-corrected PPIs. p_vir_hrw &lt;- plot(corrected_ppi_hrw, param = &quot;VIR&quot;, zlim = c(0, 20000)) + labs(title = &quot;Herwijnen: VIR&quot;) p_vir_dhl &lt;- plot(corrected_ppi_dhl, param = &quot;VIR&quot;, zlim = c(0, 20000)) + labs(title = &quot;Den Helder: VIR&quot;) ggarrange(p_vir_hrw, p_vir_dhl, ncol = 2, nrow = 1, common.legend = TRUE, legend = &quot;right&quot;) 2.7 Keep biology/meteorology classification By default the range-bias correction returns values from 0 upwards, so there is no way for us to distinguish anymore between ‘pixels’ that did not reflect and those that were filtered out as meteorology. That’s why we will additionally add the class parameter to the range-bias corrected PPIs. To avoid misalignment and differences in vertical integration compared with the range-bias correction, we can ‘trick’ the RBC by replacing the DBZH values it expects by the BIOLD(despeckled biology) values (either 0 for meteorology or 1 for biology) multiplied by 1000. This would result in very high integrated values of VIR where an area is classified as biology and very low values where it is classified as meteorology. pvol_hrw_classified &lt;- calculate_param(pvol_hrw, DBZH = BIOLD * 1000) pvol_dhl_classified &lt;- calculate_param(pvol_dhl, DBZH = BIOLD * 1000) pvol_hrw_classified &lt;- remove_groundclutter(remove_groundclutter(pvol_hrw_classified, pvol_clutter_dynamic_hrw), pvol_clutter_static_hrw) pvol_dhl_classified &lt;- remove_groundclutter(remove_groundclutter(pvol_dhl_classified, pvol_clutter_dynamic_dhl), pvol_clutter_static_dhl) corrected_ppi_hrw_classified &lt;- integrate_to_ppi(pvol_hrw_classified, vp_hrw, res = 500, xlim = c(-150000, 150000), ylim = c(-150000, 150000)) corrected_ppi_dhl_classified &lt;- integrate_to_ppi(pvol_dhl_classified, vp_dhl, res = 500, xlim = c(-150000, 150000), ylim = c(-150000, 150000)) p_vir_hrw_classified &lt;- plot(corrected_ppi_hrw_classified, param = &quot;VIR&quot;, zlim = c(0, 50000)) + labs(title = &quot;Herwijnen: VIR&quot;) p_vir_dhl_classified &lt;- plot(corrected_ppi_dhl_classified, param = &quot;VIR&quot;, zlim = c(0, 50000)) + labs(title = &quot;Den Helder: VIR&quot;) ggarrange(p_vir_hrw_classified, p_vir_dhl_classified, ncol = 2, nrow = 1, common.legend = TRUE, legend = &quot;right&quot;) That looks good, so now we add it to the corrected PPIs. We reclassify the VIR as follows: Biology gets class = 2, Meteorology gets class = 1, Background gets class = 0. corrected_ppi_hrw_classified$data@data %&gt;% mutate(class = case_when( VIR &gt; 40000 ~ 2, VIR &lt;= 40000 &amp; VIR &gt; 0 ~ 1, VIR == 0 ~ 0 )) %&gt;% dplyr::select(class) -&gt; class_hrw corrected_ppi_dhl_classified$data@data %&gt;% mutate(class = case_when( VIR &gt; 40000 ~ 2, VIR &lt;= 40000 &amp; VIR &gt; 0 ~ 1, VIR == 0 ~ 0 )) %&gt;% dplyr::select(class) -&gt; class_dhl corrected_ppi_hrw$data$class &lt;- unlist(class_hrw) corrected_ppi_dhl$data$class &lt;- unlist(class_dhl) 2.8 Distance to radar To account for remaining range-bias effects, it is also useful to calculate the distance to the radar from a given PPI pixel. We can then include it in our modelling efforts later on. source(&quot;R/calculate_distance_to_radar.R&quot;) corrected_ppi_hrw &lt;- calculate_distance_to_radar(corrected_ppi_hrw) corrected_ppi_dhl &lt;- calculate_distance_to_radar(corrected_ppi_dhl) 2.9 Spatial coordinates Furthermore, it can be useful to keep spatial coordinates to correct for spatial autocorrelation should this be necessary, so we calculate these as well. coords_hrw &lt;- coordinates(corrected_ppi_hrw$data) corrected_ppi_hrw$data$x &lt;- coords_hrw[, 1] corrected_ppi_hrw$data$y &lt;- coords_hrw[, 2] coords_dhl &lt;- coordinates(corrected_ppi_dhl$data) corrected_ppi_dhl$data$x &lt;- coords_dhl[, 1] corrected_ppi_dhl$data$y &lt;- coords_dhl[, 2] saveRDS(corrected_ppi_hrw, file = &quot;data/processed/corrected_ppi_hrw.RDS&quot;) saveRDS(corrected_ppi_dhl, file = &quot;data/processed/corrected_ppi_dhl.RDS&quot;) 2.10 Visualising range-bias correction Now we can finally have a proper look at the range-corrected versions of the PPI overlaid on an interactive map. It’s a little hard to interpret with the PPI pixels that contain no birds set to 0 and no landscape below, so let’s see what it looks like on a basemap with those removed. As there are some ships out at the North Sea causing reflectivities orders of magnitude higher and thus stretching the colormap, we — for now — need to ‘clip’ these values to a maximum set at the value of the 99th percentile. source(&quot;R/clip.R&quot;) filtered_corrected_ppi_hrw &lt;- corrected_ppi_hrw filtered_corrected_ppi_hrw$data@data &lt;- as.data.frame(apply(filtered_corrected_ppi_hrw$data@data, 2, clip, bounds = c(0.05, 0.99))) filtered_corrected_ppi_dhl &lt;- corrected_ppi_dhl filtered_corrected_ppi_dhl$data@data &lt;- as.data.frame(apply(filtered_corrected_ppi_dhl$data@data, 2, clip, bounds = c(0.05, 0.99))) 2.10.1 Range-corrected PPI of Herwijnen radar (???): Somehow now broken after adding biology classification mapview(corrected_ppi_hrw$data) 2.10.2 Range-corrected PPI of Den Helder radar mapview(corrected_ppi_dhl$data) 2.11 Preprocess additional scans Now that the processing steps have been explained in detail, we can process the additional scans in our dataset in a similar fashion. For that we will focus on all scans from 22:00 CET until 01:00 CET, which corresponds with 23:00 until 02:00 in local Amsterdam time, as that should ‘cover’ most of the fireworks disturbance that occurs (based on the plots in Selecting firework take-off moment). source(&quot;R/preprocess_radar_data.R&quot;) hrw_pvols &lt;- Sys.glob(file.path(&quot;data/raw/pvol/fireworks-2017-2018&quot;, &quot;*NL62*&quot;)) dhl_pvols &lt;- Sys.glob(file.path(&quot;data/raw/pvol/fireworks-2017-2018&quot;, &quot;*NL61*&quot;)) dynamic_groundclutter_hrw &lt;- readRDS(&quot;data/processed/clutter_dynamic_hrw_avg.RDS&quot;) static_groundclutter_hrw &lt;- readRDS(&quot;data/processed/clutter_static_hrw_avg.RDS&quot;) dynamic_groundclutter_dhl &lt;- readRDS(&quot;data/processed/clutter_dynamic_dhl_avg.RDS&quot;) static_groundclutter_dhl &lt;- readRDS(&quot;data/processed/clutter_static_dhl_avg.RDS&quot;) for (pvol in hrw_pvols) { preprocess_radar_data(pvol_path = pvol, ei_rays = ei_rays_hrw, pvol_dynamic_groundclutter = dynamic_groundclutter_hrw, pvol_static_groundclutter = static_groundclutter_hrw, res = 500) } for (pvol in dhl_pvols) { preprocess_radar_data(pvol_path = pvol, ei_rays = ei_rays_dhl, pvol_dynamic_groundclutter = dynamic_groundclutter_dhl, pvol_static_groundclutter = static_groundclutter_dhl, azim_limits = c(90, 200), res = 500) } References "],
["03.Annotate-land-use.html", "3 Annotating land use 3.1 Processing environment 3.2 Converting the land use map 3.3 Adding land use classifications to the PPIs 3.4 Calculate distance to nearest urban area 3.5 Add population density", " 3 Annotating land use In this study we aim to quantify the response to fireworks across different bird communities, for which we use take-off habitat as a proxy. In this notebook we will classify land use, and a variety of factors that can serve as a proxy for the severity of fireworks disturbance, such as the distance to the nearest residential area for each of the PPI ‘pixels’. The land use is based on the CORINE Land Cover dataset and specifically the 2018 version (CLC2018), which should be most relevant for the 2017-2018 fireworks event. 3.1 Processing environment library(raster) library(sf) library(stars) library(dplyr) library(ggplot2) library(ggpubr) library(gridExtra) library(viridis) library(mapview) 3.2 Converting the land use map To start, we need to convert the land use map to the same 1) resolution, and 2) extent of the radar PPIs as we can then simply ‘overlay’ both rasters on top of each other and merge them. We load the PPIs and extract the CRS information contained in the proj4 strings. ppi_hrw &lt;- readRDS(&quot;data/processed/corrected_ppi_hrw.RDS&quot;) ppi_dhl &lt;- readRDS(&quot;data/processed/corrected_ppi_dhl.RDS&quot;) ppi_proj4_hrw &lt;- ppi_hrw$data@proj4string ppi_proj4_dhl &lt;- ppi_dhl$data@proj4string And we load and prepare the land use map it’s all about. To aid the classification process, we also load the legend of land use classes contained in the entire CLC2018 dataset, otherwise the classes will remain anonymous numbers. landuse &lt;- raster(&quot;data/raw/landuse/clc2018_clc2018_v2018_20_raster100m/CLC2018_CLC2018_V2018_20.tif&quot;) landuse_classes &lt;- read.csv(&quot;data/raw/landuse/clc2018_clc2018_v2018_20_raster100m/Legend/CLC2018_CLC2018_V2018_20_QGIS.txt&quot;, col.names = c(&quot;landuse_id&quot;, &quot;r&quot;, &quot;g&quot;, &quot;b&quot;, &quot;x&quot;, &quot;landuse_class&quot;), header = FALSE)[, c(&quot;landuse_id&quot;, &quot;landuse_class&quot;),] 3.2.1 Cropping the land use map As the CLC2018 dataset is so large it does not fit in memory at all in the steps below, so we have to crop the raster dataset for further processing. Even then, it still requires a beefy machine to process these files. First, we calculate a bounding box for the landuse raster based on the bounding boxes of the radar data. padding &lt;- 25000 # Padding in m to make sure we crop out of the land use map with a wide margin to compensate for edge-effects later bbox_meters &lt;- abs(ppi_dhl$data@bbox[[1]]) + padding # Assuming the PPI range of DHL and HRW are the same bbox_hrw &lt;- st_bbox(c(xmin = -bbox_meters, ymin = -bbox_meters, xmax = bbox_meters, ymax = bbox_meters), crs = ppi_proj4_hrw) bbox_dhl &lt;- st_bbox(c(xmin = -bbox_meters, ymin = -bbox_meters, xmax = bbox_meters, ymax = bbox_meters), crs = ppi_proj4_dhl) bbox_hrw %&gt;% st_as_sfc() %&gt;% st_transform(crs(landuse)) %&gt;% st_bbox -&gt; bbox_landuse_hrw bbox_dhl %&gt;% st_as_sfc() %&gt;% st_transform(crs(landuse)) %&gt;% st_bbox -&gt; bbox_landuse_dhl We can now crop and plot the land use maps centered on the radar sites, with a meter padding surrounding the extent of the radar data. ext_hrw &lt;- extent(c(bbox_landuse_hrw[1], bbox_landuse_hrw[3], bbox_landuse_hrw[2], bbox_landuse_hrw[4])) ext_dhl &lt;- extent(c(bbox_landuse_dhl[1], bbox_landuse_dhl[3], bbox_landuse_dhl[2], bbox_landuse_dhl[4])) landuse_crop_hrw &lt;- crop(landuse, ext_hrw) landuse_crop_dhl &lt;- crop(landuse, ext_dhl) sea_id &lt;- match(&#39;Sea and ocean&#39;, landuse_classes$landuse_class) landuse_crop_hrw[is.na(landuse_crop_hrw)] &lt;- landuse_classes[sea_id, &quot;landuse_id&quot;] # Convert Sea that is set to NaN landuse_crop_dhl[is.na(landuse_crop_dhl)] &lt;- landuse_classes[sea_id, &quot;landuse_id&quot;] And plot the result: par(pty = &quot;s&quot;, mfrow = c(1, 2)) image(landuse_crop_hrw, main = &quot;Herwijnen&quot;) image(landuse_crop_dhl, main = &quot;Den Helder&quot;) 3.2.2 Reprojecting the land use map Now that the land use map is cropped, we can start the reprojection to the CRS of the radar PPI. As we’re dealing with categorical data, we set method = &quot;ngb&quot; to use nearest neighbour interpolation. Despite using interpolation, this reprojection does not change the resolution from the base of the CLC2018 dataset to that of the PPI, so we’ll have to do that next. landuse_hrw_reprojected &lt;- projectRaster(landuse_crop_hrw, crs = ppi_proj4_hrw, method = &quot;ngb&quot;) landuse_dhl_reprojected &lt;- projectRaster(landuse_crop_dhl, crs = ppi_proj4_dhl, method = &quot;ngb&quot;) levels(landuse_hrw_reprojected) &lt;- levels(landuse_crop_hrw) levels(landuse_dhl_reprojected) &lt;- levels(landuse_crop_dhl) If the reprojection went successful, the CRS of the reprojected land use map and the radar PPI should be the same. compareCRS(ppi_hrw$data@proj4string, landuse_hrw_reprojected@crs) compareCRS(ppi_dhl$data@proj4string, landuse_dhl_reprojected@crs) ## [1] TRUE ## [1] TRUE Apparently that is the case. 3.2.3 Reclassifying land use types to functional classes The CLC2018 dataset contains a total of 44 land use classes. For our purpose, we reduce these 44 to 5 classes with more biologically relevant groupings, specifically: Urban area Agricultural area Semi-open area Forests Wetlands Water bodies The following table is used to convert/reclassify the classes contained within the CLC2018 dataset, with the original land use classes under landuse_class and how they will be reclassified under landuse_target. We also indicate whether these areas are inhabited (inhabited = 1), or uninhabited (inhabited = 0). In The Netherlands inhabited areas are classified as “Discontinuous urban fabric” in the CLC2018 dataset, all other areas we set to uninhabited. landuse_classes %&lt;&gt;% mutate(landuse_target = case_when( landuse_id &gt;= 100 &amp; landuse_id &lt; 200 ~ &quot;Urban area&quot;, landuse_id &gt;= 200 &amp; landuse_id &lt;= 213 ~ &quot;Agricultural area&quot;, landuse_id &gt;= 221 &amp; landuse_id &lt;= 223 ~ &quot;Semi-open area&quot;, landuse_id &gt;= 231 &amp; landuse_id &lt;= 243 ~ &quot;Agricultural area&quot;, landuse_id &gt;= 244 &amp; landuse_id &lt; 300 ~ &quot;Forests&quot;, landuse_id &gt;= 300 &amp; landuse_id &lt;= 313 ~ &quot;Forests&quot;, landuse_id &gt;= 321 &amp; landuse_id &lt;= 335 ~ &quot;Semi-open area&quot;, landuse_id &gt;= 400 &amp; landuse_id &lt; 500 ~ &quot;Wetlands&quot;, landuse_id &gt;= 500 &amp; landuse_id &lt; 999 ~ &quot;Water bodies&quot;, landuse_id == 999 ~ &quot;NODATA&quot;)) %&gt;% mutate(landuse_target_id = case_when( landuse_target == &quot;Urban area&quot; ~ 1, landuse_target == &quot;Agricultural area&quot; ~ 2, landuse_target == &quot;Semi-open area&quot; ~ 3, landuse_target == &quot;Forests&quot; ~ 4, landuse_target == &quot;Wetlands&quot; ~ 5, landuse_target == &quot;Water bodies&quot; ~ 6, landuse_target == &quot;NODATA&quot; ~ 9 )) landuse_classes$inhabited &lt;- 0 landuse_classes$inhabited[landuse_classes$landuse_class == &quot;Discontinuous urban fabric&quot;] &lt;- 1 landuse_classes landuse_id landuse_class landuse_target landuse_target_id inhabited 111 Continuous urban fabric Urban area 1 0 112 Discontinuous urban fabric Urban area 1 1 121 Industrial or commercial units Urban area 1 0 122 Road and rail networks and associated land Urban area 1 0 123 Port areas Urban area 1 0 124 Airports Urban area 1 0 131 Mineral extraction sites Urban area 1 0 132 Dump sites Urban area 1 0 133 Construction sites Urban area 1 0 141 Green urban areas Urban area 1 0 142 Sport and leisure facilities Urban area 1 0 211 Non-irrigated arable land Agricultural area 2 0 212 Permanently irrigated land Agricultural area 2 0 213 Rice fields Agricultural area 2 0 221 Vineyards Semi-open area 3 0 222 Fruit trees and berry plantations Semi-open area 3 0 223 Olive groves Semi-open area 3 0 231 Pastures Agricultural area 2 0 241 Annual crops associated with permanent crops Agricultural area 2 0 242 Complex cultivation patterns Agricultural area 2 0 243 Land principally occupied by agriculture with significant areas of natural vegetation Agricultural area 2 0 244 Agro-forestry areas Forests 4 0 311 Broad-leaved forest Forests 4 0 312 Coniferous forest Forests 4 0 313 Mixed forest Forests 4 0 321 Natural grasslands Semi-open area 3 0 322 Moors and heathland Semi-open area 3 0 323 Sclerophyllous vegetation Semi-open area 3 0 324 Transitional woodland-shrub Semi-open area 3 0 331 Beaches dunes sands Semi-open area 3 0 332 Bare rocks Semi-open area 3 0 333 Sparsely vegetated areas Semi-open area 3 0 334 Burnt areas Semi-open area 3 0 335 Glaciers and perpetual snow Semi-open area 3 0 411 Inland marshes Wetlands 5 0 412 Peat bogs Wetlands 5 0 421 Salt marshes Wetlands 5 0 422 Salines Wetlands 5 0 423 Intertidal flats Wetlands 5 0 511 Water courses Water bodies 6 0 512 Water bodies Water bodies 6 0 521 Coastal lagoons Water bodies 6 0 522 Estuaries Water bodies 6 0 523 Sea and ocean Water bodies 6 0 999 NODATA NODATA 9 0 With a sort-of ‘raster attribute table’ in place, we can now reclassify the detailed landuse classes to the broader categories listed above. landuse_dhl_reclassified &lt;- ratify(reclassify(landuse_dhl_reprojected, cbind(landuse_classes$landuse_id, landuse_classes$landuse_target_id)), count = TRUE) landuse_hrw_reclassified &lt;- ratify(reclassify(landuse_hrw_reprojected, cbind(landuse_classes$landuse_id, landuse_classes$landuse_target_id)), count = TRUE) writeRaster(landuse_dhl_reclassified, &quot;data/processed/landuse/landuse_dhl_reclassified.tif&quot;, overwrite = TRUE) writeRaster(landuse_hrw_reclassified, &quot;data/processed/landuse/landuse_hrw_reclassified.tif&quot;, overwrite = TRUE) This leaves us with the following count of ~100x100m cells per land use category cellcounts &lt;- cbind(levels(landuse_hrw_reclassified)[[1]][&quot;COUNT&quot;], levels(landuse_dhl_reclassified)[[1]][&quot;COUNT&quot;]) colnames(cellcounts) &lt;- c(&quot;Herwijnen&quot;, &quot;Den Helder&quot;) rownames(cellcounts) &lt;- unique(landuse_classes$landuse_target)[-7] cellcounts Herwijnen Den Helder Urban area 1860678 809932 Agricultural area 6256242 3384907 Semi-open area 194271 133709 Forests 1437047 498510 Wetlands 346616 364301 Water bodies 3851726 8890353 3.2.4 Resampling the land use map to a lower resolution The cellsize of the PPIs is 500x500 meters, but the land use map is much more finely detailed (~100x100m), so we need to resample the latter to derive a land use map at a 500x500 meter resolution as well. As the resolution of the PPIs is so much higher than that of the land use map, we need to resample the latter to a lower resolution. Instead of classifying a single pixel in the PPI as belonging to a single land use class, we will do so using land use proportions. We therefore calculate the proportions belonging to each of the land use classes within an area of cells roughly the size of the PPI pixels. Subsequently we resample this to match 1:1 with the PPI pixels and store the land use proportions for each of the land use classes in the PPIs. This is done in the calculate_land_use_proportion() function below. calculate_land_use_proportion &lt;- function(raster, reference_raster, overwrite = FALSE) { values &lt;- c(sort(unique(getValues(raster)))) # classes: multidimensional logical array for the classes contained within the land use map # 1 if a land use class is present on that position, 0 if not classes &lt;- layerize(raster, filename = paste(&quot;data/processed/landuse/layerize/&quot;, substitute(raster), sep = &quot;&quot;), format = &quot;raster&quot;, bylayer = TRUE, classes = values, overwrite = overwrite) # factor: nr of cells in both horizontal and vertical direction to aggregate factor &lt;- round(dim(raster)[1:2] / dim(reference_raster)[1:2]) # agg: aggregated version of classes (aggregation factor defined by factor) containing mean coverage by a class in a given area # 1 corresponds with full coverage, 0 with no coverage of that class within the pixel at all agg &lt;- aggregate(classes, factor, na.rm = TRUE, fun = mean) # x: the agg and ppi pixels almost overlap exactly, but there is a teeny tiny difference which we can # iron out by resampling once more. x &lt;- resample(agg, reference_raster) return(x) } We can now calculate the proportions and will save these to some raster files for potential inspection in GIS software. landuse_hrw &lt;- calculate_land_use_proportion(landuse_hrw_reclassified, as(ppi_hrw$data, &quot;RasterLayer&quot;), overwrite = TRUE) landuse_dhl &lt;- calculate_land_use_proportion(landuse_dhl_reclassified, as(ppi_dhl$data, &quot;RasterLayer&quot;), overwrite = TRUE) names(landuse_hrw) &lt;- c(&quot;urban&quot;, &quot;agricultural&quot;, &quot;semiopen&quot;, &quot;forests&quot;, &quot;wetlands&quot;, &quot;waterbodies&quot;) names(landuse_dhl) &lt;- c(&quot;urban&quot;, &quot;agricultural&quot;, &quot;semiopen&quot;, &quot;forests&quot;, &quot;wetlands&quot;, &quot;waterbodies&quot;) writeRaster(landuse_hrw, &quot;data/processed/landuse/landuse_hrw.tif&quot;, overwrite = TRUE) writeRaster(landuse_dhl, &quot;data/processed/landuse/landuse_dhl.tif&quot;, overwrite = TRUE) By now the resampled land use raster should be very similar to the PPI raster, with the exception of — of course — the values contained within. compareRaster(landuse_hrw, as(ppi_hrw$data, &quot;RasterLayer&quot;), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE) compareRaster(landuse_dhl, as(ppi_dhl$data, &quot;RasterLayer&quot;), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE) ## [1] TRUE ## [1] TRUE Ok, let’s save a copy of what we have so far. saveRDS(landuse_hrw, &quot;data/processed/landuse/landuse_hrw.RDS&quot;) saveRDS(landuse_dhl, &quot;data/processed/landuse/landuse_dhl.RDS&quot;) 3.3 Adding land use classifications to the PPIs With the land use rasters overlapping exactly with the PPIs, we can simply extract the values of the resampled land use rasters and add these as additional parameters to the PPIs. landuse_hrw &lt;- readRDS(&quot;data/processed/landuse/landuse_hrw.RDS&quot;) landuse_dhl &lt;- readRDS(&quot;data/processed/landuse/landuse_dhl.RDS&quot;) values_hrw &lt;- rasterToPoints(landuse_hrw, spatial = TRUE) values_dhl &lt;- rasterToPoints(landuse_dhl, spatial = TRUE) ppi_hrw$data@data &lt;- cbind(ppi_hrw$data@data, values_hrw@data) ppi_dhl$data@data &lt;- cbind(ppi_dhl$data@data, values_dhl@data) 3.4 Calculate distance to nearest urban area We can use the distance to the nearest inhabited urban area as a proxy for disturbance. To calculate this, we reclassify the raster to cells containing inhabited urban area and everything else. For every cell on the raster that is not a cell we have just classified as inhabited urban area, we will calculate the distance (in meters) to the nearest cell classified as inhabited urban area. We classify a PPI cell as uninhabited if the proportion of its constituent cells (at a finer resolution) that is inhabited is &gt; 0.95. dhl_inhabited &lt;- ratify(reclassify(landuse_dhl_reprojected, cbind(landuse_classes$landuse_id, landuse_classes$inhabited)), count = TRUE) hrw_inhabited &lt;- ratify(reclassify(landuse_hrw_reprojected, cbind(landuse_classes$landuse_id, landuse_classes$inhabited)), count = TRUE) dhl_inhabited &lt;- calculate_land_use_proportion(dhl_inhabited, as(ppi_dhl$data, &quot;RasterLayer&quot;), overwrite = TRUE) hrw_inhabited &lt;- calculate_land_use_proportion(hrw_inhabited, as(ppi_hrw$data, &quot;RasterLayer&quot;), overwrite = TRUE) names(dhl_inhabited) &lt;- c(&quot;uninhabited&quot;, &quot;inhabited&quot;) names(hrw_inhabited) &lt;- c(&quot;uninhabited&quot;, &quot;inhabited&quot;) dist_dhl &lt;- dhl_inhabited dist_dhl[dist_dhl$uninhabited &gt; 0.95] &lt;- NA dist_dhl &lt;- distance(dist_dhl$inhabited) dist_hrw &lt;- hrw_inhabited dist_hrw[dist_hrw$uninhabited &gt; 0.95] &lt;- NA dist_hrw &lt;- distance(dist_hrw$inhabited) writeRaster(dist_hrw, &quot;data/processed/landuse/dist_urban_hrw.tif&quot;, overwrite = TRUE) writeRaster(dist_dhl, &quot;data/processed/landuse/dist_urban_dhl.tif&quot;, overwrite = TRUE) And we add these values to the PPIs again. values_dist_hrw &lt;- rasterToPoints(dist_hrw, spatial = TRUE) values_dist_dhl &lt;- rasterToPoints(dist_dhl, spatial = TRUE) ppi_hrw$data@data$dist_urban &lt;- values_dist_hrw@data$layer ppi_dhl$data@data$dist_urban &lt;- values_dist_dhl@data$layer 3.5 Add population density Another proxy for disturbance to explore is simply the number of humans living in a certain area. The Dutch Central Bureau of Statistics (CBS) annually publishes a dataset containing the number of inhabitants organized in 500x500m grid cells. We will now add this to the PPIs as well. cbs_maps &lt;- st_read(&quot;data/raw/population-density/2019-CBS_VK500_2018_v1/CBS_VK500_2018_v1.shp&quot;) ## Reading layer `CBS_VK500_2018_v1&#39; from data source `/mnt/volume_ams3_01/raw/population-density/2019-CBS_VK500_2018_v1/CBS_VK500_2018_v1.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 151108 features and 31 fields ## geometry type: POLYGON ## dimension: XY ## bbox: xmin: 13000 ymin: 306500 xmax: 278500 ymax: 619500 ## proj4string: +proj=sterea +lat_0=52.15616055555555 +lon_0=5.38763888888889 +k=0.9999079 +x_0=155000 +y_0=463000 +ellps=bessel +units=m +no_defs cbs_hrw &lt;- st_transform(cbs_maps, ppi_hrw$data@proj4string) cbs_dhl &lt;- st_transform(cbs_maps, ppi_dhl$data@proj4string) # Template for the rasterization following the standard 500x500m resolution of the CBS grid template_hrw &lt;- st_as_stars(st_bbox(cbs_hrw[&quot;INWONER&quot;]), values = NA_real_, dx = 500, dy = 500) template_dhl &lt;- st_as_stars(st_bbox(cbs_dhl[&quot;INWONER&quot;]), values = NA_real_, dx = 500, dy = 500) # Now rasterize pop_density_rasterized_hrw &lt;- as(st_rasterize(cbs_hrw[&quot;INWONER&quot;], template = template_hrw), &quot;Raster&quot;) pop_density_rasterized_dhl &lt;- as(st_rasterize(cbs_dhl[&quot;INWONER&quot;], template = template_dhl), &quot;Raster&quot;) # Set negative or NA raster values to 0 pop_density_rasterized_hrw[pop_density_rasterized_hrw &lt; 0] &lt;- 0 pop_density_rasterized_dhl[pop_density_rasterized_dhl &lt; 0] &lt;- 0 # Now aggregate by summing up values in cells to &#39;cover&#39; the values that fit in a PPI pixel factor_hrw &lt;- round(dim(pop_density_rasterized_hrw)[1:2] / dim(as(ppi_hrw$data, &quot;RasterLayer&quot;))[1:2]) factor_dhl &lt;- round(dim(pop_density_rasterized_dhl)[1:2] / dim(as(ppi_dhl$data, &quot;RasterLayer&quot;))[1:2]) agg_hrw &lt;- aggregate(pop_density_rasterized_hrw, factor_hrw, na.rm = TRUE, fun = sum) ## Warning in .local(x, ...): all fact(s) were 1, nothing to aggregate agg_dhl &lt;- aggregate(pop_density_rasterized_dhl, factor_dhl, na.rm = TRUE, fun = sum) ## Warning in .local(x, ...): all fact(s) were 1, nothing to aggregate # Resample to make the PPI and CBS population grids line up 1:1 pop_density_rasterized_hrw &lt;- resample(agg_hrw, as(ppi_hrw$data, &quot;RasterLayer&quot;)) pop_density_rasterized_dhl &lt;- resample(agg_dhl, as(ppi_dhl$data, &quot;RasterLayer&quot;)) Once again, verify if the PPI pixels match up exactly with the CBS population grids compareRaster(pop_density_rasterized_hrw, as(ppi_hrw$data, &quot;RasterLayer&quot;), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE) compareRaster(pop_density_rasterized_dhl, as(ppi_dhl$data, &quot;RasterLayer&quot;), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE) ## [1] TRUE ## [1] TRUE Now as a final step we will calculate the total population within the neighborhood surrounding the PPI pixels, to get a more representative measure of disturbance potential in the surrounding area. weights &lt;- matrix(1, nrow = 3, ncol = 3) pop_hrw &lt;- focal(pop_density_rasterized_hrw, w = weights, fun = sum, na.rm = TRUE) pop_dhl &lt;- focal(pop_density_rasterized_dhl, w = weights, fun = sum, na.rm = TRUE) pop_hrw[is.na(pop_hrw)] &lt;- 0 pop_dhl[is.na(pop_dhl)] &lt;- 0 And add it to the PPIs. values_pop_hrw &lt;- rasterToPoints(pop_hrw, spatial = TRUE) values_pop_dhl &lt;- rasterToPoints(pop_dhl, spatial = TRUE) ppi_hrw$data@data$human_pop &lt;- values_pop_hrw@data$layer ppi_dhl$data@data$human_pop &lt;- values_pop_dhl@data$layer And finally we save these PPIs again. saveRDS(ppi_hrw, file = &quot;data/processed/corrected_ppi_hrw_lu.RDS&quot;) saveRDS(ppi_dhl, file = &quot;data/processed/corrected_ppi_dhl_lu.RDS&quot;) 3.5.1 Plotting human parameters on an interactive map We have now generated proxies for fireworks ‘severity’ for later modelling stages. Let’s plot them on an interactive map again for reference. 3.5.1.1 Interactive map of Herwijnen human_parameters &lt;- c(&quot;urban&quot;, &quot;agricultural&quot;, &quot;semiopen&quot;, &quot;forests&quot;, &quot;wetlands&quot;, &quot;waterbodies&quot;, &quot;dist_urban&quot;, &quot;human_pop&quot;) mapview(ppi_hrw$data[, , human_parameters], alpha.regions = 0.6, col.regions = inferno, maxpixels=2000000, na.color = &quot;#00000000&quot;, map.types = c(&quot;CartoDB.Positron&quot;, &quot;CartoDB.DarkMatter&quot;, &quot;Esri.WorldImagery&quot;), layer.name = human_parameters) 3.5.1.2 Interactive map of Den Helder mapview(ppi_dhl$data[, , human_parameters], alpha.regions = 0.6, col.regions = inferno, maxpixels=2000000, na.color = &quot;#00000000&quot;, map.types = c(&quot;CartoDB.Positron&quot;, &quot;CartoDB.DarkMatter&quot;, &quot;Esri.WorldImagery&quot;), layer.name = human_parameters) "],
["04.Annotate-count-areas.html", "4 Annotating count areas 4.1 Processing environment 4.2 Annotate PPIs with waterbird area codes 4.3 Annotate PPIs with point-transect-counts", " 4 Annotating count areas We have data for the following counts provided by Sovon: Waterbird counts with a shapefile containing the surveyed areas and an xlsx file with the count results. Both can be linked using the identifiers contained in both datasets. PTT counts, or point transect counts, contained within an xlsx file with the routes and all bird observations at an \\((X, Y)\\) location. To make processing efficient, we will ‘annotate’ the PPIs with the corresponding area codes for the waterbird counts and some identifier for the PTT counts. Doing so, we can later on calculate relevant count-based parameters (e.g. bird biomass, etc.) and ‘join’ these by the corresponding identifiers. 4.1 Processing environment library(bioRad) library(sf) library(stars) library(raster) library(dplyr) library(tidyr) library(readr) library(stringr) library(readxl) library(ggplot2) library(viridis) library(fasterize) ppi_hrw &lt;- readRDS(&quot;data/processed/corrected_ppi_hrw_lu.RDS&quot;) ppi_dhl &lt;- readRDS(&quot;data/processed/corrected_ppi_dhl_lu.RDS&quot;) 4.2 Annotate PPIs with waterbird area codes We rename the veriables retained in the shapefile to English and add a numerical wb_area_id which we can use to link the information retained in the shapefiles with the rasterized waterbird areas. All shapefiles are transformed to the CRS of the PPIs. wb_areas &lt;- st_read(&quot;data/raw/sovon/wavo_telgebieden.shp&quot;) %&gt;% rename(wb_area_nr = GEBIEDNR, wb_area_ha = OPPHA, xcoor = XCOOR, ycoor = YCOOR) wb_areas$wb_area_id &lt;- seq(1, length(wb_areas$wb_area_nr)) wb_areas_hrw &lt;- st_transform(wb_areas, ppi_hrw$data@proj4string) wb_areas_dhl &lt;- st_transform(wb_areas, ppi_dhl$data@proj4string) ## Reading layer `wavo_telgebieden&#39; from data source `/mnt/volume_ams3_01/raw/sovon/wavo_telgebieden.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 4131 features and 4 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: 13551.48 ymin: 307546.8 xmax: 278027 ymax: 622790 ## proj4string: +proj=sterea +lat_0=52.15616055555555 +lon_0=5.38763888888889 +k=0.9999079 +x_0=155000 +y_0=463000 +ellps=bessel +units=m +no_defs We rasterize specifically the newly created wb_area_id (as this is already a numerical and not categorical value like wb_area_nr) following the ‘template’ of the existing PPIs. tpl_hrw &lt;- st_as_stars(st_bbox(ppi_hrw$data), dx = ppi_hrw$data@grid@cellsize[1], dy = ppi_hrw$data@grid@cellsize[2], values = NA_real_) tpl_dhl &lt;- st_as_stars(st_bbox(ppi_dhl$data), dx = ppi_dhl$data@grid@cellsize[1], dy = ppi_dhl$data@grid@cellsize[2], values = NA_real_) wb_areas_rasterized_hrw &lt;- st_rasterize(wb_areas_hrw[&quot;wb_area_id&quot;], template = tpl_hrw) wb_areas_rasterized_dhl &lt;- st_rasterize(wb_areas_dhl[&quot;wb_area_id&quot;], template = tpl_dhl) Let’s see how that’s gone so far. par(pty = &quot;s&quot;, mfrow = c(1, 2)) plot(wb_areas_rasterized_hrw, main = &quot;Herwijnen: wb_area_id&quot;) plot(wb_areas_rasterized_dhl, main = &quot;Den Helder: wb_area_id&quot;) Visually that seems to have gone well, now let’s make sure the rasterized waterbird areas share the same grid as the PPI ‘rasters’. compareRaster(as(wb_areas_rasterized_hrw, &quot;Raster&quot;), as(ppi_hrw$data, &quot;RasterLayer&quot;), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE) compareRaster(as(wb_areas_rasterized_dhl, &quot;Raster&quot;), as(ppi_dhl$data, &quot;RasterLayer&quot;), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE) ## [1] TRUE ## [1] TRUE Twice a TRUE, so the rasters are identical (except for the values), so we can merge the datasets using a join on the wb_area_id. # Add the wb_area_id to the PPIs ppi_hrw$data$wb_area_id &lt;- unlist(as.data.frame(as(wb_areas_rasterized_hrw, &quot;Raster&quot;))) ppi_dhl$data$wb_area_id &lt;- unlist(as.data.frame(as(wb_areas_rasterized_dhl, &quot;Raster&quot;))) # Join the additional contents of the shapefiles ppi_hrw$data@data %&gt;% left_join(dplyr::select(as.data.frame(wb_areas_hrw), wb_area_id, wb_area_nr, wb_area_ha), by = c(&quot;wb_area_id&quot; = &quot;wb_area_id&quot;)) -&gt; ppi_hrw$data@data ppi_hrw$data$geometry &lt;- NULL ppi_dhl$data@data %&gt;% left_join(dplyr::select(as.data.frame(wb_areas_dhl), wb_area_id, wb_area_nr, wb_area_ha), by = c(&quot;wb_area_id&quot; = &quot;wb_area_id&quot;)) -&gt; ppi_dhl$data@data ppi_dhl$data$geometry &lt;- NULL Let’s verify if that occurred as planned. plot(ppi_hrw, param = &quot;wb_area_id&quot;, zlim = c(min(ppi_hrw$data@data$wb_area_id, na.rm = TRUE), max(ppi_hrw$data@data$wb_area_id, na.rm = TRUE))) plot(ppi_dhl, param = &quot;wb_area_id&quot;, zlim = c(min(ppi_dhl$data@data$wb_area_id, na.rm = TRUE), max(ppi_dhl$data@data$wb_area_id, na.rm = TRUE))) This looks very comparable to the plots of the rasterized scans above and wb_area_id shows similar areas in similar colors, so this worked fine. 4.3 Annotate PPIs with point-transect-counts The PTT point transect counts are organized by routes, which consist of a few points along a transect/route. We can follow the same approach as above with the waterbird counts, by first creating coverage shapes (like the shapefile features for the waterbird areas) for each of the routes. Using the convex hull of the points within a route seems like a good starting point to convert these points to areas. However, in that case it would appear as if birds are only counted when looking ‘inwards’ to this shape. By buffering these convex hulls with a radius of the average distance between successive points, a more representative coverage area can be generated that generalises well across landscapes (e.g. the area covered in a dense forest would tend to be smaller than in open agricultural areas). 4.3.1 Loading PTT points We load the PTT data directly from the xlsx file provided by Sovon and rename the variables to English. ptt &lt;- read_excel(&quot;data/raw/sovon/tel_dec_jan_1718.xlsx&quot;, sheet = &quot;ptt&quot;) %&gt;% rename(count_id = tellingid, route = route, count_point = telpunt, season = seizoen, year = teljaar, month = maand, day = dag, species = soort, number = aantal) head(ptt, 10) count_id route count_point season year month day euring species number xcoor ycoor 80917 4 1 2017 2017 12 23 720 Aalscholver 2 246342 520763 80917 4 1 2017 2017 12 23 5920 Zilvermeeuw 18 246342 520763 80917 4 1 2017 2017 12 23 6700 Houtduif 1 246342 520763 80917 4 1 2017 2017 12 23 11870 Merel 4 246342 520763 80917 4 1 2017 2017 12 23 15630 Roek 24 246342 520763 80917 4 2 2017 2017 12 23 6700 Houtduif 1 246357 522178 80917 4 2 2017 2017 12 23 11870 Merel 1 246357 522178 80917 4 2 2017 2017 12 23 15600 Kauw 6 246357 522178 80917 4 2 2017 2017 12 23 15630 Roek 78 246357 522178 80917 4 3 2017 2017 12 23 14620 Pimpelmees 2 246692 523139 As we’re not interested in all the data here, we will load a subset of the columns, specifically all unique combinations of routes and points, which will yield the corresponding xcoor and ycoor coordinates for each count_point within a route. ptt %&gt;% dplyr::select(route, count_point, xcoor, ycoor) %&gt;% group_by(route, count_point) %&gt;% slice(1) -&gt; ptt head(ptt, 10) route count_point xcoor ycoor 4 1 246342 520763 4 2 246357 522178 4 3 246692 523139 4 4 248122 522563 4 5 248249 521818 4 6 248649 523073 4 7 249142 523614 4 8 250073 523534 4 9 252142 523524 4 10 253056 523458 4.3.2 Calculate interpoint distances For each of the routes within the PTT dataset, we will calculate the average distance between the subsequent points, to buffer our convex hull by this value. ptt %&gt;% group_by(route) %&gt;% mutate(xcoor2 = c(xcoor[-1], 0), ycoor2 = c(ycoor[-1], 0)) %&gt;% rowwise() %&gt;% mutate(interpoint_distance = pointDistance(cbind(xcoor, ycoor), cbind(xcoor2, ycoor2), lonlat = FALSE)) %&gt;% ungroup() %&gt;% filter(xcoor2 != 0) %&gt;% # Throw out last point from route where distance to next point is not relevant group_by(route) %&gt;% summarise(avg_interpoint_distance = mean(interpoint_distance), .groups = &quot;keep&quot;) -&gt; ptt_interpoint_distances ptt %&gt;% left_join(ptt_interpoint_distances, by = c(&quot;route&quot; = &quot;route&quot;)) -&gt; ptt head(ptt, 10) route count_point xcoor ycoor avg_interpoint_distance 4 1 246342 520763 1162.042 4 2 246357 522178 1162.042 4 3 246692 523139 1162.042 4 4 248122 522563 1162.042 4 5 248249 521818 1162.042 4 6 248649 523073 1162.042 4 7 249142 523614 1162.042 4 8 250073 523534 1162.042 4 9 252142 523524 1162.042 4 10 253056 523458 1162.042 We can now calculate the convex hulls of the points grouped by route. ptt %&gt;% ungroup() %&gt;% st_as_sf(coords = c(&quot;xcoor&quot;, &quot;ycoor&quot;), crs = 28992) %&gt;% # original CRS = EPSG:28992 (RD New) st_transform(crs = ppi_hrw$data@proj4string) %&gt;% group_by(route, avg_interpoint_distance) %&gt;% summarise(.groups = &quot;drop&quot;) %&gt;% st_convex_hull() %&gt;% st_as_sf() -&gt; ptt_convex_hulls_hrw # Somehow it&#39;s necessary to reconvert to sf? ptt %&gt;% ungroup() %&gt;% st_as_sf(coords = c(&quot;xcoor&quot;, &quot;ycoor&quot;), crs = 28992) %&gt;% st_transform(crs = ppi_dhl$data@proj4string) %&gt;% group_by(route, avg_interpoint_distance) %&gt;% summarise(.groups = &quot;drop&quot;) %&gt;% st_convex_hull() %&gt;% st_as_sf() -&gt; ptt_convex_hulls_dhl plot(ptt_convex_hulls_hrw[1], main = &quot;PTT Routes Herwijnen: Route&quot;) plot(ptt_convex_hulls_hrw[2], main = &quot;PTT Routes Herwijnen: Avg interpoint dist.&quot;) plot(ptt_convex_hulls_dhl[1], main = &quot;PTT Routes Den Helder: Route&quot;) plot(ptt_convex_hulls_dhl[2], main = &quot;PTT Routes Den Helder: Avg interpoint dist.&quot;) As we have calculated the average distance between the points, we can now buffer the convex hulls by this value to attain more representative sizes of the covered areas. ptt_convex_hulls_hrw %&gt;% st_buffer(dist = as.double(ptt_convex_hulls_hrw$avg_interpoint_distance)) -&gt; ptt_convex_hulls_hrw ptt_convex_hulls_dhl %&gt;% st_buffer(dist = as.double(ptt_convex_hulls_dhl$avg_interpoint_distance)) -&gt; ptt_convex_hulls_dhl st_write(ptt_convex_hulls_hrw, &quot;data/processed/sovon/ptt_convex_hulls_hrw.shp&quot;, delete_dsn = TRUE) st_write(ptt_convex_hulls_dhl, &quot;data/processed/sovon/ptt_convex_hulls_dhl.shp&quot;, delete_dsn = TRUE) plot(ptt_convex_hulls_hrw[1], main = &quot;Buffered PTT Routes Herwijnen&quot;) plot(ptt_convex_hulls_dhl[1], main = &quot;Buffered PTT Routes Den Helder&quot;) ## Deleting source `data/processed/sovon/ptt_convex_hulls_hrw.shp&#39; using driver `ESRI Shapefile&#39; ## Writing layer `ptt_convex_hulls_hrw&#39; to data source `data/processed/sovon/ptt_convex_hulls_hrw.shp&#39; using driver `ESRI Shapefile&#39; ## Writing 591 features with 2 fields and geometry type Polygon. ## Deleting source `data/processed/sovon/ptt_convex_hulls_dhl.shp&#39; using driver `ESRI Shapefile&#39; ## Writing layer `ptt_convex_hulls_dhl&#39; to data source `data/processed/sovon/ptt_convex_hulls_dhl.shp&#39; using driver `ESRI Shapefile&#39; ## Writing 591 features with 2 fields and geometry type Polygon. Now that is taken care of, we can rasterize the polygons using the fasterize package. As there is overlap between the areas covered by the routes using the convex hulls and a raster can only contain a single value for every pixel, we need to resolve this overlap. In this case we will compare overlapping areas and pick those where the average distance between the points for that area is lowest. This biases towards counts that cover a smaller area, so probably resulting in more accurate estimates of birds around. ptt_hrw &lt;- raster(ppi_hrw$data) ptt_dhl &lt;- raster(ppi_dhl$data) ptt_hrw &lt;- fasterize(ptt_convex_hulls_hrw, ptt_hrw, field = &quot;route&quot;, by = &quot;avg_interpoint_distance&quot;) ptt_dhl &lt;- fasterize(ptt_convex_hulls_dhl, ptt_dhl, field = &quot;route&quot;, by = &quot;avg_interpoint_distance&quot;) ptt_hrw &lt;- suppressWarnings(stackApply(ptt_hrw, indices = rep(1, length(ptt_hrw)), fun = min, na.rm = TRUE)) ptt_dhl &lt;- suppressWarnings(stackApply(ptt_dhl, indices = rep(1, length(ptt_dhl)), fun = min, na.rm = TRUE)) plot(ptt_hrw, main = &quot;Rasterized PTT routes Herwijnen&quot;) plot(ptt_dhl, main = &quot;Rasterized PTT routes Den Helder&quot;) With the rasterization done, let’s compare the resultant raster and see if it is identical to the PPIs. compareRaster(as(ptt_hrw, &quot;Raster&quot;), as(ppi_hrw$data, &quot;RasterLayer&quot;), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE) compareRaster(as(ptt_dhl, &quot;Raster&quot;), as(ppi_dhl$data, &quot;RasterLayer&quot;), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE) ## [1] TRUE ## [1] TRUE Two TRUEs, so that’s excellent. We can now add the ptt_route to the PPIs. ppi_hrw$data$ptt_route &lt;- unlist(as.data.frame(as(ptt_hrw, &quot;Raster&quot;))) ppi_dhl$data$ptt_route &lt;- unlist(as.data.frame(as(ptt_dhl, &quot;Raster&quot;))) Let’s verify once again if that occurred as planned. plot(ppi_hrw, param = &quot;ptt_route&quot;, zlim = c(min(ppi_hrw$data@data$ptt_route, na.rm = TRUE), max(ppi_hrw$data@data$ptt_route, na.rm = TRUE))) plot(ppi_dhl, param = &quot;ptt_route&quot;, zlim = c(min(ppi_dhl$data@data$ptt_route, na.rm = TRUE), max(ppi_dhl$data@data$ptt_route, na.rm = TRUE))) That seems fine, we can now save the PPIs, so we can start linking actual count data. saveRDS(ppi_hrw, file = &quot;data/processed/corrected-ppis-lu-sovon/corrected_ppi_hrw_lu_sovon.RDS&quot;) saveRDS(ppi_dhl, file = &quot;data/processed/corrected-ppis-lu-sovon/corrected_ppi_dhl_lu_sovon.RDS&quot;) "],
["05.Processing-count-results.html", "5 Processing count results 5.1 Processing environment 5.2 Loading the Sovon count data 5.3 Filtering/preprocessing species names 5.4 Adding vernacular family names 5.5 Linking life-history traits to species 5.6 Calculating total bird biomass 5.7 Calculating proportions across bird families", " 5 Processing count results For now, we are interested in calculating the following parameters for the count results: The number of birds within every PPI pixel. The average mass of the birds within every PPI pixel. We can derive the total numbers of birds comparatively easily from the bird counts by Sovon, but to calculate the average mass of the birds we need to link a database of life-history traits. For the latter we first need to translate the vernacular (modern) names of bird species (used by Sovon) to the scientific ones, so we can link both. 5.1 Processing environment library(rgbif) library(stringr) library(readxl) library(dplyr) library(tidyr) library(readr) library(kableExtra) 5.2 Loading the Sovon count data The count data is spread over a few sheets in an xlsx file, which we load here. For clarity, we rename all the columns to English and we filter out all counts (i.e. areas) where birds are not positively identified to species level. Although it would be possible to ‘fill’ these uncertain counts based on proportions, determining how to do that is not necessary for our purposes. Instead, we will just remove these counts altogether. Finally, subspecies identifiers for these species are removed, as we assume variation is limited and the database of life-history traits does not contain parameters for subspecies separately. sovon_data &lt;- &quot;data/raw/sovon/tel_dec_jan_1718.xlsx&quot; data &lt;- data.frame() sheets &lt;- excel_sheets(sovon_data) sheets &lt;- sheets[-c(1, 5)] # Sheet 1 and 5 contain PTT and roost counts respectively, so we ignore these for now, as they have to be processed differently # Explicit column types to suppress warnings thrown because of lacking euring codes for records with no birds coltypes &lt;- c(&quot;numeric&quot;, &quot;text&quot;, &quot;numeric&quot;, &quot;numeric&quot;, &quot;numeric&quot;, &quot;numeric&quot;, &quot;numeric&quot;, &quot;numeric&quot;, &quot;text&quot;, &quot;numeric&quot;, &quot;numeric&quot;, &quot;numeric&quot;) for (i in seq_along(sheets)) { data &lt;- rbind(data, read_excel(sovon_data, sheet = sheets[i], col_types = coltypes)) } data %&gt;% drop_na() %&gt;% # A few rows somehow contain no birds or species &#39;geen vogels&#39; rename(count_id = TELLING_ID, area_nr = GEBIEDSCODE, year = JAAR, month = MAAND, day = DAG, start_time = BEGINTIJD, end_time = EINDTIJD, &quot;euring&quot; = &quot;EURING&quot;, species = SOORT, number = Aantal, xcoor = XCOOR, ycoor = YCOOR) %&gt;% group_by(area_nr) %&gt;% filter(!any(str_ends(species, &quot;spec.&quot;))) %&gt;% # Filter out all counts with unidentified birds filter(!any(length(str_subset(species, &quot; of &quot;)) &gt; 0)) %&gt;% # Filter out all counts with either/or totals filter(!any(str_starts(species, &quot;hybride&quot;))) %&gt;% # Filter out all counts with hybrids ungroup() %&gt;% rowwise() %&gt;% mutate(species = str_split(species, &quot;\\\\(&quot;)[[1]][1] %&gt;% str_trim()) -&gt; wb_data # And remove all subspecies identifications head(wb_data, 10) %&gt;% kable(format = &quot;html&quot;, col.names = colnames(wb_data)) %&gt;% kable_styling() %&gt;% kableExtra::scroll_box(width = &quot;100%&quot;, height = &quot;400px&quot;) count_id area_nr year month day start_time end_time euring species number xcoor ycoor 1060908 BR1111 2017 12 19 1045 1108 1610 Grauwe Gans 280 127723 426233 1060908 BR1111 2017 12 19 1045 1108 1700 Nijlgans 2 127723 426233 1060909 BR1112 2017 12 19 1108 1126 1610 Grauwe Gans 76 125082 426701 1060909 BR1112 2017 12 19 1108 1126 1661 Grote Canadese Gans 50 125082 426701 1060909 BR1112 2017 12 19 1108 1126 1700 Nijlgans 22 125082 426701 1060906 BR1122 2017 12 19 1020 1037 1610 Grauwe Gans 250 125313 426061 1060906 BR1122 2017 12 19 1020 1037 1619 Soepgans 5 125313 426061 1060906 BR1122 2017 12 19 1020 1037 1661 Grote Canadese Gans 35 125313 426061 1060911 BR1130 2017 12 19 1145 1200 1610 Grauwe Gans 200 121962 426420 1060911 BR1130 2017 12 19 1145 1200 1661 Grote Canadese Gans 40 121962 426420 Following this logic, we can process the PTT counts similarly and see which species are contained in those. read_excel(sovon_data, sheet = 1) %&gt;% rename(count_id = tellingid, route = route, count_point = telpunt, season = seizoen, year = teljaar, month = maand, day = dag, euring = euring, species = soort, number = aantal, xcoor = xcoor, ycoor = ycoor) %&gt;% group_by(route, count_point) %&gt;% filter(!any(str_ends(species, &quot;spec.&quot;))) %&gt;% # Filter out all counts with unidentified birds filter(!any(length(str_subset(species, &quot; of &quot;)) &gt; 0)) %&gt;% # Filter out all counts with either/or totals filter(!any(str_starts(species, &quot;hybride&quot;))) %&gt;% # Filter out all counts with hybrids ungroup() %&gt;% rowwise() %&gt;% mutate(species = str_split(species, &quot;\\\\(&quot;)[[1]][1] %&gt;% str_trim()) -&gt; ptt_data # And remove all subspecies identifications head(ptt_data, 10) %&gt;% kable(format = &quot;html&quot;, col.names = colnames(ptt_data)) %&gt;% kable_styling() %&gt;% kableExtra::scroll_box(width = &quot;100%&quot;, height = &quot;400px&quot;) count_id route count_point season year month day euring species number xcoor ycoor 80917 4 1 2017 2017 12 23 720 Aalscholver 2 246342 520763 80917 4 1 2017 2017 12 23 5920 Zilvermeeuw 18 246342 520763 80917 4 1 2017 2017 12 23 6700 Houtduif 1 246342 520763 80917 4 1 2017 2017 12 23 11870 Merel 4 246342 520763 80917 4 1 2017 2017 12 23 15630 Roek 24 246342 520763 80917 4 2 2017 2017 12 23 6700 Houtduif 1 246357 522178 80917 4 2 2017 2017 12 23 11870 Merel 1 246357 522178 80917 4 2 2017 2017 12 23 15600 Kauw 6 246357 522178 80917 4 2 2017 2017 12 23 15630 Roek 78 246357 522178 80917 4 3 2017 2017 12 23 14620 Pimpelmees 2 246692 523139 5.3 Filtering/preprocessing species names The following section is the result of an iterative process aimed at matching species in our count data with species in the database of life-history characteristics. Unfortunately, automatic tools only get us so far, a bit of tweaking has to be done by hand. To reduce manual corrections needed, only species to which &gt;1% of the birds belong in a single count have been corrected manually. In other words: if a species which cannot be matched always accounts for less than 1% of the total number of birds within a count, this species is discarded from the whole dataset. Besides the 1% criteria, both the waterbird and PTT counts contain some exotics (e.g. ‘Helmparelhoen’/Helmeted guineafowl) for which our life-history characteristics dataset does not contain any measurements anyways (there are others that we do have measurements of), some species that are very unlikely to ever take flight during NYE (e.g. ‘Kip’/Domesticated chicken) and some mammals for which the same applies. We will remove these from the dataset manually. exotics &lt;- c(&quot;Helmparelhoen&quot;, &quot;Kaapse Casarca&quot;, &quot;Manengans&quot;, &quot;Ringtaling&quot;, &quot;Buffelkopeend&quot;, &quot;Kokardezaagbek&quot;, &quot;Chileense Flamingo&quot;, &quot;Kaapse Taling&quot;, &quot;Bahamapijlstaart&quot;, &quot;Muskuseend&quot;, &quot;Zwarte Zwaan&quot;, &quot;Knobbelgans&quot;, &quot;Zwaangans&quot;) unlikely_flight_candidate &lt;- c(&quot;Kip&quot;) mammals &lt;- c(&quot;Damhert&quot;, &quot;Haas&quot;, &quot;Ree&quot;, &quot;Bever&quot;, &quot;Bruine Rat&quot;, &quot;Muskusrat&quot;, &quot;Mol&quot;, &quot;Vos&quot;, &quot;Kat&quot;, &quot;Otter&quot;, &quot;Grijze Zeehond&quot;, &quot;Konijn&quot;, &quot;Eekhoorn&quot;, &quot;Edelhert&quot;, &quot;Gewone Zeehond&quot;, &quot;Wild Zwijn&quot;, &quot;Steenmarter&quot;, &quot;Moeflon&quot;) input_error &lt;- c(&quot;Steltstrandloper&quot;) remove_species &lt;- c(exotics, unlikely_flight_candidate, mammals, input_error) ptt_data %&gt;% filter(!species %in% remove_species) -&gt; ptt_data wb_data %&gt;% filter(!species %in% remove_species) -&gt; wb_data With all these species removed or adjusted, we can create a species lookup table. We fetch the scientific names and corresponding GBIF species IDs from the Checklist Dutch Species Register, which is the GBIF dataset with key 4dd32523-a3a3-43b7-84df-4cda02f15cf7. We furthermore remove all unnecessary information, such as subspecies from the scientific names as well. unique_species &lt;- unique(c(wb_data$species, ptt_data$species)) build_species_lut &lt;- function(specieslist, datasetKey = NULL, class_name = NULL) { # As this function can possibly return many different records, we pick the scientific name and GBIF ID (nubKey) that are the most # common in the returned results. This should most often result in an OK result of the name lookup function. Mode &lt;- function(x) { ux &lt;- unique(na.omit(x)) ux[which.max(tabulate(match(x, ux)))] } n &lt;- length(specieslist) species_lut &lt;- data.frame(lookupname = character(n), scientificname = character(n), gbif_key = numeric(n), stringsAsFactors = FALSE) # Somehow the higherTaxonKey changes regularly, so we have to query this first higherTaxonKey &lt;- NULL if (!is.null(class_name)) { class_record &lt;- name_lookup(class_name, datasetKey = datasetKey) higherTaxonKey &lt;- class_record$data$classKey } for(i in seq_along(specieslist)) { gbif_data &lt;- tryCatch({ gbif &lt;- name_lookup(specieslist[i], datasetKey = datasetKey, higherTaxonKey = higherTaxonKey, return = &quot;data&quot;) list(paste(str_split(Mode(gbif$scientificName), pattern = &quot; &quot;)[[1]][1:2], collapse = &quot; &quot;), Mode(gbif$nubKey)) }, error = function(e) { list(&quot;&quot;, NaN) }) species_lut[i, ] &lt;- c(specieslist[i], gbif_data[1], as.numeric(as.character(gbif_data[2]))) } return(species_lut) } species_lut &lt;- build_species_lut(unique_species, datasetKey = &quot;4dd32523-a3a3-43b7-84df-4cda02f15cf7&quot;, class_name = &quot;Aves&quot;) ## Warning: Unknown or uninitialised column: `scientificName`. head(species_lut, 10) %&gt;% kable(format = &quot;html&quot;, col.names = colnames(species_lut)) %&gt;% kable_styling() %&gt;% kableExtra::scroll_box(width = &quot;100%&quot;, height = &quot;400px&quot;) lookupname scientificname gbif_key Grauwe Gans Anser anser 2498036 Nijlgans Alopochen aegyptiaca 2498252 Grote Canadese Gans Branta canadensis 5232437 Soepgans Anser anser 9384117 Brandgans Branta leucopsis 5232464 Knobbelzwaan Cygnus olor 2498343 Kolgans Anser albifrons 2498017 Canadese Gans Branta hutchinsii 5232460 Toendrarietgans Anser serrirostris 9455781 Kleine Zwaan Cygnus bewickii 4409105 Finally, the lookup table also contains some scientific names which unfortunately will not match with the life-history characteristics dataset, so these too we will adjust manually. # Change to similar species which is in the LHT database species_lut[species_lut$lookupname == &quot;Toendrarietgans&quot;, &quot;scientificname&quot;] &lt;- &quot;Anser fabalis&quot; # Taiga Bean Goose species_lut[species_lut$lookupname == &quot;Kleine Canadese Gans&quot;, &quot;scientificname&quot;] &lt;- &quot;Branta leucopsis&quot; # Barnacle Goose species_lut[species_lut$lookupname == &quot;Kleine Barmsijs&quot;, &quot;scientificname&quot;] &lt;- &quot;Acanthis flammea&quot; # Redpoll species_lut[species_lut$lookupname == &quot;Pontische Meeuw&quot;, &quot;scientificname&quot;] &lt;- &quot;Larus argentatus&quot; # Herring Gull species_lut[species_lut$lookupname == &quot;Indische Gans&quot;, &quot;scientificname&quot;] &lt;- &quot;Anser albifrons&quot; # Greater White-fronted Goose species_lut[species_lut$lookupname == &quot;Canadese Gans&quot;, &quot;scientificname&quot;] &lt;- &quot;Branta canadensis&quot; # Canada Goose # Change scientific name for same species to match with the LHT database species_lut[species_lut$lookupname == &quot;Kleine Zwaan&quot;, &quot;scientificname&quot;] &lt;- &quot;Cygnus columbianus&quot; # Bewick&#39;s Swan species_lut[species_lut$lookupname == &quot;Kokmeeuw&quot;, &quot;scientificname&quot;] &lt;- &quot;Larus ridibundus&quot; # Black-headed Gull species_lut[species_lut$lookupname == &quot;Smient&quot;, &quot;scientificname&quot;] &lt;- &quot;Mareca penelope&quot; # Wigeon species_lut[species_lut$lookupname == &quot;Krakeend&quot;, &quot;scientificname&quot;] &lt;- &quot;Mareca strepera&quot; # Gadwall species_lut[species_lut$lookupname == &quot;Slobeend&quot;, &quot;scientificname&quot;] &lt;- &quot;Spatula clypeata&quot; # Northern Shoveler species_lut[species_lut$lookupname == &quot;Winterkoning&quot;, &quot;scientificname&quot;] &lt;- &quot;Troglodytes troglodytes&quot; # Wren species_lut[species_lut$lookupname == &quot;Grote Jager&quot;, &quot;scientificname&quot;] &lt;- &quot;Catharacta skua&quot; # Great Skua species_lut[species_lut$lookupname == &quot;Roodborsttapuit&quot;, &quot;scientificname&quot;] &lt;- &quot;Saxicola torquatus&quot; # Stonechat species_lut[species_lut$lookupname == &quot;Strandleeuwerik&quot;, &quot;scientificname&quot;] &lt;- &quot;Eremophila alpestris&quot; # Horned Lark 5.4 Adding vernacular family names Fetching vernacular names of scientific families from GBIF is even more convoluted than the name lookup we have done above, so instead we have manually derived a list of vernacular names for families based on the generated species lookup table. read_delim(&quot;data/raw/sovon/familyvernacular_lut.csv&quot;, delim = &quot;;&quot;, col_types = cols(lookupname = col_character(), familyvernacular = col_character())) %&gt;% right_join(species_lut, by = &quot;lookupname&quot;) -&gt; species_lut 5.5 Linking life-history traits to species We use the Life-history characteristics of European birds-dataset (Storchová and Hořák 2018) to calculate the mean mass of all birds in a PPI pixel. This dataset is stored on Dryad and we can download it there. Unfortunately at the time of writing the rdryad package is severely out-of-date with the new Dryad API, so we cannot nicely automate this download yet. Anyways, the files should be downloaded manually and added to data/raw/life-history-characteristics/. We calculate the mean of the mass of both sexed and unsexed birds and assume that represents the mean mass for a species. read_tsv(&quot;data/raw/life-history-characteristics/Life-history characteristics of European birds.txt&quot;, col_types = cols_only(&#39;Species&#39; = col_character(), &#39;WeightU_MEAN&#39; = col_double(), &#39;WeightM_MEAN&#39; = col_double(), &#39;WeightF_MEAN&#39; = col_double())) %&gt;% rowwise %&gt;% mutate(mean_weight = mean(c(WeightU_MEAN, WeightF_MEAN, WeightM_MEAN))) %&gt;% dplyr::select(Species, mean_weight) %&gt;% rename(species = Species) %&gt;% filter(!any(str_ends(species, &quot;ssp&quot;))) %&gt;% # Filter out birds not identified to species rowwise() %&gt;% mutate(species = paste(str_split(species, pattern = &quot; &quot;)[[1]][1:2], collapse = &quot; &quot;)) %&gt;% ungroup() %&gt;% group_by(species) %&gt;% summarise(mean_weight = mean(mean_weight), .groups = &quot;drop_last&quot;) %&gt;% drop_na() -&gt; lhc lhc[lhc$species == &quot;Aquila nipalenis&quot;, &quot;species&quot;] &lt;- &quot;Aquila nipalensis&quot; # Small error in dataset -&gt; notified author head(lhc, 10) %&gt;% kable(format = &quot;html&quot;, col.names = colnames(lhc)) %&gt;% kable_styling() %&gt;% kableExtra::scroll_box(width = &quot;100%&quot;, height = &quot;400px&quot;) species mean_weight Acanthis flammea 13.40 Accipiter brevipes 221.50 Accipiter gentilis 931.50 Accipiter nisus 204.00 Acridotheres cristatellus 124.35 Acridotheres tristis 124.35 Acrocephalus agricola 10.50 Acrocephalus arundinaceus 30.30 Acrocephalus dumetorum 12.00 Acrocephalus melanopogon 11.70 Now we can try to link the names once again with what can be found in GBIF. unique_species_lhc &lt;- unique(lhc$species) lhc_species_lut &lt;- build_species_lut(unique_species_lhc, dataset = NULL) head(lhc_species_lut, 10) %&gt;% kable(format = &quot;html&quot;, col.names = colnames(lhc_species_lut)) %&gt;% kable_styling() %&gt;% kableExtra::scroll_box(width = &quot;100%&quot;, height = &quot;400px&quot;) lookupname scientificname gbif_key Acanthis flammea Acanthis flammea 5231630 Accipiter brevipes Accipiter brevipes 2480578 Accipiter gentilis Accipiter gentilis 2480589 Accipiter nisus Accipiter nisus 2480637 Acridotheres cristatellus Acridotheres cristatellus 2489010 Acridotheres tristis Acridotheres tristis 2489005 Acrocephalus agricola Acrocephalus agricola 2493137 Acrocephalus arundinaceus Acrocephalus arundinaceus 2493128 Acrocephalus dumetorum Acrocephalus dumetorum 2493145 Acrocephalus melanopogon Acrocephalus melanopogon 2493124 With the GBIF IDs/keys in place for both the life-history characteristics, as well as the Sovon counts, we can now link the datasets together. We start with the waterbirds. lhc %&gt;% left_join(lhc_species_lut, by = c(&quot;species&quot; = &quot;scientificname&quot;)) %&gt;% dplyr::select(species, mean_weight, gbif_key) -&gt; lhc wb_data %&gt;% left_join(species_lut, by = c(&quot;species&quot; = &quot;lookupname&quot;)) %&gt;% left_join(dplyr::select(lhc, mean_weight, gbif_key), by = c(&quot;gbif_key&quot; = &quot;gbif_key&quot;)) %&gt;% left_join(dplyr::select(lhc, mean_weight, species), by = c(&quot;scientificname&quot; = &quot;species&quot;)) %&gt;% dplyr::select(-c(mean_weight.x)) %&gt;% rename(mean_weight = mean_weight.y) -&gt; wb_data_lhc head(wb_data_lhc, 10) %&gt;% kable(format = &quot;html&quot;, col.names = colnames(wb_data_lhc)) %&gt;% kable_styling() %&gt;% kableExtra::scroll_box(width = &quot;100%&quot;, height = &quot;400px&quot;) count_id area_nr year month day start_time end_time euring species number xcoor ycoor familyvernacular scientificname gbif_key mean_weight 1060908 BR1111 2017 12 19 1045 1108 1610 Grauwe Gans 280 127723 426233 Geese Anser anser 2498036 3347 1060908 BR1111 2017 12 19 1045 1108 1700 Nijlgans 2 127723 426233 Geese Alopochen aegyptiaca 2498252 2270 1060909 BR1112 2017 12 19 1108 1126 1610 Grauwe Gans 76 125082 426701 Geese Anser anser 2498036 3347 1060909 BR1112 2017 12 19 1108 1126 1661 Grote Canadese Gans 50 125082 426701 Geese Branta canadensis 5232437 4635 1060909 BR1112 2017 12 19 1108 1126 1700 Nijlgans 22 125082 426701 Geese Alopochen aegyptiaca 2498252 2270 1060906 BR1122 2017 12 19 1020 1037 1610 Grauwe Gans 250 125313 426061 Geese Anser anser 2498036 3347 1060906 BR1122 2017 12 19 1020 1037 1619 Soepgans 5 125313 426061 Geese Anser anser 9384117 3347 1060906 BR1122 2017 12 19 1020 1037 1661 Grote Canadese Gans 35 125313 426061 Geese Branta canadensis 5232437 4635 1060911 BR1130 2017 12 19 1145 1200 1610 Grauwe Gans 200 121962 426420 Geese Anser anser 2498036 3347 1060911 BR1130 2017 12 19 1145 1200 1661 Grote Canadese Gans 40 121962 426420 Geese Branta canadensis 5232437 4635 And then the PTT counts. ptt_data %&gt;% left_join(species_lut, by = c(&quot;species&quot; = &quot;lookupname&quot;)) %&gt;% left_join(dplyr::select(lhc, mean_weight, gbif_key), by = c(&quot;gbif_key&quot; = &quot;gbif_key&quot;)) %&gt;% left_join(dplyr::select(lhc, mean_weight, species), by = c(&quot;scientificname&quot; = &quot;species&quot;)) %&gt;% dplyr::select(-c(mean_weight.x)) %&gt;% rename(mean_weight = mean_weight.y) -&gt; ptt_data_lhc head(ptt_data_lhc, 10) %&gt;% kable(format = &quot;html&quot;, col.names = colnames(ptt_data_lhc)) %&gt;% kable_styling() %&gt;% kableExtra::scroll_box(width = &quot;100%&quot;, height = &quot;400px&quot;) count_id route count_point season year month day euring species number xcoor ycoor familyvernacular scientificname gbif_key mean_weight 80917 4 1 2017 2017 12 23 720 Aalscholver 2 246342 520763 Cormorants Phalacrocorax carbo 2481890 2254.0 80917 4 1 2017 2017 12 23 5920 Zilvermeeuw 18 246342 520763 Gulls Larus argentatus 2481139 1054.0 80917 4 1 2017 2017 12 23 6700 Houtduif 1 246342 520763 Pigeons Columba palumbus 2495455 496.5 80917 4 1 2017 2017 12 23 11870 Merel 4 246342 520763 Thrushes Turdus merula 2490719 97.0 80917 4 1 2017 2017 12 23 15630 Roek 24 246342 520763 Crows Corvus frugilegus 2482513 459.0 80917 4 2 2017 2017 12 23 6700 Houtduif 1 246357 522178 Pigeons Columba palumbus 2495455 496.5 80917 4 2 2017 2017 12 23 11870 Merel 1 246357 522178 Thrushes Turdus merula 2490719 97.0 80917 4 2 2017 2017 12 23 15600 Kauw 6 246357 522178 Crows Corvus monedula 2482473 236.0 80917 4 2 2017 2017 12 23 15630 Roek 78 246357 522178 Crows Corvus frugilegus 2482513 459.0 80917 4 3 2017 2017 12 23 14620 Pimpelmees 2 246692 523139 Tits Cyanistes caeruleus 2487879 11.5 Now we can verify if our 1% criteria (see above) for species matching is met. We do this by calculating the proportions of birds belonging to a certain species out of the total numbers of birds counted within a count. This should result in an empty dataframe, which will stop the code chunk below from running if that is not the case. wb_data_lhc %&gt;% as.data.frame() %&gt;% group_by(count_id) %&gt;% mutate(total_birds_count = sum(number)) %&gt;% group_by(count_id, species) %&gt;% mutate(proportion_species = sum(number) / total_birds_count) %&gt;% ungroup() %&gt;% arrange(count_id) %&gt;% filter((is.na(mean_weight) &amp; (proportion_species &gt; 0.01))) -&gt; wb_data_lhc_verify stopifnot(nrow(wb_data_lhc_verify) == 0) rm(wb_data_lhc_verify) And once again, we can do the same for the PTT counts. ptt_data_lhc %&gt;% as.data.frame() %&gt;% group_by(count_id) %&gt;% mutate(total_birds_count = sum(number)) %&gt;% group_by(count_id, species) %&gt;% mutate(proportion_species = sum(number) / total_birds_count) %&gt;% ungroup() %&gt;% arrange(count_id) %&gt;% filter((is.na(mean_weight) &amp; (proportion_species &gt; 0.01))) -&gt; ptt_data_lhc_verify stopifnot(nrow(ptt_data_lhc_verify) == 0) rm(ptt_data_lhc_verify) With that out of the way we can finally remove the remaining empty rows and save the PTT and waterbird counts in their final form. ptt_data_lhc %&gt;% drop_na() -&gt; ptt_data wb_data_lhc %&gt;% drop_na() -&gt; wb_data And we save the data for further use. saveRDS(ptt_data, file = &quot;data/processed/sovon/ptt.RDS&quot;) saveRDS(wb_data, file = &quot;data/processed/sovon/wb.RDS&quot;) 5.6 Calculating total bird biomass While we are at it, we will already calculate the total biomass contained within each of the count areas, so we can then add these values to the PPIs through the IDs of the count areas/routes. We use the waterbird count from January 2018, and the point-transect counts from 2017, as these are the best in terms of coverage. wb_year &lt;- 2018 ptt_year &lt;- 2017 wb_data %&gt;% mutate(area_nr = as.character(area_nr)) %&gt;% filter(year == wb_year) %&gt;% rowwise() %&gt;% mutate(specific_biomass = number * mean_weight) %&gt;% ungroup() %&gt;% group_by(area_nr, year) %&gt;% summarise(total_biomass = sum(specific_biomass), weighted_mean_weight = weighted.mean(mean_weight, number), .groups = &quot;drop_last&quot;) %&gt;% ungroup() %&gt;% group_by(area_nr) %&gt;% # Below is only required if year-filter is NOT set, otherwise does nothing summarise(total_biomass = mean(total_biomass), weighted_mean_weight = mean(weighted_mean_weight), .groups = &quot;drop_last&quot;) %&gt;% identity() -&gt; wb_biomass ptt_data %&gt;% filter(year == ptt_year) %&gt;% rowwise() %&gt;% mutate(specific_biomass = number * mean_weight) %&gt;% ungroup() %&gt;% group_by(route, year) %&gt;% summarise(total_biomass = sum(specific_biomass), weighted_mean_weight = weighted.mean(mean_weight, number), .groups = &quot;drop_last&quot;) %&gt;% ungroup() %&gt;% group_by(route) %&gt;% # Below is only required if year-filter is NOT set, otherwise does nothing summarise(total_biomass = mean(total_biomass), weighted_mean_weight = mean(weighted_mean_weight), .groups = &quot;drop_last&quot;) %&gt;% identity() -&gt; ptt_biomass And now we will save these datasets of total_biomass as well. saveRDS(wb_biomass, file = &quot;data/processed/sovon/wb_biomass.RDS&quot;) saveRDS(ptt_biomass, file = &quot;data/processed/sovon/ptt_biomass.RDS&quot;) 5.7 Calculating proportions across bird families Now that we have identified which families birds belong to, we can calculate the proportion of birds that belong to these families across all the PTT and waterbird counts. This can give an idea of the spatial composition of bird communities to illustrate analysis results with. wb &lt;- wb_data ptt &lt;- ptt_data families &lt;- unique(species_lut$familyvernacular) wb %&gt;% mutate(area_nr = as.character(area_nr)) %&gt;% filter(year == wb_year) %&gt;% group_by(area_nr, year) %&gt;% mutate(total_birds = sum(number)) %&gt;% ungroup() %&gt;% group_by(area_nr, year, familyvernacular) %&gt;% mutate(familyprop = sum(number) / total_birds) %&gt;% ungroup() %&gt;% dplyr::select(area_nr, familyvernacular, familyprop) %&gt;% distinct() %&gt;% arrange(area_nr) %&gt;% pivot_wider(names_from = familyvernacular, values_from = familyprop) %&gt;% replace(is.na(.), 0) %&gt;% identity() -&gt; wb_props ptt %&gt;% filter(year == ptt_year) %&gt;% group_by(route, year) %&gt;% mutate(total_birds = sum(number)) %&gt;% ungroup() %&gt;% group_by(route, year, familyvernacular) %&gt;% mutate(familyprop = sum(number) / total_birds) %&gt;% ungroup() %&gt;% dplyr::select(route, familyvernacular, familyprop) %&gt;% distinct() %&gt;% arrange(route) %&gt;% pivot_wider(names_from = familyvernacular, values_from = familyprop) %&gt;% replace(is.na(.), 0) %&gt;% identity() -&gt; ptt_props And now we will save these datasets of family proportions as well. saveRDS(wb_props, file = &quot;data/processed/sovon/wb_props.RDS&quot;) saveRDS(ptt_props, file = &quot;data/processed/sovon/ptt_props.RDS&quot;) References "],
["06.Applying-annotations-to-all-PPIs.html", "6 Apply processing to all PPIs 6.1 Processing environment 6.2 Load the reference PPIs 6.3 Add biomass to reference PPIs 6.4 Copy annotations from reference PPIs to other PPIs", " 6 Apply processing to all PPIs We have so far explained the processing ‘pipeline’ for the PPIs for Herwijnen and Den Helder radars, but have only applied this to a single moment in time, a single volume scan. Now we will apply the processing to all other available PPIs by simply copying over the annotations in case we ever need to repeat the analysis for other scans. We have so far done the following: Pre-processed the radar data, by removing clutter and applying the range-bias correction (Kranstauber et al. 2020). Annotated the PPIs with land use class proportions, distance to inhabited areas and human population. Annotated the PPIs with corresponding count locations for the Sovon data. Connected the Sovon count data with life-history characteristics for the species contained within and calculated bird biomass. 6.1 Processing environment library(dplyr) library(tidyr) library(kableExtra) 6.2 Load the reference PPIs Two PPIs have been processed all the way and those will be our ‘reference’ PPIs from which we copy the data over to the other PPIs which have not had the same treatment. ppi_hrw &lt;- readRDS(&quot;data/processed/corrected-ppis-lu-sovon/corrected_ppi_hrw_lu_sovon.RDS&quot;) ppi_dhl &lt;- readRDS(&quot;data/processed/corrected-ppis-lu-sovon/corrected_ppi_dhl_lu_sovon.RDS&quot;) 6.3 Add biomass to reference PPIs We have previously calculated the total_biomass already for all the count areas/routes, but now we will annotate the reference PPIs with these values as well. We correct for the size of an area the count is conducted in by ‘spreading’ the total biomass over the number of pixels annotated with a certain count area/route. wb &lt;- readRDS(&quot;data/processed/sovon/wb_biomass.RDS&quot;) ptt &lt;- readRDS(&quot;data/processed/sovon/ptt_biomass.RDS&quot;) ppi_hrw$data@data %&lt;&gt;% left_join(dplyr::select(wb, area_nr, total_biomass, weighted_mean_weight), by = c(&quot;wb_area_nr&quot; = &quot;area_nr&quot;)) %&gt;% rename(wb_total_biomass = total_biomass, wb_weighted_mean_weight = weighted_mean_weight) %&gt;% group_by(wb_area_nr) %&gt;% mutate(wb_total_biomass = wb_total_biomass / n()) %&gt;% ungroup() %&gt;% left_join(dplyr::select(ptt, route, total_biomass, weighted_mean_weight), by = c(&quot;ptt_route&quot; = &quot;route&quot;)) %&gt;% rename(ptt_total_biomass = total_biomass, ptt_weighted_mean_weight = weighted_mean_weight) %&gt;% group_by(ptt_route) %&gt;% mutate(ptt_total_biomass = ptt_total_biomass / n()) %&gt;% ungroup() %&gt;% rowwise() %&gt;% mutate(total_biomass = sum(wb_total_biomass, ptt_total_biomass, na.rm = TRUE), weighted_mean_weight = mean(c(wb_weighted_mean_weight, ptt_weighted_mean_weight), na.rm = TRUE)) %&gt;% ungroup() ppi_dhl$data@data %&lt;&gt;% left_join(dplyr::select(wb, area_nr, total_biomass, weighted_mean_weight), by = c(&quot;wb_area_nr&quot; = &quot;area_nr&quot;)) %&gt;% rename(wb_total_biomass = total_biomass, wb_weighted_mean_weight = weighted_mean_weight) %&gt;% group_by(wb_area_nr) %&gt;% mutate(wb_total_biomass = wb_total_biomass / n()) %&gt;% ungroup() %&gt;% left_join(dplyr::select(ptt, route, total_biomass, weighted_mean_weight), by = c(&quot;ptt_route&quot; = &quot;route&quot;)) %&gt;% rename(ptt_total_biomass = total_biomass, ptt_weighted_mean_weight = weighted_mean_weight) %&gt;% group_by(ptt_route) %&gt;% mutate(ptt_total_biomass = ptt_total_biomass / n()) %&gt;% ungroup() %&gt;% rowwise() %&gt;% mutate(total_biomass = sum(wb_total_biomass, ptt_total_biomass, na.rm = TRUE), weighted_mean_weight = mean(c(wb_weighted_mean_weight, ptt_weighted_mean_weight), na.rm = TRUE)) %&gt;% ungroup() 6.4 Copy annotations from reference PPIs to other PPIs We select the variables related to land use, distance to inhabited areas and population density, waterbird counts and PTT counts and add these to the PPIs that contain just the variables resulting from the range-bias correction (Kranstauber et al. 2020). While we are at it, we will also create dataframes containing all the information within the PPIs, to use for possible later modelling exercises. columns &lt;- c(&quot;urban&quot;, &quot;agricultural&quot;, &quot;semiopen&quot;, &quot;forests&quot;, &quot;wetlands&quot;, &quot;waterbodies&quot;, &quot;dist_urban&quot;, &quot;human_pop&quot;, &quot;wb_area_id&quot;, &quot;wb_area_nr&quot;, &quot;ptt_route&quot;, &quot;wb_area_id&quot;, &quot;wb_area_nr&quot;, &quot;wb_area_ha&quot;, &quot;ptt_route&quot;, &quot;wb_total_biomass&quot;, &quot;ptt_total_biomass&quot;, &quot;total_biomass&quot;, &quot;wb_weighted_mean_weight&quot;, &quot;ptt_weighted_mean_weight&quot;, &quot;weighted_mean_weight&quot;) hrw &lt;- ppi_hrw$data@data %&gt;% dplyr::select(all_of(columns)) dhl &lt;- ppi_dhl$data@data %&gt;% dplyr::select(all_of(columns)) hrw_all &lt;- ppi_hrw$data@data %&gt;% filter(row_number() == 0) dhl_all &lt;- ppi_dhl$data@data %&gt;% filter(row_number() == 0) hrw_ppis &lt;- Sys.glob(file.path(&quot;data/processed/corrected-ppis&quot;, &quot;*NL62*&quot;)) dhl_ppis &lt;- Sys.glob(file.path(&quot;data/processed/corrected-ppis&quot;, &quot;*NL61*&quot;)) for (ppi_path in hrw_ppis) { ppi &lt;- readRDS(ppi_path) ppi$data@data &lt;- bind_cols(ppi$data@data, hrw) saveRDS(ppi, file = paste(&quot;data/processed/final-ppis/&quot;, basename(ppi_path), sep = &quot;&quot;)) ppi$data@data %&gt;% mutate(datetime = as.POSIXct(ppi$datetime), pixel = row_number()) %&gt;% bind_rows(hrw_all) -&gt; hrw_all } for (ppi_path in dhl_ppis) { ppi &lt;- readRDS(ppi_path) ppi$data@data &lt;- bind_cols(ppi$data@data, dhl) saveRDS(ppi, file = paste(&quot;data/processed/final-ppis/&quot;, basename(ppi_path), sep = &quot;&quot;)) ppi$data@data %&gt;% mutate(datetime = as.POSIXct(ppi$datetime), pixel = row_number()) %&gt;% bind_rows(dhl_all) -&gt; dhl_all } saveRDS(hrw_all, file = &quot;data/processed/hrw.RDS&quot;) saveRDS(dhl_all, file = &quot;data/processed/dhl.RDS&quot;) data/processed/hrw.RDS and data/processed/dhl.RDS now contain all the PPI rows for each radar respectively. References "],
["07.Composite-all-PPIs.html", "7 Composite all PPIs 7.1 Processing environment 7.2 Generating the composite PPIs 7.3 Visualising the composites", " 7 Composite all PPIs With all the preprocessing done, we can now make composites of the PPIs to ‘solve’ the overlapping areas of the Den Helder and Herwijnen radars. While we’re at it, we will also render out these composites for VIR, to visualise the en-masse take-off of birds. 7.1 Processing environment library(bioRad) library(ggplot2) library(magick) library(purrr) library(viridis) library(dplyr) 7.2 Generating the composite PPIs We will loop over all the Herwijnen and Den Helder PPIs we have generated so far to create composite PPIs for all included parameters. We generate these composites at a 500m, 1000m and 2000m resolution to later test at which resolution the models perform best. Additionally we will save the composites as a bunch of .png files that we can then use separately or inclued in the animated GIF below. source(&quot;R/comp_ppi.R&quot;) hrw_ppis &lt;- Sys.glob(file.path(&quot;data/processed/final-ppis&quot;, &quot;*NL62*&quot;)) dhl_ppis &lt;- Sys.glob(file.path(&quot;data/processed/final-ppis&quot;, &quot;*NL61*&quot;)) generate_composites &lt;- function(hrw_ppis, dhl_ppis, res, maxrange) { # Make a new empty PPI to store all composites in template_ppi &lt;- readRDS(hrw_ppis[1]) all &lt;- template_ppi$data@data %&gt;% filter(row_number() == 0) basemap &lt;- NULL for (i in seq_along(hrw_ppis)) { ppi_hrw &lt;- readRDS(hrw_ppis[i]) ppi_dhl &lt;- readRDS(dhl_ppis[i]) # Set all columns to NA if further than maxrange from radar ppi_hrw$data@data[ppi_hrw$data@data$dist_radar &gt; maxrange, ] &lt;- NA ppi_dhl$data@data[ppi_dhl$data@data$dist_radar &gt; maxrange, ] &lt;- NA params &lt;- c(&quot;VIR&quot;, &quot;VID&quot;, &quot;R&quot;, &quot;overlap&quot;, &quot;eta_sum&quot;, &quot;eta_sum_expected&quot;, &quot;dist_radar&quot;, &quot;class&quot;, &quot;urban&quot;, &quot;agricultural&quot;, &quot;semiopen&quot;, &quot;forests&quot;, &quot;wetlands&quot;, &quot;waterbodies&quot;, &quot;dist_urban&quot;, &quot;human_pop&quot;, &quot;wb_area_id&quot;, &quot;wb_area_nr&quot;, &quot;ptt_route&quot;, &quot;wb_area_ha&quot;, &quot;wb_total_biomass&quot;, &quot;ptt_total_biomass&quot;, &quot;total_biomass&quot;, &quot;wb_weighted_mean_weight&quot;, &quot;ptt_weighted_mean_weight&quot;, &quot;weighted_mean_weight&quot;) # All mean methods except for factors and urban area (set to max), because we want to strictly filter out fireworks methods &lt;- c(&quot;mean&quot;, &quot;mean&quot;, &quot;mean&quot;, &quot;mean&quot;, &quot;mean&quot;, &quot;mean&quot;, &quot;min&quot;, &quot;min&quot;, &quot;max&quot;, &quot;mean&quot;, &quot;mean&quot;, &quot;mean&quot;, &quot;mean&quot;, &quot;mean&quot;, &quot;mean&quot;, &quot;mean&quot;, &quot;factor&quot;, &quot;factor&quot;, &quot;factor&quot;, &quot;factor&quot;, &quot;mean&quot;, &quot;mean&quot;, &quot;mean&quot;, &quot;mean&quot;, &quot;mean&quot;, &quot;mean&quot;) cppi &lt;- comp_ppi(list(ppi_hrw, ppi_dhl), param = params, method = methods, res = c(res, res), coverage = &quot;count&quot;) # Set rain and background pixels to NA cppi$data$VIR[cppi$data$class &lt; 2] &lt;- NA # Add coordinates coords_cppi &lt;- raster::coordinates(cppi$data) cppi$data$x &lt;- coords_cppi[, 1] cppi$data$y &lt;- coords_cppi[, 2] # Add pixel ID cppi$data@data %&gt;% mutate(pixel = row_number()) -&gt; cppi$data@data # Solve different factors solve_factors &lt;- function(x) { r &lt;- x[1] if (is.na(x[1]) &amp;&amp; is.na(x[2])) { r &lt;- NA } if (is.na(x[1]) &amp;&amp; !is.na(x[2])) { r &lt;- x[2] } if (!is.na(x[1]) &amp;&amp; is.na(x[2])) { r &lt;- x[1] } if (!is.na(x[1]) &amp;&amp; !is.na(x[2])) { if (x[1] != x[2]) { r &lt;- NA } else { r &lt;- x[1] } } r } for (j in which(methods == &quot;factor&quot;)) { cppi$data@data[params[j]] &lt;- apply(cppi$data@data[params[j]], 1, solve_factors) } saveRDS(cppi, file = paste(&quot;data/processed/composite-ppis/&quot;, res, &quot;m/&quot;, strftime(ppi_hrw$datetime, format = &quot;%Y%m%d%H%M&quot;), &quot;.RDS&quot;, sep = &quot;&quot;)) cppi$data@data %&gt;% mutate(datetime = as.POSIXct(ppi_hrw$datetime)) %&gt;% bind_rows(all) -&gt; all if (i == 1) { basemap &lt;- download_basemap(cppi, alpha = 0.3) } cppi$data$VIR &lt;- log10(cppi$data$VIR) cppi$data$VIR[is.na(cppi$data$VIR)] &lt;- 0 bioRad::map(cppi, map = basemap, radar_size = 1, xlim = c(3.1, 6.8), ylim = c(51, 54), zlim = c(0, 4.5), palette = viridis(256, option = &quot;viridis&quot;, alpha = 0.6)) + labs(title = &quot;Fireworks NYE 2017-2018&quot;, subtitle = paste(ppi_hrw$datetime, &#39; UTC&#39;, sep = &quot;&quot;)) ggsave(paste(&quot;data/plots/vir-ppis/&quot;, res, &quot;m/&quot;, strftime(ppi_hrw$datetime, format = &quot;%Y%m%d%H%M&quot;), &quot;.png&quot;, sep = &quot;&quot;)) } saveRDS(all, file = paste(&quot;data/processed/all_&quot;, res, &quot;m.RDS&quot;, sep = &quot;&quot;)) } # Somehow this often hangs despite ample memory available, in which case better executed serially. # r &lt;- parallel::mclapply(c(500, 1000, 2000), function(x) { generate_composites(hrw_ppis, dhl_ppis, res = x, maxrange = 66000)}, # mc.cores = 3, mc.preschedule = FALSE) r &lt;- parallel::mclapply(c(1000, 2000), function(x) { generate_composites(hrw_ppis, dhl_ppis, res = x, maxrange = 66000)}, mc.cores = 3, mc.preschedule = FALSE) 7.3 Visualising the composites In order to run this comparatively simple conversion to a GIF of the PPIs, it may be necessary to increase the memory available to ImageMagick by changing the memory policy in /etc/ImageMagick-6/policy.xml. Additionally, we will reduce the resolution of the animated GIF and we’ll stick to the 1000m resolution PPIs. width &lt;- 800 composites &lt;- list.files(path = &quot;data/plots/vir-ppis/1000m/&quot;, pattern = &quot;*.png&quot;, full.names = TRUE) process_image &lt;- function(img_path) { image_read(img_path) %&gt;% image_resize(geometry_size_pixels(width = width)) %&gt;% image_write(path = paste(tools::file_path_sans_ext(img_path), &quot;.jpeg&quot;, sep = &quot;&quot;), format = &quot;jpeg&quot;) } for (file in list.files(path = &quot;data/plots/vir-ppis/&quot;, pattern = &quot;*.png&quot;, full.names = TRUE)) { process_image(file) } list.files(path = &quot;data/plots/vir-ppis/&quot;, pattern = &quot;*.jpeg&quot;, full.names = T) %&gt;% purrr::map(image_read) %&gt;% image_join() %&gt;% image_animate(fps = 2) %&gt;% image_write(&quot;data/plots/vir-ppis/NYE-2017-2018.gif&quot;) knitr::include_graphics(&quot;data/plots/vir-ppis/NYE-2017-2018.gif&quot;) (#fig:composite_ppi_animation)Animation of VIRs during NYE 2017-2018 "],
["08.Model-fireworks-disturbance.html", "8 Modelling fireworks disturbance 8.1 Processing environment 8.2 Preparing a dataset for modelling 8.3 Determine model resolution based on performance in simple total_biomass model 8.4 Check for correlations among predictors 8.5 Correlated land use proportions 8.6 Determine the most suitable proxy for disturbance 8.7 Determine the optimal number of boosting steps 8.8 Variable importance 8.9 Model marginal effects 8.10 Spatial autocorrelation", " 8 Modelling fireworks disturbance We have so far: Pre-processed the radar data by removing clutter and applying the range-bias correction (Kranstauber et al. 2020). Annotated the PPIs with land use proportions and indicators of disturbance, i.e. distance to inhabited urban areas and (human) population density. Annotated the PPIs with the total biomass calculated from the Sovon counts. With the dataset of annotated PPIs, we can start to explore the relation between fireworks disturbance and the birds measured aloft during NYE 2017-2018. The following parameters we assume are important predictors for measured bird densities aloft: The total biomass of birds on the ground. The take-off habitat of these birds. The human population in the vicinity of birds. The distance to the nearest inhabited urban area. 8.1 Processing environment library(ggstatsplot) library(ggplot2) library(dplyr) library(readr) library(tidyr) library(parallel) library(ggridges) library(pgirmess) library(mboost) library(leaflet) library(leaflet.opacity) library(leafem) library(usdm) library(mapview) In the previous chapter, we have created some datasets encompassing all the data contained within the individual PPIs at different resolutions. We will determine the optimal resolution and then continue using this dataset for further modelling. resolutions &lt;- file.path(&quot;data/processed&quot;, c(&quot;all_500m.RDS&quot;, &quot;all_1000m.RDS&quot;, &quot;all_2000m.RDS&quot;)) data &lt;- lapply(resolutions, function(x) readRDS(x)) names(data) &lt;- c(&quot;500m&quot;, &quot;1000m&quot;, &quot;2000m&quot;) 8.2 Preparing a dataset for modelling As we’re mostly interested in the moment of en masse take-off of birds, and we want to limit the effects of dispersal, we will limit our analysis to the first 5 minutes after 00:05 on January 1st, 2018 (or 23:05 on December 31st, 2017 in UTC), as both radar sites (Den Helder and Herwijnen) show a low VIR prior to and a rapid increase in VIR for that period (see Identifying moment of take-off). Making sure birds are thus still sufficiently ‘linked’ to the take-off sites requires that we limit our analysis to only this one scan. Furthermore, we want to make sure that: 1. the area is ‘covered’ by at least 1 radar, 1. we have an estimate of total_biomassfor these sites, 1. the proportion of urban area (urban) in the PPI pixel is less than .25, 1. VIR is &gt; 0 (otherwise log-conversion will return -Inf), so we replace 0-values with 1e-3, 1. the radar beam does not overshoot birds too much based on the vp. dt_start &lt;- as.POSIXct(&quot;2017-12-31 23:05:00&quot;, tz = &quot;UTC&quot;) dt_end &lt;- as.POSIXct(&quot;2017-12-31 23:10:00&quot;, tz = &quot;UTC&quot;) clean_data &lt;- function(data, scan_start, scan_end, max_distance) { mdl_variables &lt;- c(&quot;VIR&quot;, &quot;dist_radar&quot;, &quot;datetime&quot;, &quot;total_biomass&quot;, &quot;agricultural&quot;, &quot;semiopen&quot;, &quot;forests&quot;, &quot;wetlands&quot;, &quot;waterbodies&quot;, &quot;urban&quot;, &quot;dist_urban&quot;, &quot;human_pop&quot;, &quot;disturb_pot&quot;, &quot;pixel&quot;, &quot;coverage&quot;, &quot;class&quot;, &quot;x&quot;, &quot;y&quot;) log10_variables &lt;- c(&quot;dist_urban&quot;, &quot;human_pop&quot;, &quot;total_biomass&quot;, &quot;dist_urban&quot;, &quot;disturb_pot&quot;) data %&gt;% filter(coverage &gt; 0, class != 1, datetime &gt;= scan_start &amp; datetime &lt; scan_end, total_biomass &gt; 0, dist_radar &lt; max_distance, urban &lt; 0.1) %&gt;% mutate(VIR = replace_na(VIR, 0.1), VIR = log10(VIR), disturb_pot = human_pop / dist_urban, total_biomass = total_biomass / 1000) %&gt;% dplyr::select(all_of(mdl_variables)) %&gt;% filter_all(all_vars(is.finite(.))) %&gt;% identity() -&gt; data_cleaned data_cleaned } data_cleaned &lt;- lapply(data, function(x) clean_data(x, dt_start, dt_end, 66000)) rm(data) 8.3 Determine model resolution based on performance in simple total_biomass model As we want to correct for the influence of total_biomass on the measured response by the radars, we will test the performance of a simple model using just dist_radar to correct for range-biased measurement error and total_biomass for the resolutions we have generated composte PPIs for so far (500m, 1000m and 2000m). Let’s start with a calculation of the RMSE. resolution_models &lt;- mcmapply(function(dataset) mboost(VIR ~ bbs(dist_radar) + bbs(total_biomass), data = dataset, control = boost_control(mstop = 10000, trace = TRUE)), dataset = data_cleaned, SIMPLIFY = FALSE) saveRDS(resolution_models, file = &quot;data/models/resolution_models.RDS&quot;) resolution_models &lt;- readRDS(&quot;data/models/resolution_models.RDS&quot;) RMSE &lt;- function(error) { sqrt(mean(error^2)) } sapply(resolution_models, function(x) RMSE(residuals(x))) ## 500m 1000m 2000m ## 1.209230 1.212941 1.222400 We can also use percentage of deviance explained deviance_explained &lt;- function(observed, predicted) { p &lt;- predicted o &lt;- observed i &lt;- rep(mean(observed), length(observed)) # Intercept total.deviance &lt;- sum((o - i) * (o - i)) / length(observed) # Deviance from an intercept-only model resid.deviance &lt;- sum((o - p) * (o - p)) / length(observed) # Deviance from the fitted model (total.deviance - resid.deviance) / total.deviance } mapply(function(data, model) { deviance_explained(data$VIR, predict(model))}, data = data_cleaned, model = resolution_models) ## 500m 1000m 2000m ## 0.2376405 0.2378637 0.2384314 Turns out most models perform quite similarly. However, to make the link between birds and the habitat they take off from as strong as possible, it makes sense to continue just with the 500m model. data_cleaned &lt;- data_cleaned$`500m` saveRDS(data_cleaned, file = &quot;data/models/data_cleaned.RDS&quot;) rm(resolution_models) 8.4 Check for correlations among predictors We have to see if variables are strongly correlated and thus unfit for being included in the same model, so we calculate Spearman correlation coefficients for all numerical predictors. As this is ecological data, some degree of correlation is of course inevitable for most variables. mdl_variables &lt;- c(&quot;VIR&quot;, &quot;dist_radar&quot;, &quot;datetime&quot;, &quot;total_biomass&quot;, &quot;agricultural&quot;, &quot;semiopen&quot;, &quot;forests&quot;, &quot;wetlands&quot;, &quot;waterbodies&quot;, &quot;urban&quot;, &quot;dist_urban&quot;, &quot;human_pop&quot;, &quot;disturb_pot&quot;, &quot;pixel&quot;, &quot;coverage&quot;, &quot;class&quot;) predictors &lt;- mdl_variables[!mdl_variables %in% c(&quot;VIR&quot;, &quot;datetime&quot;, &quot;pixel&quot;, &quot;x&quot;, &quot;y&quot;, &quot;coverage&quot;, &quot;class&quot;)] corr_radar &lt;- ggcorrmat(data_cleaned, output = &quot;plot&quot;, type = &quot;spearman&quot;, cor.vars = all_of(predictors), colors = c(&quot;#2166AC&quot;, &quot;#F7F7F7&quot;, &quot;#B2182B&quot;)) corr_radar So obviously there is correlation between the disturbance proxies and between agricultural and other land use proportions. For the disturbance proxies it would make sense to determine which is most performant (including all does not make sense), but we can continue using the agricultural predictor as boosted models do not suffer from multicollinearity problems like traditional (e.g.) GAMs. 8.5 Correlated land use proportions While we’re at it, let’s see what the distributions of values are for the different land use proportions. data_cleaned %&gt;% dplyr::select(agricultural, semiopen, forests, wetlands, waterbodies) %&gt;% pivot_longer(cols = everything(), names_to = &quot;landuse&quot;, values_to = &quot;value&quot;) %&gt;% ggplot(aes(x = value, y = landuse, fill = stat(x))) + geom_density_ridges_gradient(scale = 1, rel_min_height = 0.0) + scale_fill_viridis_c(name = &quot;LU Prop.&quot;, option = &quot;C&quot;) + labs(title = &quot;Distribution of land use proportions in modelling dataset&quot;) + xlab(&quot;Land use proportion&quot;) + ylab(&quot;Land use class&quot;) As can be expected in The Netherlands, the dominant land use class is clearly agricultural with the most prominent peak at full PPI pixel coverage (values close to 1) and all other land use classes peaking very strongly at low proportions. This essentially means that when one of the other land use classes increases in proportion, this will almost always come at the cost of the proportion of agricultural and vice versa. 8.6 Determine the most suitable proxy for disturbance Now we will compare the disturbance proxies in a similar fashion to how we compared the performance of the model using different PPI resolutions, by calculating deviance explained and RMSE. fm_dist_urban &lt;- VIR ~ bbs(dist_radar) + bbs(total_biomass) + bbs(semiopen) + bbs(forests) + bbs(wetlands) + bbs(waterbodies) + bbs(agricultural) + bbs(dist_urban) fm_human_pop &lt;- VIR ~ bbs(dist_radar) + bbs(total_biomass) + bbs(semiopen) + bbs(forests) + bbs(wetlands) + bbs(waterbodies) + bbs(agricultural) + bbs(human_pop) fm_disturb_pot &lt;- VIR ~ bbs(dist_radar) + bbs(total_biomass) + bbs(semiopen) + bbs(forests) + bbs(wetlands) + bbs(waterbodies) + bbs(agricultural) + bbs(disturb_pot) formulas &lt;- list(fm_dist_urban, fm_human_pop, fm_disturb_pot) disturbance_models &lt;- mcmapply(function(formula) mboost(formula, data = data_cleaned, control = boost_control(mstop = 10000, trace = TRUE)), formula = formulas, SIMPLIFY = FALSE) names(disturbance_models) &lt;- c(&quot;dist_urban&quot;, &quot;human_pop&quot;, &quot;disturb_pot&quot;) saveRDS(disturbance_models, file = &quot;data/models/disturbance_models.RDS&quot;) disturbance_models &lt;- readRDS(&quot;data/models/disturbance_models.RDS&quot;) RMSE &lt;- function(error) { sqrt(mean(error^2)) } rmse &lt;- sapply(disturbance_models, function(x) RMSE(residuals(x))) d2 &lt;- mapply(function(model) { deviance_explained(data_cleaned$VIR, predict(model))}, model = disturbance_models) as.data.frame(list(&quot;RMSE&quot; = as.matrix(rmse), &quot;D2&quot; = as.matrix(d2))) RMSE D2 dist_urban 1.110643 0.3568815 human_pop 1.115877 0.3508063 disturb_pot 1.118576 0.3476619 It is clear dist_urban performs the best, though just by a slight margin. As it is probably the most interpretable proxy from a policy perspective, we can continue using it without any regrets. model &lt;- disturbance_models$dist_urban saveRDS(model, file = &quot;data/models/model.RDS&quot;) rm(disturbance_models) 8.7 Determine the optimal number of boosting steps The main hyperparameter to be tuned for the boosted GAMs using mboost is the number of boosting iterations/steps. By stopping boosting before model performance (measured using cross-validation) worsens, we can avoid overfitting. We limit this test of model performance for a maximum of 50,000 boosts. model_boosts &lt;- mboost(fm_dist_urban, data = data_cleaned, control = boost_control(mstop = 50000, trace = FALSE)) saveRDS(model_boosts, file = &quot;data/models/model_boosts.RDS&quot;) model_boosts &lt;- readRDS(&quot;data/models/model_boosts.RDS&quot;) cv10f &lt;- cv(model.weights(model_boosts), type = &quot;kfold&quot;, B = 10) cvm &lt;- cvrisk(model_boosts, folds = cv10f, papply = lapply) saveRDS(cvm, file = &quot;data/models/cvm_boosts.RDS&quot;) cvm &lt;- readRDS(&quot;data/models/cvm_boosts.RDS&quot;) plot(cvm) We can see that model performance improves very little beyond a few thousand boosting iterations. As we have to quantify model uncertainty using bootstrapping techniques, it makes little computational sense to push much beyond 10000 boosts, as that would just make the bootstrapping procedure last much longer. 8.8 Variable importance We can quantify the importance of variables within our model using the varimp function which returns variable importance, a measure of the total improvement to model deviance a variable is responsible for. plot(varimp(model)) 8.9 Model marginal effects Let’s quickly visualise marginal effects of this model, showing how individual variables influence model outcome with all other variables held constant. par(mfrow = c(2, 4)) plot(model) 8.10 Spatial autocorrelation Model residuals should not show strong autocorrelation as then the independency of errors assumption is violated (see for example this). Additionally, a model with strong autocorrelation in the residuals suggests that it lacks a spatial component within the predictors. As it is computationally too difficult to calculate the spatial autocorrelation for the entire dataset at once, we subsample 25% of datapoints for these calculations. Results may thus vary to some degree. df &lt;- data_cleaned df$residual &lt;- resid(model) df %&gt;% filter(dist_radar &lt; 66000) %&gt;% slice_sample(prop = 0.25) -&gt; df_sample correlogram &lt;- correlog(df_sample[, c(&quot;x&quot;, &quot;y&quot;)], df_sample[, &quot;residual&quot;], method = &quot;Moran&quot;, nbclass = NULL) saveRDS(correlogram , file = &quot;data/models/correlogram.RDS&quot;) correlogram &lt;- readRDS(&quot;data/models/correlogram.RDS&quot;) plot(correlogram) This shows there’s some spatial autocorrelation in residuals remaining. We use a plot of residuals to assess where this occurs and if this indicates our model is missing some important spatial effect, or if there is another explanation. df &lt;- data_cleaned df$residual &lt;- resid(model) df$preds &lt;- predict.mboost(model, newdata = data_cleaned) ppi &lt;- readRDS(&quot;data/processed/composite-ppis/500m/201712312305.RDS&quot;) ppi$data@data %&gt;% left_join(dplyr::select(df, pixel, preds, residual), by = &quot;pixel&quot;) -&gt; ppi$data@data ppi$data@data$VIR_log &lt;- log10(ppi$data@data$VIR) ppi$data@data$total_biomass_log &lt;- log10(ppi$data@data$total_biomass / 1000) pal_resid &lt;- colorspace::diverging_hcl(50, &quot;Blue-Red 3&quot;, power = 2) z_lims_resid &lt;- c(-3, 3) palette_resid &lt;- colorNumeric(pal_resid, na.color = &quot;#00000005&quot;, domain = z_lims_resid) raster_resid &lt;- as(ppi$data[&quot;residual&quot;], &quot;RasterLayer&quot;) raster_resid[raster_resid &lt;= z_lims_resid[1]] &lt;- z_lims_resid[1] raster_resid[raster_resid &gt;= z_lims_resid[2]] &lt;- z_lims_resid[2] leaflet() %&gt;% addTiles(group = &quot;OSM (default)&quot;) %&gt;% addRasterImage(raster_resid, colors = palette_resid, layerId = &quot;resid&quot;, group = &quot;resid&quot;) %&gt;% addImageQuery(raster_resid, layerId = &quot;resid&quot;) %&gt;% addLegend(pal = palette_resid, values = z_lims_resid) %&gt;% addOpacitySlider(layerId = &quot;resid&quot;) %&gt;% identity() ## Warning in colors(.): Some values were outside the color scale and will be treated as NA The plot shows how residuals become larger as the distance from the radars increases, and this is a more pronounced effect in the domain of the Den Helder radar. This effect is partially a consequence of radar range-bias and using a single distance to radar vs. 2 for each radar separately. You can see how this results in mostly ‘overprediction’ within the Herwijnen radar domain at long distances and ‘underprediction’ of VIR at long distances within the domain of Den Helder. To illustrate this, we can limit the calculation of residual spatial autocorrelation to datapoints that are substantially closer to the radar. This should then result in Moran’s I values substantially closer to 0. df &lt;- data_cleaned df$residual &lt;- resid(model) df %&gt;% filter(dist_radar &lt; 50000) %&gt;% slice_sample(prop = 0.25) -&gt; df_sample correlogram &lt;- correlog(df_sample[, c(&quot;x&quot;, &quot;y&quot;)], df_sample[, &quot;residual&quot;], method = &quot;Moran&quot;, nbclass = NULL) saveRDS(correlogram , file = &quot;data/models/correlogram_limited_domain.RDS&quot;) correlogram &lt;- readRDS(&quot;data/models/correlogram_limited_domain.RDS&quot;) plot(correlogram) As indeed is the case. To illustrate this even better, we can calculate local Moran’s I values to see where exactly spatial autocorrelation occurs. r &lt;- as(ppi$data[&quot;residual&quot;], &quot;RasterLayer&quot;) local_sa &lt;- lisa(x = r, d1 = 0, d2 = 1500, statistic = &quot;I&quot;) saveRDS(local_sa, file = &quot;data/models/local_sa.RDS&quot;) local_sa &lt;- readRDS(&quot;data/models/local_sa.RDS&quot;) mapview(local_sa) ## Warning in rasterCheckSize(x, maxpixels = maxpixels): maximum number of pixels for Raster* viewing is 5e+05 ; ## the supplied Raster* has 575775 ## ... decreasing Raster* resolution to 5e+05 pixels ## to view full resolution set &#39;maxpixels = 575775 &#39; We can see - indeed - that spatial autocorrelation in the residuals is strongest at distance from the radar and thankfully does not occur in areas that contain areas of scarce land use types (eg forests). While some degree of spatial autocorrelation in residuals is present, this indicates it does not affect our interpretation of results. References "],
["09.Quantifying-model-uncertainty.html", "9 Quantifying model uncertainty 9.1 Processing environment 9.2 Load the constructed model 9.3 Bootstrapped uncertainty analysis 9.4 Recombine bootstrapped results", " 9 Quantifying model uncertainty We use a boostrapping approach to quantify model uncertainty. Luckily, the mboost already contains the functions to do so. The partial dependence plots generated in the previous chapter visualise the marginal effect of certain predictors on the outcome log(VIR). We use a bootstrapping approach to quantify the model uncertainty. 9.1 Processing environment library(parallel) library(tibble) library(dplyr) library(tidyr) library(patchwork) 9.2 Load the constructed model model &lt;- readRDS(&quot;data/models/model.RDS&quot;) 9.3 Bootstrapped uncertainty analysis Using the bootstrapping procedure provided in mboost, tweaked to our use case, we can derive uncertainty estimates from the trained model. We make a few changes to the default functioning of the confint.mboost function. We let bootstrap folds be determined outside of the function call, so they can be stored separately and processing can be parallellised more easily. We include variable importance as variable to be bootstrapped, so uncertainty estimates around that value can be quantified too. We calculate model predictions for a finer grid along the variables of interest (1000 values instead of 100). 9.3.1 Determine bootstrap folds The folds contain indexes of datapoints that are resampled for each of the 1000 bootstrap iterations. folds &lt;- cv(model.weights(model), B = 1000) saveRDS(folds, file = &quot;data/models/confints/folds.RDS&quot;) 9.3.2 Running the bootstrapping procedure It is very computationally intensive to execute the bootstrapping procedure, hence it is best executed manually tweaking settings to the local machine (memory, CPU cores, etc). See the R/mboost_uncertainty_analysis.R file for an example of how to do so. In this case I had 2-3 RStudio jobs running the script on a batch of the folds, which can be combined later on as results are stored in data/models/confints/. Execution took about 3 days. source(&quot;R/mboost_uncertainty_analysis.R&quot;) 9.4 Recombine bootstrapped results Having adjusted the bootstrapping procedure a bit, we now have to recombine the data so the R object matches the format mboost functions expect. Additionally, we will include the variable importance now as well. cis &lt;- lapply(Sys.glob(&quot;data/models/confints/modelci*&quot;)[2:1000], readRDS) ci_boot_pred &lt;- lapply(cis, function(x) x$boot_pred) ci_varimp &lt;- lapply(cis, function(x) x$varimp) modelci &lt;- readRDS(&quot;data/models/confints/modelci_1.RDS&quot;) modelci$boot_pred[2:1000] &lt;- ci_boot_pred modelci$boot_pred[1] &lt;- NULL modelci$data &lt;- cis[[1]]$data modelci$varimp &lt;- ci_varimp saveRDS(modelci, file = &quot;data/models/confints/final_modelci.RDS&quot;) Let’s confirm it worked by plotting the bootstrapped confidence intervals. vars &lt;- c(&quot;dist_radar&quot;, &quot;total_biomass&quot;, &quot;semiopen&quot;, &quot;forests&quot;, &quot;wetlands&quot;, &quot;waterbodies&quot;, &quot;agricultural&quot;, &quot;dist_urban&quot;) par(mfrow = c(2, 4)) lapply(vars, function(x) plot(modelci, which = x)) ## [[1]] ## NULL ## ## [[2]] ## NULL ## ## [[3]] ## NULL ## ## [[4]] ## NULL ## ## [[5]] ## NULL ## ## [[6]] ## NULL ## ## [[7]] ## NULL ## ## [[8]] ## NULL Voilà, that seems to have done the trick. "],
["10.Figures-1-Data-overview.html", "10 Figure 1: Data overview 10.1 Processing environment 10.2 Workflow", " 10 Figure 1: Data overview Most of Figure 1 in the paper is made using QGIS and Adobe Illustrator, but here we export VIR and total_biomass estimates. Furthermore, we use the land use map that is stored in data/processed/landuse/landuse_hrw_reclassified.tif, so that doesn’t need exporting anymore. 10.1 Processing environment library(bioRad) library(raster) library(magrittr) source(&quot;R/comp_ppi.R&quot;) 10.2 Workflow We load the radar PPIs. hrw &lt;- readRDS(&quot;data/processed/final-ppis/RAD_NL62_VOL_NA_201712312305_ODIM.RDS&quot;) dhl &lt;- readRDS(&quot;data/processed/final-ppis/RAD_NL61_VOL_NA_201712312305_ODIM.RDS&quot;) Composite the PPIs and log-transform VIR and total_biomass for improved visualisation. cppi &lt;- comp_ppi(list(hrw, dhl), param = c(&quot;VIR&quot;, &quot;total_biomass&quot;), res = 500, method = c(&quot;mean&quot;, &quot;mean&quot;)) cppi$data$VIR &lt;- log10(cppi$data$VIR) cppi$data$VIR[is.infinite(cppi$data$VIR)] &lt;- 0 cppi$data$VIR[cppi$data$VIR == 0] &lt;- NA cppi$data$total_biomass[cppi$data$total_biomass == 0] &lt;- NA cppi$data$total_biomass &lt;- log10(cppi$data$total_biomass) Make plots to confirm the composite and transformation works as intended. plot(cppi, param = &quot;VIR&quot;, zlim = c(0, 10)) plot(cppi, param = &quot;total_biomass&quot;, zlim = c(0, 7)) And now we write out raster files containing these parameters, which we can then stitch together in QGIS and Adobe Illustrator. raster::writeRaster(as(cppi$data[&quot;VIR&quot;], &quot;RasterLayer&quot;), filename = &quot;data/plots/paper/fig1_VIR.tif&quot;, overwrite = TRUE) raster::writeRaster(as(cppi$data[&quot;total_biomass&quot;], &quot;RasterLayer&quot;), filename = &quot;data/plots/paper/fig1_total_biomass.tif&quot;, overwrite = TRUE) "],
["10.Figures-2-Model.html", "11 Figure 2: Model output 11.1 Processing environment 11.2 Variable importance 11.3 Compare groups 11.4 Visualise marginal effects 11.5 All marginal effects", " 11 Figure 2: Model output We have now quantified uncertainty in our model using bootstrapping and can finally visualise the outcome. 11.1 Processing environment library(ggplot2) library(mboost) library(dplyr) library(tidyr) library(magrittr) library(patchwork) library(ggdist) Once again we have tweaked some of the mboost default functionality, in this case to facilitate plotting using ggplot2. modelci &lt;- readRDS(&quot;data/models/confints/final_modelci.RDS&quot;) data_cleaned &lt;- readRDS(&quot;data/models/data_cleaned.RDS&quot;) source(&quot;R/mboost_bootstrapped_quantiles.R&quot;) source(&quot;R/plot.mboost_adjusted.R&quot;) 11.2 Variable importance We start by calculating summary statistics of bootstrapped variable importance, as we’ll organise the final figure according to descending variable importance. bootstrapped_varimp &lt;- function(modelci, exclude = c(&quot;dist_radar&quot;), round = 0) { ind_vis &lt;- lapply(modelci$varimp, function(x) { x %&gt;% filter(!variable %in% exclude) %&gt;% mutate(vi = reduction / sum(reduction) * 100) }) vis_out &lt;- ind_vis[[1]] %&gt;% dplyr::select(variable, vi) %&gt;% mutate(variable = as.character(variable)) agg_vis &lt;- lapply(ind_vis[2:length(ind_vis)], function(x) { x %&gt;% dplyr::select(vi) }) vis_out[2:length(ind_vis)] &lt;- bind_cols(agg_vis) vis_out } bvi_biol &lt;- bootstrapped_varimp(modelci) bvi_all &lt;- bootstrapped_varimp(modelci, exclude = NULL) And we can plot the distribution of these variable importance measures for each of the predictors, for a model containing all predictors and one containing just biologically-relevant predictors. For the latter we have rescaled variable importance back to 100% after removal of dist_radar. bvi_biol %&gt;% pivot_longer(!variable, names_to = &quot;bootstrap&quot;, values_to = &quot;vi&quot;) %&gt;% ggplot(aes(x = vi, y = variable)) + stat_eye() + labs(x = &quot;Variable importance (%)&quot;, y = &quot;Predictor&quot;, title = &quot;Biologically-relevant predictors&quot;) bvi_all %&gt;% pivot_longer(!variable, names_to = &quot;bootstrap&quot;, values_to = &quot;vi&quot;) %&gt;% ggplot(aes(x = vi, y = variable)) + stat_eye() + labs(x = &quot;Variable importance (%)&quot;, y = &quot;Predictor&quot;, title = &quot;All model predictors&quot;) We can now also calculate the mean variable importance for each of the predictors to determine the rank in the final figure. bvi_biol %&gt;% pivot_longer(!variable, names_to = &quot;bootstrap&quot;, values_to = &quot;vi&quot;) %&gt;% group_by(variable) %&gt;% summarise(mean_vi = mean(vi), q025 = quantile(vi, probs = 0.025), q975 = quantile(vi, probs = 0.975), .groups = &quot;drop_last&quot;) %&gt;% mutate(mean_round = round(mean_vi, 0)) %&gt;% arrange(desc(mean_vi)) -&gt; bvi_biol bvi_all %&gt;% pivot_longer(!variable, names_to = &quot;bootstrap&quot;, values_to = &quot;vi&quot;) %&gt;% group_by(variable) %&gt;% summarise(mean_vi = mean(vi), q025 = quantile(vi, probs = 0.025), q975 = quantile(vi, probs = 0.975), .groups = &quot;drop_last&quot;) %&gt;% mutate(mean_round = round(mean_vi, 0)) %&gt;% arrange(desc(mean_vi)) -&gt; bvi_all bvi_biol bvi_all variable mean_vi q025 q975 mean_round agricultural 57.957796 53.8559739 62.258847 58 dist_urban 11.224674 8.7710815 13.865724 11 total_biomass 11.205561 9.5601848 13.114829 11 semiopen 9.701687 7.1161404 12.720081 10 forests 6.858195 5.1324696 8.923469 7 wetlands 1.592545 0.8943166 2.368806 2 waterbodies 1.459543 0.8798055 2.054568 1 variable mean_vi q025 q975 mean_round dist_radar 53.8822446 51.3484728 56.294842 54 agricultural 26.7337361 24.1565126 29.401097 27 dist_urban 5.1751480 4.0042855 6.435504 5 total_biomass 5.1651208 4.4211618 6.025859 5 semiopen 4.4744563 3.2454436 5.895291 4 forests 3.1617301 2.3702680 4.100341 3 wetlands 0.7346076 0.4135183 1.096298 1 waterbodies 0.6729564 0.4023422 0.950528 1 11.3 Compare groups There’s quite some overlap in the confidence intervals, so let’s see which variables actually have different variable importance. bvi_all %&gt;% pivot_longer(!variable, names_to = &quot;bootstrap&quot;, values_to = &quot;vi&quot;) -&gt; all summary(aov(vi ~ variable, data = all)) pairwise.t.test(all$vi, all$variable) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## variable 7 9811 1401.6 930.9 &lt;2e-16 *** ## Residuals 24 36 1.5 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Pairwise comparisons using t tests with pooled SD ## ## data: all$vi and all$variable ## ## agricultural dist_radar dist_urban forests semiopen total_biomass waterbodies ## dist_radar &lt; 2e-16 - - - - - - ## dist_urban &lt; 2e-16 &lt; 2e-16 - - - - - ## forests &lt; 2e-16 &lt; 2e-16 0.21316 - - - - ## semiopen &lt; 2e-16 &lt; 2e-16 1.00000 0.82000 - - - ## total_biomass &lt; 2e-16 &lt; 2e-16 1.00000 0.21316 1.00000 - - ## waterbodies &lt; 2e-16 &lt; 2e-16 0.00053 0.09627 0.00346 0.00053 - ## wetlands &lt; 2e-16 &lt; 2e-16 0.00053 0.09894 0.00369 0.00053 1.00000 ## ## P value adjustment method: holm Indeed, mean variable importance for dist_urban is not significantly different from total_biomass and the same applies to waterbodies and wetlands. 11.4 Visualise marginal effects Now that we have calculated how the marginal effects should be ordered, we can generate the final plots. 11.4.1 Biologically-relevant marginal effects confidence.intervals &lt;- c(0.95, 0.8, 0.5) colors &lt;- c(&quot;urban&quot; = &quot;#94346E&quot;, &quot;agricultural&quot; = &quot;#73AF48&quot;, &quot;semiopen&quot; = &quot;#EDAD08&quot;, &quot;forests&quot; = &quot;#0F8554&quot;, &quot;wetlands&quot; = &quot;#38A6A5&quot;, &quot;waterbodies&quot; = &quot;#1D6996&quot;, &quot;dist_urban&quot; = &quot;#94346E&quot;, &quot;total_biomass&quot; = &quot;#CC503E&quot;, &quot;dist_radar&quot; = &quot;#666666&quot;) x_labels &lt;- c(&quot;urban&quot; = &quot;Urban&quot;, &quot;agricultural&quot; = &quot;Agricultural&quot;, &quot;semiopen&quot; = &quot;Semi-open&quot;, &quot;forests&quot; = &quot;Forests&quot;, &quot;wetlands&quot; = &quot;Wetlands&quot;, &quot;waterbodies&quot; = &quot;Water bodies&quot;, &quot;dist_urban&quot; = &quot;Distance to fireworks (m)&quot;, &quot;total_biomass&quot; = &quot;Bird biomass (kg/km^2)&quot;, &quot;dist_radar&quot; = &quot;Distance from radar (m)&quot;) limit_quantiles &lt;- c(&quot;dist_urban&quot;, &quot;total_biomass&quot;) manual_limits &lt;- list(&quot;dist_urban&quot; = c(min(data_cleaned$dist_urban), quantile(data_cleaned$dist_urban, probs = 0.975)), &quot;total_biomass&quot; = c(0, quantile(data_cleaned$total_biomass, probs = 0.975))) ylims &lt;- c(-1.8, 1.5) plot_mboost_pdp &lt;- function(modelci, data, which, confints, colors = NULL, ylims = ylims, varimp = NULL) { bootstrapped_quantiles &lt;- as.data.frame(t(mboost_bootstrapped_quantiles(modelci, confidence.intervals, which = which))) bootstrapped_quantiles$x &lt;- modelci$data[modelci$model$which(which)][[1]][, 1] bootstrapped_quantiles$y &lt;- plot.mboost_adjusted(modelci$model, which = which, newdata = modelci$data[[modelci$model$which(which)]])[[2]] p &lt;- ggplot(bootstrapped_quantiles) i &lt;- 1 sorted_confints &lt;- sort(confints, decreasing = TRUE) # Add variable importance if (is.null(varimp)) { variable_importance &lt;- function(model, which, exclude = c(&quot;dist_radar&quot;), round = 0) { vi &lt;- as.data.frame(varimp(model)) %&gt;% filter(!variable %in% exclude) vi$vi &lt;- vi$reduction / sum(vi$reduction) * 100 vi %&gt;% filter(variable == which) %&gt;% dplyr::select(vi) %&gt;% as.numeric() %&gt;% round(round) } vi &lt;- variable_importance(modelci$model, which) } else { vi &lt;- varimp %&gt;% filter(variable == which) %&gt;% dplyr::select(mean_round) } offset_right &lt;- 0.95 offset_top &lt;- 0.4 if (which == &quot;dist_urban&quot;) { p &lt;- p + annotate(&quot;text&quot;, x = manual_limits$dist_urban[[2]] * offset_right, y = ylims[2] - offset_top, label = paste0(vi, &quot;%&quot;), hjust = 1, color = colors[which], fontface = &quot;bold&quot;, size = 12, alpha = 0.5) } else if(which == &quot;total_biomass&quot;) { p &lt;- p + annotate(&quot;text&quot;, x = manual_limits$total_biomass[[2]] * offset_right, y = ylims[2] - offset_top, label = paste0(vi, &quot;%&quot;), hjust = 1, color = colors[which], fontface = &quot;bold&quot;, size = 12, alpha = 0.5) } else { p &lt;- p + annotate(&quot;text&quot;, x = 1 * offset_right, y = ylims[2] - offset_top, label = paste0(vi, &quot;%&quot;), hjust = 1, color = colors[which], fontface = &quot;bold&quot;, size = 12, alpha = 0.5) } # Add density if (which == &quot;dist_urban&quot;) { dens &lt;- density(data[, which], bw = 225, from = manual_limits$dist_urban[[1]], to = manual_limits$dist_urban[[2]]) } else if (which == &quot;total_biomass&quot;) { dens &lt;- density(data[, which], bw = 100, from = manual_limits$total_biomass[[1]], to = manual_limits$total_biomass[[2]]) } else { dens &lt;- density(data[, which], bw = 0.03556, from = 0, to = 1) } scale_lims &lt;- c(ylims[1] + 0.05, ylims[2] - 0.05) dens$y &lt;- scales::rescale(dens$y, to = scale_lims) dens &lt;- as.data.frame(list(as.matrix(dens$x), as.matrix(dens$y))) colnames(dens) &lt;- c(&quot;x&quot;, &quot;y&quot;) p &lt;- p + geom_line(aes(x = x, y = y), data = dens, color = &quot;grey50&quot;, lineend = &quot;round&quot;, linetype = 3) + scale_y_continuous(sec.axis = sec_axis(~ ., name = &quot;Predictor frequency&quot;, breaks = scale_lims, labels = c(&quot;min&quot;, &quot;max&quot;))) ## Add horizontal line p &lt;- p + geom_hline(yintercept = 0) for (ci in sorted_confints) { alphas &lt;- rev(factor(sorted_confints)) ymax &lt;- as.name(paste((1 - (1 - ci) / 2) * 100, &quot;%&quot;, sep = &quot;&quot;)) ymax &lt;- enquo(ymax) ymin &lt;- as.name(paste(((1 - ci) / 2) * 100, &quot;%&quot;, sep = &quot;&quot;)) ymin &lt;- enquo(ymin) p &lt;- p + geom_ribbon(aes(x = x, ymin = !!ymin, ymax = !!ymax, alpha = !!alphas[i]), fill = colors[which]) + geom_line(aes(x = x, y = y), color = colors[which], size = 1.5, lineend = &quot;round&quot;) i &lt;- i + 1 } p &lt;- p + scale_alpha_discrete(range = c(0.2, 0.5)) + coord_cartesian(ylim = ylims, expand = FALSE) + guides(alpha = FALSE) if (which == &quot;dist_urban&quot;) { xlabel &lt;- x_labels[which] p &lt;- p + coord_cartesian(xlim = manual_limits$dist_urban, ylim = ylims, expand = FALSE) # scale_x_continuous(breaks = c(0, 10000, 20000, 30000), labels = c(0, 10, 20, 30)) } else if (which == &quot;total_biomass&quot;) { xlabel &lt;- x_labels[which] p &lt;- p + coord_cartesian(xlim = manual_limits$total_biomass, ylim = ylims, expand = FALSE) + scale_x_continuous(breaks = c(250, 500, 750), labels = c(250*4, 500*4, 750*4)) } else { xlabel &lt;- paste(&quot;%&quot;, x_labels[which]) p &lt;- p + scale_x_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1), labels = c(&quot;0%&quot;, &quot;25%&quot;, &quot;50%&quot;, &quot;75%&quot;, &quot;100%&quot;)) } p &lt;- p + theme_classic(base_size = 10) + labs(x = xlabel, y = expression(paste(&quot;Flight response &quot;, log[10], &quot;(VIR)&quot;))) + theme(axis.line.y.left = element_line(color = colors[which], size = 1), axis.line.y.right = element_line(color = &quot;grey&quot;), axis.ticks.y.left = element_line(color = colors[which], size = 1), axis.ticks.y.right = element_line(color = &quot;grey&quot;), axis.title.y = element_text()) if (which(varimp$variable == which) %% 2 == 0) { p &lt;- p + theme(axis.title.y.left = element_blank()) } else { p &lt;- p + theme(axis.title.y.right = element_blank()) } if (!which %in% limit_quantiles) { p &lt;- p + theme(axis.title.x = element_text(vjust = 0.5)) } p } predictors &lt;- bvi_biol$variable plots &lt;- mapply(function(predictors) {plot_mboost_pdp(modelci, data_cleaned, which = predictors, confidence.intervals, colors, ylims, bvi_biol)}, predictors = predictors, SIMPLIFY = FALSE) # layout &lt;- c(area(1, 1, 1, 2), area(1, 3, 1, 4), area(2, 1, 2, 2), area(2, 3, 2, 4), area(3, 1, 3, 2), area(3, 3, 3, 4), area(4, 2, 4, 3)) # p &lt;- wrap_plots(plots, design = layout) p &lt;- wrap_plots(plots, ncol = 2) p And we save it as a PDF so we can tweak the plot manually in Adobe Illustrator. ggsave(filename = &quot;data/plots/paper/fig2_biol.pdf&quot;, plot = p, width = 16, height = 20, dpi = 300, units = &quot;cm&quot;) 11.5 All marginal effects confidence.intervals &lt;- c(0.95, 0.8, 0.5) colors &lt;- c(&quot;urban&quot; = &quot;#94346E&quot;, &quot;agricultural&quot; = &quot;#73AF48&quot;, &quot;semiopen&quot; = &quot;#EDAD08&quot;, &quot;forests&quot; = &quot;#0F8554&quot;, &quot;wetlands&quot; = &quot;#38A6A5&quot;, &quot;waterbodies&quot; = &quot;#1D6996&quot;, &quot;dist_urban&quot; = &quot;#94346E&quot;, &quot;total_biomass&quot; = &quot;#CC503E&quot;, &quot;dist_radar&quot; = &quot;#666666&quot;) x_labels &lt;- c(&quot;urban&quot; = &quot;Urban&quot;, &quot;agricultural&quot; = &quot;Agricultural&quot;, &quot;semiopen&quot; = &quot;Semi-open&quot;, &quot;forests&quot; = &quot;Forests&quot;, &quot;wetlands&quot; = &quot;Wetlands&quot;, &quot;waterbodies&quot; = &quot;Water bodies&quot;, &quot;dist_urban&quot; = &quot;Distance to fireworks (m)&quot;, &quot;total_biomass&quot; = &quot;Bird biomass (kg/km^2)&quot;, &quot;dist_radar&quot; = &quot;Distance from radar (km)&quot;) limit_quantiles &lt;- c(&quot;dist_urban&quot;, &quot;total_biomass&quot;) manual_limits &lt;- list(&quot;dist_urban&quot; = c(min(data_cleaned$dist_urban), max(data_cleaned$dist_urban)), &quot;total_biomass&quot; = c(min(data_cleaned$total_biomass), max(data_cleaned$total_biomass)), &quot;dist_radar&quot; = c(0, 66000)) ylims &lt;- c(-4, 3) plot_mboost_pdp &lt;- function(modelci, data, which, confints, colors = NULL, ylims = ylims, varimp = NULL) { bootstrapped_quantiles &lt;- as.data.frame(t(mboost_bootstrapped_quantiles(modelci, confidence.intervals, which = which))) bootstrapped_quantiles$x &lt;- modelci$data[modelci$model$which(which)][[1]][, 1] bootstrapped_quantiles$y &lt;- plot.mboost_adjusted(modelci$model, which = which, newdata = modelci$data[[modelci$model$which(which)]])[[2]] p &lt;- ggplot(bootstrapped_quantiles) i &lt;- 1 sorted_confints &lt;- sort(confints, decreasing = TRUE) # Add variable importance if (is.null(varimp)) { variable_importance &lt;- function(model, which, exclude = c(&quot;dist_radar&quot;), round = 0) { vi &lt;- as.data.frame(varimp(model)) %&gt;% filter(!variable %in% exclude) vi$vi &lt;- vi$reduction / sum(vi$reduction) * 100 vi %&gt;% filter(variable == which) %&gt;% dplyr::select(vi) %&gt;% as.numeric() %&gt;% round(round) } vi &lt;- variable_importance(modelci$model, which) } else { vi &lt;- varimp %&gt;% filter(variable == which) %&gt;% dplyr::select(mean_round, q025, q975) } offset_right &lt;- 0.95 offset_top &lt;- 0.75 vi_string &lt;- paste0(vi$mean_round, &quot;% [&quot;, round(vi$q025, digits = 2), &quot;;&quot;, round(vi$q975, digits = 2), &quot;]&quot;) if (which == &quot;dist_urban&quot;) { p &lt;- p + annotate(&quot;text&quot;, x = manual_limits$dist_urban[[2]] * offset_right, y = ylims[2] - offset_top, label = vi_string, hjust = 1, color = colors[which], fontface = &quot;bold&quot;, size = 5, alpha = 0.5) } else if(which == &quot;total_biomass&quot;) { p &lt;- p + annotate(&quot;text&quot;, x = manual_limits$total_biomass[[2]] * offset_right, y = ylims[2] - offset_top, label = vi_string, hjust = 1, color = colors[which], fontface = &quot;bold&quot;, size = 5, alpha = 0.5) } else if(which == &quot;dist_radar&quot;) { p &lt;- p + annotate(&quot;text&quot;, x = manual_limits$dist_radar[[2]] * offset_right, y = ylims[2] - offset_top, label = vi_string, hjust = 1, color = colors[which], fontface = &quot;bold&quot;, size = 5, alpha = 0.5) } else { p &lt;- p + annotate(&quot;text&quot;, x = 1 * offset_right, y = ylims[2] - offset_top, label = vi_string, hjust = 1, color = colors[which], fontface = &quot;bold&quot;, size = 5, alpha = 0.5) } # Add density if (which == &quot;dist_urban&quot;) { dens &lt;- density(data[, which], bw = 225, from = manual_limits$dist_urban[[1]], to = manual_limits$dist_urban[[2]]) } else if (which == &quot;total_biomass&quot;) { dens &lt;- density(data[, which], bw = 100, from = manual_limits$total_biomass[[1]], to = manual_limits$total_biomass[[2]]) } else if (which == &quot;dist_radar&quot;) { dens &lt;- density(data[, which], from = manual_limits$dist_radar[[1]], to = manual_limits$dist_radar[[2]]) } else { dens &lt;- density(data[, which], bw = 0.03556, from = 0, to = 1) } scale_lims &lt;- c(ylims[1] + 0.05, ylims[2] - 0.05) dens$y &lt;- scales::rescale(dens$y, to = scale_lims) dens &lt;- as.data.frame(list(as.matrix(dens$x), as.matrix(dens$y))) colnames(dens) &lt;- c(&quot;x&quot;, &quot;y&quot;) p &lt;- p + geom_line(aes(x = x, y = y), data = dens, color = &quot;grey50&quot;, lineend = &quot;round&quot;, linetype = 3) + scale_y_continuous(sec.axis = sec_axis(~ ., name = &quot;Predictor frequency&quot;, breaks = scale_lims, labels = c(&quot;min&quot;, &quot;max&quot;))) ## Add horizontal line p &lt;- p + geom_hline(yintercept = 0) for (ci in sorted_confints) { alphas &lt;- rev(factor(sorted_confints)) ymax &lt;- as.name(paste((1 - (1 - ci) / 2) * 100, &quot;%&quot;, sep = &quot;&quot;)) ymax &lt;- enquo(ymax) ymin &lt;- as.name(paste(((1 - ci) / 2) * 100, &quot;%&quot;, sep = &quot;&quot;)) ymin &lt;- enquo(ymin) p &lt;- p + geom_ribbon(aes(x = x, ymin = !!ymin, ymax = !!ymax, alpha = !!alphas[i]), fill = colors[which]) + geom_line(aes(x = x, y = y), color = colors[which], size = 1.5, lineend = &quot;round&quot;) i &lt;- i + 1 } p &lt;- p + scale_alpha_discrete(range = c(0.2, 0.5)) + coord_cartesian(ylim = ylims, expand = FALSE) + guides(alpha = FALSE) biomass_formatter &lt;- function(x) x * 4 if (which == &quot;dist_urban&quot;) { xlabel &lt;- x_labels[which] # p &lt;- p + # coord_cartesian(xlim = manual_limits$dist_urban, ylim = ylims, expand = FALSE) # scale_x_continuous(breaks = c(0, 10000, 20000, 30000), labels = c(0, 10, 20, 30)) } else if (which == &quot;total_biomass&quot;) { xlabel &lt;- x_labels[which] p &lt;- p + coord_cartesian(xlim = manual_limits$total_biomass, ylim = ylims, expand = FALSE) + scale_x_continuous(labels = biomass_formatter) } else if (which == &quot;dist_radar&quot;) { xlabel &lt;- x_labels[which] p &lt;- p + coord_cartesian(xlim = manual_limits$dist_radar, ylim = ylims, expand = FALSE) + scale_x_continuous(breaks = c(0, 10000, 20000, 30000, 40000, 50000, 60000), labels = c(0, 10, 20, 30, 40, 50, 60)) } else { xlabel &lt;- paste(&quot;%&quot;, x_labels[which]) p &lt;- p + scale_x_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1), labels = c(&quot;0%&quot;, &quot;25%&quot;, &quot;50%&quot;, &quot;75%&quot;, &quot;100%&quot;)) } p &lt;- p + theme_classic(base_size = 10) + labs(x = xlabel, y = expression(paste(&quot;Flight response &quot;, log[10], &quot;(VIR)&quot;))) + theme(axis.line.y.left = element_line(color = colors[which], size = 1), axis.line.y.right = element_line(color = &quot;grey&quot;), axis.ticks.y.left = element_line(color = colors[which], size = 1), axis.ticks.y.right = element_line(color = &quot;grey&quot;), axis.title.y = element_text()) if (which(varimp$variable == which) %% 2 == 0) { p &lt;- p + theme(axis.title.y.left = element_blank()) } else { p &lt;- p + theme(axis.title.y.right = element_blank()) } if (!which %in% limit_quantiles) { p &lt;- p + theme(axis.title.x = element_text(vjust = 0.5)) } p } predictors &lt;- bvi_all$variable plots &lt;- mapply(function(predictors) {plot_mboost_pdp(modelci, data_cleaned, which = predictors, confidence.intervals, colors, ylims, bvi_all)}, predictors = predictors, SIMPLIFY = FALSE) p &lt;- wrap_plots(plots, ncol = 2) p And once again we save the plot to PDF. ggsave(filename = &quot;data/plots/paper/fig2_all.pdf&quot;, plot = p, width = 16, height = 20, dpi = 300, units = &quot;cm&quot;) "],
["10.Figures-3-Species-composition.html", "12 Figure 3: Species composition 12.1 Processing environment 12.2 Characteristic families 12.3 Mean habitat biomass and weight 12.4 Sorting of families by weight 12.5 Prepare plot", " 12 Figure 3: Species composition To illustrate how species composition changes with habitat types, we make a variety of plots: The top-5 taxonomic families per habitat type. The proportions of birds that belong to a selection of families that are representative for the entire Dutch landscape. To quantify the necessary variables we rely mostly on the point-transect counts from Sovon as these cover all species (instead of the waterbird counts). 12.1 Processing environment library(bioRad) library(ggplot2) library(dplyr) library(tidyr) library(stringr) library(ggpointdensity) library(patchwork) library(GGally) ## Registered S3 method overwritten by &#39;GGally&#39;: ## method from ## +.gg ggplot2 library(tibble) We load the study PPI and proportions of taxonomic groups in the counts. ppi &lt;- readRDS(&quot;data/processed/composite-ppis/500m/201712312305.RDS&quot;) wb_props &lt;- readRDS(&quot;data/processed/sovon/wb_props.RDS&quot;) ptt &lt;- readRDS(&quot;data/processed/sovon/ptt.RDS&quot;) ptt_props &lt;- readRDS(&quot;data/processed/sovon/ptt_props.RDS&quot;) ppi$data@data %&gt;% # left_join(wb_props, by = c(&quot;wb_area_nr&quot; = &quot;area_nr&quot;)) %&gt;% left_join(ptt_props, by = c(&quot;ptt_route&quot; = &quot;route&quot;)) %&gt;% filter(coverage &gt; 0, class != 1, total_biomass &gt; 0, dist_radar &lt; 66000, urban &lt; 0.1) %&gt;% identity() -&gt; data We select only those PPI pixels (and their corresponding counts) which are covered for &gt;99% by a single habitat type. landuse_limit &lt;- 0.99 12.2 Characteristic families Geese, ducks, pigeons, thrushes, tits, waders, crows and finches represent a substantial part of the Dutch avifauna across a large range of body sizes. We select these to illustrate how the taxonomic proportions change with habitats. selected_families &lt;- c(&quot;Geese&quot;, &quot;Ducks&quot;, &quot;Pigeons&quot;, &quot;Thrushes&quot;, &quot;Tits&quot;, &quot;Waders&quot;, &quot;Crows&quot;, &quot;Finches&quot;) data %&gt;% dplyr::select(all_of(c(colnames(ptt_props)[2:45], &quot;semiopen&quot;, &quot;forests&quot;, &quot;wetlands&quot;, &quot;waterbodies&quot;, &quot;agricultural&quot;))) %&gt;% pivot_longer(cols = all_of(colnames(ptt_props)[2:45]), names_to = &quot;family&quot;, values_to = &quot;family_prop&quot;) %&gt;% pivot_longer(cols = all_of(c(&quot;agricultural&quot;, &quot;semiopen&quot;, &quot;forests&quot;, &quot;wetlands&quot;, &quot;waterbodies&quot;)), names_to = &quot;landuse&quot;, values_to = &quot;landuse_prop&quot;) %&gt;% drop_na() %&gt;% filter(family %in% selected_families, landuse_prop &gt;= landuse_limit) %&gt;% group_by(family, landuse) %&gt;% summarise(mean_family_prop = mean(family_prop), .groups = &quot;drop_last&quot;) %&gt;% pivot_wider(names_from = landuse, values_from = mean_family_prop) %&gt;% identity() -&gt; characteristic_families characteristic_families family agricultural forests semiopen waterbodies wetlands Crows 0.0619286 0.1373295 0.0740222 0.0182881 0.0407936 Ducks 0.1508770 0.0233594 0.0726795 0.3419478 0.2416624 Finches 0.0152677 0.1314283 0.0628657 0.0062778 0.0102175 Geese 0.2946680 0.0281144 0.0384954 0.3065711 0.0666727 Pigeons 0.0508753 0.0549949 0.0921633 0.0077864 0.0028696 Thrushes 0.0228345 0.0957379 0.0658859 0.0068034 0.0121501 Tits 0.0084950 0.2470226 0.0778224 0.0051277 0.1186220 Waders 0.0953540 0.0006251 0.0310129 0.0873656 0.2058158 12.3 Mean habitat biomass and weight We calculate the mean biomass for all areas covered for &gt;99% by a single habitat type and calculate mean bird weight for these areas from the point-transect counts. data %&gt;% dplyr::select(all_of(c(&quot;total_biomass&quot;, &quot;ptt_weighted_mean_weight&quot;, &quot;semiopen&quot;, &quot;forests&quot;, &quot;wetlands&quot;, &quot;waterbodies&quot;, &quot;agricultural&quot;))) %&gt;% pivot_longer(cols = all_of(c(&quot;semiopen&quot;, &quot;forests&quot;, &quot;wetlands&quot;, &quot;waterbodies&quot;, &quot;agricultural&quot;)), names_to = &quot;landuse&quot;, values_to = &quot;proportion&quot;) %&gt;% filter(proportion &gt;= landuse_limit) %&gt;% mutate(total_biomass = total_biomass / 1000) %&gt;% group_by(landuse) %&gt;% summarise(mean_biomass = mean(total_biomass), mean_weight = mean(ptt_weighted_mean_weight, na.rm = TRUE), .groups = &quot;drop_last&quot;) %&gt;% arrange(desc(mean_weight)) %&gt;% identity() -&gt; habitat_mass habitat_mass landuse mean_biomass mean_weight waterbodies 96.527428 1367.6172 agricultural 132.997045 1256.0901 wetlands 197.144370 866.0075 semiopen 31.288826 742.2743 forests 4.002946 246.8706 12.4 Sorting of families by weight Now we sort families according to weight ptt %&gt;% distinct(species, .keep_all = TRUE) %&gt;% group_by(familyvernacular) %&gt;% summarise(mean_weight = mean(mean_weight), .groups = &quot;drop_last&quot;) %&gt;% filter(familyvernacular %in% selected_families) %&gt;% arrange(desc(mean_weight)) %&gt;% rowid_to_column()-&gt; family_weights characteristic_families %&gt;% left_join(family_weights, by = c(&quot;family&quot; = &quot;familyvernacular&quot;)) %&gt;% arrange(desc(mean_weight)) -&gt; characteristic_families characteristic_families$rank &lt;- factor(characteristic_families$mean_weight, ordered = TRUE, levels = characteristic_families$mean_weight) 12.5 Prepare plot And plot a simple barplot figure. characteristic_families %&gt;% pivot_longer(cols = !c(&quot;family&quot;, &quot;rowid&quot;, &quot;mean_weight&quot;, &quot;rank&quot;), names_to = &quot;landuse&quot;, values_to = &quot;family_prop&quot;) -&gt; cf_long colors &lt;- c(&quot;urban&quot; = &quot;#94346E&quot;, &quot;agricultural&quot; = &quot;#73AF48&quot;, &quot;semiopen&quot; = &quot;#EDAD08&quot;, &quot;forests&quot; = &quot;#0F8554&quot;, &quot;wetlands&quot; = &quot;#38A6A5&quot;, &quot;waterbodies&quot; = &quot;#1D6996&quot;, &quot;dist_urban&quot; = &quot;#94346E&quot;, &quot;total_biomass&quot; = &quot;#CC503E&quot;, &quot;dist_radar&quot; = &quot;#666666&quot;) landuse_names &lt;- c(&quot;agricultural&quot; = &quot;Agricultural&quot;, &quot;semiopen&quot; = &quot;Semi-open&quot;, &quot;forests&quot; = &quot;Forests&quot;, &quot;wetlands&quot; = &quot;Wetlands&quot;, &quot;waterbodies&quot; = &quot;Water bodies&quot;) plot_family_proportions &lt;- function(props, which) { landuse_labeller &lt;- function(variable, value) { label &lt;- paste0(landuse_names[value], &quot; &quot;, round(habitat_mass[habitat_mass$landuse == which, ]$mean_weight, digits = 0), &quot;g&quot;) return(label) } proportion_labeller &lt;- function(value) paste0(value * 100, &quot;%&quot;) props %&gt;% filter(landuse == which) %&gt;% ggplot() + geom_col(aes(x = family_prop, y = reorder(family, mean_weight), alpha = family_prop), fill = colors[which]) + labs(x = &quot;Proportion of birds&quot;, y = &quot;Taxonomic group&quot;) + coord_cartesian(expand = FALSE, xlim = c(0, ceiling(max(cf_long$family_prop) * 100) / 100)) + scale_x_continuous(breaks = c(0, 0.1, 0.2, 0.3), labels = proportion_labeller) + scale_alpha_continuous(range = c(0.3, 1)) + facet_wrap(vars(landuse), strip.position = &quot;top&quot;, labeller = landuse_labeller) + theme_classic(base_size = 12) + theme(legend.position = &quot;none&quot;, axis.title.y = element_blank(), strip.background = element_blank(), strip.text.x = element_text(hjust = 0, size = 12, family = &quot;Helvetica&quot;, face = &quot;bold&quot;)) } plots &lt;- mapply(function(landuses) { plot_family_proportions(cf_long, landuses) }, landuses = habitat_mass$landuse, SIMPLIFY = FALSE) ## Warning: The labeller API has been updated. Labellers taking `variable` and `value` arguments are now deprecated. See labellers documentation. ## Warning: The labeller API has been updated. Labellers taking `variable` and `value` arguments are now deprecated. See labellers documentation. ## Warning: The labeller API has been updated. Labellers taking `variable` and `value` arguments are now deprecated. See labellers documentation. ## Warning: The labeller API has been updated. Labellers taking `variable` and `value` arguments are now deprecated. See labellers documentation. ## Warning: The labeller API has been updated. Labellers taking `variable` and `value` arguments are now deprecated. See labellers documentation. p &lt;- wrap_plots(plots) p And we save it as .pdf for editing in Illustrator. ggsave(filename = &quot;data/plots/paper/fig3.pdf&quot;, plot = p, width = 20, height = 14, dpi = 300, units = &quot;cm&quot;) "],
["A1.Generating-VPs-for-Den-Helder-radar.html", "13 Generating vertical profiles for Den Helder radar", " 13 Generating vertical profiles for Den Helder radar The Den Helder radar is situated very close to the coast, so take-off densities derived from the calculate_vp() function in bioRad (Dokter et al. 2019) are likely underestimated as large swaths of sea (both North and Wadden Sea) are contained within the volume. To correct for this, we will select a section, defined by minimum and maximum azimuths, to generate the vertical profiles for. We load the DBZH from the polar volume containing the peak moment of take-off for the Den Helder radar, which occurs at 23:05 UTC. library(bioRad) pvol_path &lt;- &quot;data/raw/pvol/fireworks-2017-2018/RAD_NL61_VOL_NA_201712312305_ODIM.h5&quot; pvol &lt;- read_pvolfile(pvol_path, param = &quot;DBZH&quot;) To illustrate the problem, let’s plot the lowest scan of the pvol we have loaded: scan &lt;- get_scan(pvol, 0.3) plot(scan) As can be seen, there is a large swath of sea clutter, roughly between azimuths 200 and 325. The Wadden Sea can be seen from azimuths 45 until roughly 90. The area in between is where the majority of birds take off: the mainland of North Holland. We can visualise what a focus on this area would cover by plotting a PPI where all values between azimuths 90 and 200 have been set to a very high value. See below: scan_section &lt;- scan scan_section$params$DBZH[, 90:200] &lt;- 100 ppi &lt;- project_as_ppi(scan, grid_size = 100, range_max = 35000) ppi_section &lt;- project_as_ppi(scan_section, grid_size = 100, range_max = 35000) par(pty = &quot;s&quot;, mfrow = c(1, 2)) plot(ppi) plot(ppi_section) Now with that in mind we can calculate the vps for the entire area and compare that with one that is calculated just from the section above (azimuths between 90 and 200). vp_all_azimuths = calculate_vp(pvol_path, verbose = FALSE) vp_land_based_azimuths = calculate_vp(pvol_path, azim_min = 90, azim_max = 200, verbose = FALSE) And plot the corresponding VPs: plot(vp_all_azimuths, main = &quot;VP calculated from the entire Den Helder radar domain&quot;) plot(vp_land_based_azimuths, main = &quot;VP calculated from the main land area covered by Den Helder radar&quot;) We can see there is a substantial difference in density derived from the VPs when focussing on the main land of North Holland vs. when we look at the entire radar domain and include large swaths of the North and Wadden Sea. References "],
["References.html", "14 References", " 14 References "]
]
