[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"","code":""},{"path":"index.html","id":"abstract","chapter":"Preface","heading":"Abstract","text":"Fireworks important parts celebrations globally, little remains known effect wildlife. synchronized extraordinary use fireworks New Year’s Eve causes strong flight response birds. use weather radar systematic bird counts quantify flight response differs across bird communities determine distance-dependence relationship. average, approximately 1000 times birds flight New Year’s Eve regular nights. found disturbance fireworks decreases distance, strongly first 5 km, overall flight activity remained elevated tenfold 10 km. found communities large-bodied species respond strongly smaller birds. Given pervasive nature disturbance, mitigation achieved establishing large firework-free zones centralizing fireworks urban centers. Conservation action prioritize disturbance-prone, larger-bodied, bird communities.","code":""},{"path":"index.html","id":"authors","chapter":"Preface","heading":"Authors","text":"Bart Hoekstra1, Willem Bouten1, Adriaan Dokter1,2, Hans van Gasteren1,3, Chris van Turnhout4,5, Bart Kranstauber1, Emiel van Loon1, Hidde Leijnse6,7, Judy Shamoun-Baranes11 Institute Biodiversity Ecosystem Dynamics, University Amsterdam, P.O. Box 94240, 1090 GE Amsterdam, Netherlands2 Cornell Lab Ornithology, Cornell University, 159 Sapsucker Woods Rd, Ithaca, NY 14850, United States America3 Royal Netherlands Air Force, P.O Box 8762, 4820 BB Breda, Netherlands4 Sovon Dutch Centre Field Ornithology, P.O. Box 6521, 6503 GA Nijmegen, Netherlands5 Department Animal Ecology & Physiology, Institute Biological Environmental Sciences (RIBES), Radboud University, P.O. Box 9010, 6500 GL Nijmegen, Netherlands6 R&D Observations Data Technology, Royal Netherlands Meteorological Institute, De Bilt, Netherlands7 Hydrology Quantitative Water Management Group, Wageningen University & Research, Wageningen, Netherlands","code":""},{"path":"index.html","id":"how-to-use-this-document","chapter":"Preface","heading":"How to use this document","text":"","code":""},{"path":"index.html","id":"run-interactively","chapter":"Preface","heading":"Run interactively","text":"RMarkdown notebook files run successively order numbering, starting 01.Selecting-take--moments.Rmd.","code":""},{"path":"index.html","id":"knit-it","chapter":"Preface","heading":"Knit it","text":"Use following line console click Build Book RStudio.","code":"\nbookdown::render_book(input = \"index.Rmd\", output_format = \"bookdown::bs4_book\", clean = TRUE)"},{"path":"index.html","id":"full-repro-mode","chapter":"Preface","heading":"Full-reproduction mode","text":"spirit reproducibility, entire analysis can theoretically reproduced push button. facilitate faster reproduction, code chunks run full reproduction mode switched . can done setting R variable full_repro TRUE build_bookdown.R.","code":""},{"path":"selecting-firework-take-off-moment.html","id":"selecting-firework-take-off-moment","chapter":"1 Selecting firework take-off moment","heading":"1 Selecting firework take-off moment","text":"study select moment ‘en masse’ take-birds turn year. make sure birds still fairly ‘close’ take-habitat, therefore focus period increase VIR (Vertically Integrated Reflectivity) highest. Based experience, one expect occur 00:05 00:15 January 1st, people tend light fireworks right shared New Year’s wishes .","code":""},{"path":"selecting-firework-take-off-moment.html","id":"processing-environment","chapter":"1 Selecting firework take-off moment","heading":"1.1 Processing environment","text":"use vol2bird included bioRad package (Dokter et al. 2019) calculate vertical profiles reflectivity, determine exact take moment birds. implies assume birds take skies everywhere simultaneously, seems realistic assumption given lighting fireworks synchronised national time, rather local time sunset/sunrise.","code":"\nlibrary(bioRad)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nSys.setenv(TZ = \"UTC\")"},{"path":"selecting-firework-take-off-moment.html","id":"calculate-the-vertical-profiles","chapter":"1 Selecting firework take-off moment","heading":"1.2 Calculate the vertical profiles","text":"calculate vertical profiles period December 31st, 2017 22:00 01:00 UTC January 1st, 2018, corresponds 23:00 til 02:00 local Amsterdam time (UTC + 1). necessary generate many vp files, gives better temporal overview event add ‘temporal padding’ around fireworks event.Beware: calculate vertical profiles, running instance Docker required. code chunk run full-reproduction mode.See appendix [generating VPs Den Helder][generating-vps--den-helder-radar] detailed explanation limit vp generation Den Helder certain azimuths.","code":"\nfireworks_scans <- Sys.glob(file.path(\"data/raw/pvol/fireworks-2017-2018\", \"*_ODIM.h5\"))\ncat(\"Files left to process: \", length(fireworks_scans), \"\\n\")\ni <- 1\nfor (scan in fireworks_scans) {\n  if (i %% 5 == 0) {\n    cat(i, \"... \")\n  }\n  \n  vpfile_out <- sub(\"raw/pvol/fireworks-2017-2018\", \"processed/vp/fireworks-2017-2018\", scan)\n  if (grepl(\"RAD_NL61\", vpfile_out)) {\n    try(calculate_vp(scan, vpfile = vpfile_out, verbose = FALSE, mount = dirname(fireworks_scans[1]),\n                     azim_min = 90, azim_max = 200, h_layer = 50, n_layer = 80))\n  } else {\n    try(calculate_vp(scan, vpfile = vpfile_out, verbose = FALSE, mount = dirname(fireworks_scans[1]),\n                     h_layer = 50, n_layer = 80))\n  }\n  i <- i + 1\n}"},{"path":"selecting-firework-take-off-moment.html","id":"generate-time-series-of-vertical-profiles","chapter":"1 Selecting firework take-off moment","heading":"1.3 Generate time series of vertical profiles","text":"can now generate time series vertical profiles (VPTS) plot bird densities get idea going NYE 2017-2018.plots Herwijnen Den Helder show exactly expect: comparatively low densities birds aloft leading midnight (23:00 CET), suddenly strong increase birds right midnight. Den Helder peak appears much pronounced, whereas Herwijnen period disturbance seems take considerably longer. probably due vastly different environment around radar site: Herwijnen located solidly center country, whereas Den Helder located close coast ‘peninsula’ much less land surroundings, pronounced vol2bird taking rangegates within 5-35km radar account.","code":"\nfw_hrw_vpts <- Sys.glob(file.path(\"data/processed/vp/fireworks-2017-2018\", \"*NL62*\")) %>%\n  read_vpfiles() %>%\n  bind_into_vpts() %>%\n  regularize_vpts(interval = \"auto\")\n\nfw_dhl_vpts <- Sys.glob(file.path(\"data/processed/vp/fireworks-2017-2018\", \"*NL61*\")) %>%\n  read_vpfiles() %>%\n  bind_into_vpts() %>%\n  regularize_vpts(interval = \"auto\")\n\nstart <- as.POSIXct(\"2017-12-31 22:00:00\")\nend <- as.POSIXct(\"2018-01-01 01:00:00\")\n\nindexes_hrw <- which(fw_hrw_vpts$datetime >= start & fw_hrw_vpts$datetime <= end)\nindexes_dhl <- which(fw_dhl_vpts$datetime >= start & fw_dhl_vpts$datetime <= end) # Should mostly be identical\n\ntitle_hrw <- expression(\"Herwijnen: volume density [#/km\"^3 * \"]\")\ntitle_dhl <- expression(\"Den Helder: volume density [#/km\"^3 * \"]\")\nplot(fw_hrw_vpts[indexes_hrw], main = title_hrw)\nplot(fw_dhl_vpts[indexes_dhl], main = title_dhl)## projecting on 300 seconds interval grid...\n## projecting on 300 seconds interval grid..."},{"path":"selecting-firework-take-off-moment.html","id":"identifying-moment-of-take-off","chapter":"1 Selecting firework take-off moment","heading":"1.4 Identifying moment of take-off","text":"integrate time series vertical profiles, can calculate VIR derivatives determine volume scan birds really take skies radar separately.plot shows rapid increase VIR first 15 20 minutes midnight (23:00 CET) Den Helder Herwijnen radar respectively. period, VIR starts drop, faster Den Helder Herwijnen, possibly result birds dispersing North Holland mainland towards IJsselmeer area, deliberately excluded generation vertical profiles (selecting azimuths land).reduce effect bird dispersal analysis, focus first 5 minute-scan VIR grows rapidly. 23:05 CET 23:10 CET.mainly focus working following polar volume files:Herwijnen: RAD_NL62_VOL_NA_201712312305_ODIM.h5Den Helder: RAD_NL61_VOL_NA_201712312305_ODIM.h5","code":"\nintegrated_hrw <- integrate_profile(fw_hrw_vpts)\nintegrated_dhl <- integrate_profile(fw_dhl_vpts)\n\nintegrated_hrw$vir_deriv <- c(NA, diff(integrated_hrw$vir, 1))\nintegrated_dhl$vir_deriv <- c(NA, diff(integrated_dhl$vir, 1))\n\nintegrated_hrw$radar <- \"Herwijnen\"\nintegrated_dhl$radar <- \"Den Helder\"\n\nintegrated <- rbind(integrated_hrw, integrated_dhl)\n\nintegrated_l <- integrated %>%\n  pivot_longer(-c(\"datetime\", \"radar\"), names_to = \"variable\", values_to = \"value\") %>%\n  filter(variable == \"vir\" | variable == \"vir_deriv\") %>%\n  filter(datetime >= start & datetime <= end)\n\nmax_vir_deriv <- integrated_l %>%\n  filter(variable == \"vir_deriv\") %>%\n  drop_na() %>%\n  group_by(radar) %>%\n  summarize(max_value = max(value), datetime = datetime[which.max(value)], .groups = \"drop_last\")\n\ntheme_set(theme_bw())\nggplot(integrated_l, aes(x = datetime)) +\n  geom_line(aes(y = value, colour = radar, linetype = variable)) +\n  scale_x_datetime(breaks = \"10 min\", date_labels = \"%H:%M\", expand = c(0, 0), timezone = \"Europe/Amsterdam\") + \n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  scale_linetype_discrete(name = \"Line type\", labels = c(\"VIR\", expression(paste(Delta,\"VIR/scan\")))) + \n  labs(title = \"Time series of Vertically Integrated Reflectivities (VIR)\",\n       subtitle = \"NYE 2017-2018\",\n       x = \"Time\",\n       y = \"VIR\",\n       colour = \"Radar\",\n       linetype = \"Linetype\") +\n  theme(axis.text.x = element_text(angle = -90),\n        panel.grid.minor = element_blank())\n# integrated_l %>%\n#   filter(variable == \"vir\",\n#          datetime < \"2018-01-01 00:30:00\") %>%\n#   mutate(datetime = datetime + 2.5*60) %>%\n#   ggplot(aes(x = datetime)) +\n#   geom_rect(aes(xmin = as.POSIXct(\"2017-12-31 23:05:00\"), xmax = as.POSIXct(\"2017-12-31 23:10:00\"),\n#               ymin = -1000, ymax = 5000), fill = \"lightgrey\", alpha = 0.1, color = \"grey50\") +\n#   geom_line(aes(y = value, colour = radar)) +\n#   scale_x_datetime(breaks = \"10 min\", date_labels = \"%H:%M\", expand = c(0, 0), timezone = \"Europe/Amsterdam\") + \n#   scale_color_manual(values = c(\"blue\", \"red\")) +\n#   # scale_linetype_discrete(name = \"Line type\", labels = c(\"VIR\", expression(paste(Delta,\"VIR/scan\")))) + \n#   # scale_x_datetime(labels = date_format(\"%m/%d %H:%M\", tz = \"America/Toronto\"))\n#   # labs(title = \"Time series of Vertically Integrated Reflectivities (VIR)\",\n#   #      subtitle = \"NYE 2017-2018\",\n#   labs(x = \"Time\",\n#        y = \"VIR\") +\n#   coord_cartesian(expand = FALSE, ylim = c(0, 2250)) +\n#   theme_classic(base_size = 15) +\n#   theme(axis.text.x = element_text(angle = -90),\n#         panel.grid.minor = element_blank(),\n#         legend.position = \"none\")\n#   \n\n# ggsave(\"data/plots/presentations/VIR-Timeseries.pdf\", width = 8, height = 5)\npvol_folder <- \"data/raw/pvol/fireworks-2017-2018/\"\nscan_timestamp <- lubridate::ymd_hm(\"2017-12-31 23:05\")\n\npvol_hrw_path <- paste(pvol_folder, \"RAD_NL62_VOL_NA_\", format(scan_timestamp, \"%Y%m%d%H%M\"), \"_ODIM.h5\", sep = \"\")\npvol_dhl_path <- paste(pvol_folder, \"RAD_NL61_VOL_NA_\", format(scan_timestamp, \"%Y%m%d%H%M\"), \"_ODIM.h5\", sep = \"\")\n\nsave(pvol_hrw_path, pvol_dhl_path, file = \"data/processed/pvol_selection.RData\")"},{"path":"selecting-firework-take-off-moment.html","id":"determining-maximum-range-from-radar-to-detect-birds","chapter":"1 Selecting firework take-off moment","heading":"1.5 Determining maximum range from radar to detect birds","text":"can assume flight altitudes derived vol2bird representative flight altitudes throughout country. Given disturbance happens comparatively low altitudes, radar likely ‘overshoot’ entirely substantial distances away radar compensating range-effects (e.g. using Kranstauber et al. (2020)) thus undesired consequences. Therefore need determina maximum range still feasibly measure birds aloft. can inspecting vpts plots , now focussing lowest 1km. Notice generating VPTSs 50m height bins vs. standard 100m height bins, can pinpoint precisely altitude densities drop .can now see 600m ASL density starts drop substantially, set altitudinal cutoff determine range using data coming range-bias correction (Kranstauber et al. 2020). Although birds somewhat lower height overall Den Helder Herwijnen, acceptable threshold Herwijnen anyways covers much land area within study domain Den Helder, thus representative range-bias correction Herwijnen important Den Helder.Now can calculate distance height (600m) height lowest elevation (0.3 degrees) round nearest kilometer.roughly 66 kilometers radar, lowest elevation scan pierces sky altitude 600m.","code":"\nplot(fw_hrw_vpts[indexes_hrw], ylim = c(0, 1000))\nplot(fw_dhl_vpts[indexes_dhl], ylim = c(0, 1000))\naltitude_cutoff <- 600\nranges <- seq(0, 180000, 100)\nbeamheights <- beam_height(ranges, 0.3)\nnearest_index <- which(abs(beamheights - altitude_cutoff) == min(abs(beamheights - altitude_cutoff)))\nslantrange <- ranges[nearest_index]\ndistance_cutoff <- plyr::round_any(beam_distance(slantrange, 0.3), 1000)\ndistance_cutoff## [1] 66000"},{"path":"radar-data-preprocessing.html","id":"radar-data-preprocessing","chapter":"2 Radar Data Preprocessing","heading":"2 Radar Data Preprocessing","text":"Weather radar data firework events turns years usually contain degree precipitation clutter. filter precipitation advanced algorithms MistNet developed, dealing dual-polarization radar data , can use simpler yet robust method using depolarization ratio (Kilambi, Fabry, Meunier 2018).make sure processed weather radar data contain significant proportions precipitation ground clutter anymore, process data follows:remove electromagnetic interference based visual inspection scans throw data affected rays.calculate depolarization ratio (Kilambi, Fabry, Meunier 2018) separate biology meteorology classifying range gates depolarization ratio \\(>-12dB\\) biology. subsequently ‘despeckle’ , remove obvious misclassifications.average reflectivity number scans time fireworks event throw range-gates highest average reflectivities.steps can undertaken directly polar volume data, can subsequently plug cleaned volume range-bias correction.","code":""},{"path":"radar-data-preprocessing.html","id":"processing-environment-1","chapter":"2 Radar Data Preprocessing","heading":"2.1 Processing environment","text":"usual, processing takes place using bioRad (Dokter et al. 2019).","code":"\nlibrary(bioRad)\nlibrary(plotly)\nlibrary(gridExtra)\nlibrary(ggpubr)\nlibrary(mapview)\nlibrary(viridis)\nlibrary(raster)\nlibrary(dplyr)\nlibrary(magrittr)"},{"path":"radar-data-preprocessing.html","id":"removing-electromagnetic-interference","chapter":"2 Radar Data Preprocessing","heading":"2.2 Removing electromagnetic interference","text":"determined scans birds taking based maximum increase reflectivity scan involved radars. Let’s now look scans see much filtering electromagnetic interference need . easiest way determine rays subject interference plotting scans polar coordinates \\((r, \\alpha)\\), interference stands horizontal lines less constant, gradually changing reflectivities. Plotting using plotly makes easier identify specific problematic rays one can zoom identify exact azimuths \\(\\alpha\\) interference occurs, web version stick static plots using bioRad:::plot.scan().scans using:Herwijnen: RAD_NL62_VOL_NA_201712312305_ODIM.h5Den Helder: RAD_NL61_VOL_NA_201712312305_ODIM.h5For illustrative purposes illustrate removal EM interference Herwijnen radar, procedure Den Helder exactly identical, scan contains little said clutter.Right away can see rays two places scan subject electromagnetic interference. probably problematic lowest elevations volume scan, nevertheless 16 scans checked manually. results identification following rays contain electromagnetic interference (ei_rays), organised list scan numbers (organised ascendingly per elevation angle) keys. Admittedly: another ray seems contain interference first scan, far away radar (150km+) affect results meaningful numbers birds can detected range anyways thus exclude analysis. Similarly, similar patterns interference/clutter higher elevation scans, affect results.can now remove data affected rays corresponding scans setting values NA (see R/remove_rays.R).","code":"\npvol_hrw <- read_pvolfile(pvol_hrw_path, param = \"all\")\npvol_dhl <- read_pvolfile(pvol_dhl_path, param = \"all\")\n\nscan <- plot(pvol_hrw$scans[[1]], param = \"DBZH\", xlim = c(0, 180000)) + theme_dark()\n# ggplotly(scan)  # Use when manually filtering EM contaminated beams\nplot(scan)\nei_rays_hrw <- list(c(201, 202, 214, 215), # scan 1\n                    c(201, 202, 214, 215), # scan 2\n                    c(201, 202, 214, 215), # scan 3\n                    c(202, 214, 215))      # scan 4\nnames(ei_rays_hrw) <- c(1, 2, 3, 4)\n\nei_rays_dhl <- list(c(60, 61)) # scan 1\nnames(ei_rays_dhl) <- c(1)\nsource(\"R/remove_rays.R\")\npvol_hrw <- remove_rays(pvol_hrw, rays = ei_rays_hrw)\npvol_dhl <- remove_rays(pvol_dhl, rays = ei_rays_dhl)"},{"path":"radar-data-preprocessing.html","id":"verify-removal-of-rays-with-em-interference","chapter":"2 Radar Data Preprocessing","heading":"2.2.1 Verify removal of rays with EM interference","text":"removal correct, \\((r,\\alpha)\\) plots show clear horizontal structures anymore.seems work nicely.","code":"\ni = 1\nplot(pvol_hrw$scans[[i]], param = \"DBZH\", xlim = c(0, 180000)) + theme_dark() + \n  labs(title = \"Herwijnen: Cleaned from EM interference\", subtitle = paste(\"Elevation:\", round(pvol_hrw$scans[[i]]$attributes$where$elangle, 1)))\nplot(pvol_dhl$scans[[i]], param = \"DBZH\", xlim = c(0, 180000)) + theme_dark() + \n  labs(title = \"Den Helder: Cleaned from EM interference\", subtitle = paste(\"Elevation:\", round(pvol_dhl$scans[[i]]$attributes$where$elangle, 1)))"},{"path":"radar-data-preprocessing.html","id":"filter-meteorology-using-the-depolarization-ratio","chapter":"2 Radar Data Preprocessing","heading":"2.3 Filter meteorology using the depolarization ratio","text":"Meteorology can filtered using depolarization ratio following Kilambi et al. (2018). calculate depolarization ratio raw pvol data EM interference removed subsequently ‘despeckle’ results improve classification.Despeckling works comparing classification majority neighbourhood rangegates classification center rangegate, changing latter reflect majority neighbourhood classification difference. define ‘neighbourhood’ \\(3^{\\circ}\\) \\(3 \\times rscale\\) area centered around focal rangegate (3 rangegates azimuth \\(\\times\\) 3 rangegates range). Selecting rangegates taking sphericity radar scan account (e.g. ray 360 directly adjacent ray 1) made easier R/window_coords.R function. despeckling implemented R/despeckle_scan_logical.R.despeckling algorithm place, can:Calculate depolarization ratio (DPR).Classify biology rangegates DPR > -12 store classification BIOLR (Biology Raw) scan parameter pvol object.Despeckle classification store outcome BIOLD (Biology Despeckled) scan parameter pvol object.","code":"\nsource(\"R/window_coords.R\")\nsource(\"R/despeckle_scan_logical.R\")\n\n# Calculate depolarization ratio, classify and despeckle biology classifications for the entire volume\ncalculate_dpr <- function(pvol){\n  for (i in seq_along(pvol$scans)) {\n    # Calculate ZDR as ZDR = DBZH - DBZV\n    pvol$scans[[i]]$params$ZDR <- pvol$scans[[i]]$params$DBZH - pvol$scans[[i]]$params$DBZV\n    attributes(pvol$scans[[i]]$params$ZDR)$param <- \"ZDR\"\n    \n    # Calculate depolarization ratio\n    zdr_linear <- 10 ** (pvol$scans[[i]]$params$ZDR / 10)\n    dpr_linear <- (zdr_linear + 1 - 2 * sqrt(zdr_linear) * pvol$scans[[i]]$params$RHOHV) / \n                  (zdr_linear + 1 + 2 * sqrt(zdr_linear) * pvol$scans[[i]]$params$RHOHV)\n    pvol$scans[[i]]$params$DPR <- 10 * log10(dpr_linear)\n    attributes(pvol$scans[[i]]$params$DPR)$param <- \"DPR\"\n    \n    # Classify based on depolarization ratio\n    biology <- (pvol$scans[[i]]$params$DPR > -12) * 1  # multiply by 1 to convert TRUE/FALSE to 1/0\n    class(biology) <- c(\"param\", \"matrix\")\n    attributes(biology) <- attributes(pvol$scans[[i]]$params$DPR)  # copy attributes from DPR\n    attributes(biology)$param <- \"BIOLR\"\n    pvol$scans[[i]]$params$BIOLR <- biology\n    \n    # Despeckle biology classification\n    pvol$scans[[i]]$params$BIOLD <- pvol$scans[[i]]$params$BIOLR\n    pvol$scans[[i]]$params$BIOLD <- despeckle_scan_logical(pvol$scans[[i]]$params$BIOLD)\n    attributes(pvol$scans[[i]]$params$BIOLD)$param <- \"BIOLD\"\n  }\n  \n  return(pvol)\n}\n\npvol_hrw <- suppressWarnings(calculate_dpr(pvol_hrw)) # Will throw NaN warnings if not suppressed\npvol_dhl <- suppressWarnings(calculate_dpr(pvol_dhl)) "},{"path":"radar-data-preprocessing.html","id":"verify-dpr-based-classification","chapter":"2 Radar Data Preprocessing","heading":"2.3.1 Verify DPR-based classification","text":"Now let’s plot PPIs verify accuracy DPR-based classification subsequent despeckling, plotting DBZH, VRADH, DPR, BIOLR BIOLD.plots show accurate classification obvious precipitation zones, except edges echoes, BIOLD vast improvement BIOLR, showing value despeckling. Similarly, lot ‘noise’ birds , despeckling takes care quite nicely well. Additionally, shows pattern expect see: closer distances radar ‘speckles’ near precipitation zones turned biology, distances radar often ‘flipped’ meteorology. method may perfect, classifies birds quite conservatively. misclassifications remain affect results much, number occur centers precipitation echoes, likely turn numerical outliers.","code":"\nsource(\"R/side_by_side_ppi.R\")\nside_by_side_ppi(pvol_hrw, pvol_dhl, \"Herwijnen\", \"Den Helder\", params = c(\"DBZH\", \"VRADH\", \"DPR\", \"BIOLR\", \"BIOLD\"))"},{"path":"radar-data-preprocessing.html","id":"remove-classified-precipitation-from-polar-volumes","chapter":"2 Radar Data Preprocessing","heading":"2.4 Remove classified precipitation from polar volumes","text":"Now accurate classifications rangegates based depolarization ratios, can start remove precipitation polar volumes, retain scan comprises birds (occasional misclassifications). areas DPR DBZH overlap, also remove rangegates classified.Plotting PPIs now show cleaned-/precipitation-free scan next classifications.looks good Herwijnen Den Helder radars, latter lot sea clutter still needs removed, next list filtering ground clutter.","code":"\nsource(\"R/remove_precipitation.R\")\npvol_hrw <- remove_precipitation(pvol_hrw)\npvol_dhl <- remove_precipitation(pvol_dhl)\nside_by_side_ppi(pvol_hrw, pvol_dhl, \"Herwijnen\", \"Den Helder\", params = c(\"DBZH\", \"VRADH\"))"},{"path":"radar-data-preprocessing.html","id":"filter-ground-clutter","chapter":"2 Radar Data Preprocessing","heading":"2.5 Filter ground clutter","text":"filter ground clutter calculating summary statistics rangegate reflectivities :36 scans preceding scans selected study fireworks event (= 3 hours worth scans).day clear weather closest 31st December 2017.filter ground clutter based mean DBZH values. Using variance mad DBZH tested, difficulties:variance sensitive outliers caused rangegates NA values (detection ‘mds’, minimum detectable signal) occasionally flipping noisy measurement, resulting high variances.mad much robust outliers, compute values need set NA cells ‘mds’ (minimum detectable signal), result mad values close , exactly 0 cells never reflected well true static clutter, ’s difficult separate .Finally, visual inspection showed mean mad DBZH (assuming one overcome aforementioned problem latter) differ much, mean somewhat ‘aggressive’ filtering, case quite good.Combining clutter removal based clear day well 36 preceding scans lets us account truly static clutter (e.g. buildings) well clutter dynamic sea wind park clutter, without also requiring us resort filtering dynamic clutter using VRADH threshold. quality filtering assessed visually.","code":""},{"path":"radar-data-preprocessing.html","id":"dynamic-clutter","chapter":"2 Radar Data Preprocessing","heading":"2.5.1 Dynamic clutter","text":"select 36 (3 hours worth scans) preceding start fireworks (23:00 UTC) add additional margin 3 scans (15 minutes scans) VIR plots previous chapter shown numbers birds aloft low stable period.can now loop files one one stack reflectivity data (DBZH) — filtering precipitation — multidimensional array.Note: following code chunk run full-reproduction mode takes quite lot time. Results saved, next iteration chunk can skipped.DBZH compiled single multidimensional array, can calculate mean reflectivity, store DBZH_AVG pvol now contains dynamic clutter map.","code":"\navailable_scans_hrw <- Sys.glob(file.path(\"data/raw/pvol/clutter-removal-20171231\", \"*NL62*20171231*\"))\navailable_scans_dhl <- Sys.glob(file.path(\"data/raw/pvol/clutter-removal-20171231\", \"*NL61*20171231*\"))\nfw_start_hrw_pvol_path <- \"data/raw/pvol/fireworks-2017-2018/RAD_NL62_VOL_NA_201712312300_ODIM.h5\"\nfw_start_dhl_pvol_path <- \"data/raw/pvol/fireworks-2017-2018/RAD_NL61_VOL_NA_201712312300_ODIM.h5\"\nselected_scan_hrw <- sub(\"fireworks-2017-2018\", \"clutter-removal-20171231\", fw_start_hrw_pvol_path)\nselected_scan_dhl <- sub(\"fireworks-2017-2018\", \"clutter-removal-20171231\", fw_start_dhl_pvol_path)\n\nselected_scan_id_hrw <- match(selected_scan_hrw, available_scans_hrw)\nselected_scan_id_dhl <- match(selected_scan_dhl, available_scans_dhl)\n\nusable_scans_hrw <- available_scans_hrw[(selected_scan_id_hrw-dynamic_time_margin-dynamic_nr_preceding_scans+1):\n                                          (selected_scan_id_hrw-dynamic_time_margin)]\nusable_scans_dhl <- available_scans_dhl[(selected_scan_id_dhl-dynamic_time_margin-dynamic_nr_preceding_scans+1):\n                                          (selected_scan_id_dhl-dynamic_time_margin)]\nsource(\"R/stack_rainfree_reflectivities.R\")\nstack_rainfree_reflectivities(usable_scans_hrw, outputfile = \"data/processed/clutter_dynamic_hrw.RDS\")\nstack_rainfree_reflectivities(usable_scans_dhl, outputfile = \"data/processed/clutter_dynamic_dhl.RDS\")\npvol_clutter_dynamic_hrw <- readRDS(\"data/processed/clutter_dynamic_hrw.RDS\")\npvol_clutter_dynamic_dhl <- readRDS(\"data/processed/clutter_dynamic_dhl.RDS\")\n\nsource(\"R/calculate_reflectivity_stack_mean.R\")\n\npvol_clutter_dynamic_hrw <- calculate_reflectivity_stack_mean(pvol_clutter_dynamic_hrw, mds)\npvol_clutter_dynamic_dhl <- calculate_reflectivity_stack_mean(pvol_clutter_dynamic_dhl, mds)\n\nsaveRDS(pvol_clutter_dynamic_hrw, \"data/processed/clutter_dynamic_hrw_avg.RDS\")\nsaveRDS(pvol_clutter_dynamic_dhl, \"data/processed/clutter_dynamic_dhl_avg.RDS\")\npvol_clutter_dynamic_hrw <- readRDS(\"data/processed/clutter_dynamic_hrw_avg.RDS\")\npvol_clutter_dynamic_dhl <- readRDS(\"data/processed/clutter_dynamic_dhl_avg.RDS\")"},{"path":"radar-data-preprocessing.html","id":"verify-dynamic-clutter-map","chapter":"2 Radar Data Preprocessing","heading":"2.5.1.1 Verify dynamic clutter map","text":"Let’s see looks like basemap, using DBZH_AVG threshold \\(-10dbZ\\), following (Dokter et al. 2011).Visually assessing clutter map shows works quite well, selecting e.g. areas wind parks, sea clutter, high buildings, industry, etc. Exactly hoped achieve.","code":"\nscan_hrw <- pvol_clutter_dynamic_hrw$scans[[1]]\nscan_dhl <- pvol_clutter_dynamic_dhl$scans[[1]]\n\nside_by_side_ppi(pvol_clutter_dynamic_hrw, pvol_clutter_dynamic_dhl, \"Herwijnen dynamic clutter\", \"Den Helder dynamic clutter\", \n                 params = \"DBZH_AVG\", range_max = 50000, scan_id = 1, basemap = TRUE, zlim = c(-11, -10))"},{"path":"radar-data-preprocessing.html","id":"static-clutter","chapter":"2 Radar Data Preprocessing","heading":"2.5.2 Static clutter","text":"Now, let’s retry exactly procedure, time selecting day precipitation, can done using tool KNMI, can filter truly static clutter.select following days:Herwijnen: December 29th, 2017Den Helder: December 25th, 2017Note: following code chunk run full-reproduction mode takes lot time run. Results saved, next iteration chunk can skipped.calculate mean DBZH values (DBZH_AVG).","code":"\nsource(\"R/stack_rainfree_reflectivities.R\")\navailable_scans_hrw <- Sys.glob(file.path(\"data/raw/pvol/clutter-removal-20171229-hrw\", \"*NL62*20171229*\"))\navailable_scans_dhl <- Sys.glob(file.path(\"data/raw/pvol/clutter-removal-20171225-dhl\", \"*NL61*20171225*\"))\n\nstack_rainfree_reflectivities(available_scans_hrw, outputfile = \"data/processed/clutter_static_hrw.RDS\")\nstack_rainfree_reflectivities(available_scans_dhl, outputfile = \"data/processed/clutter_static_dhl.RDS\")\npvol_clutter_static_hrw <- readRDS(\"data/processed/clutter_static_hrw.RDS\")\npvol_clutter_static_dhl <- readRDS(\"data/processed/clutter_static_dhl.RDS\")\n\nsource(\"R/calculate_reflectivity_stack_mean.R\") # Source because full_repro may be set to FALSE\n\npvol_clutter_static_hrw <- calculate_reflectivity_stack_mean(pvol_clutter_static_hrw, mds)\npvol_clutter_static_dhl <- calculate_reflectivity_stack_mean(pvol_clutter_static_dhl, mds)\n\nsaveRDS(pvol_clutter_static_hrw, \"data/processed/clutter_static_hrw_avg.RDS\")\nsaveRDS(pvol_clutter_static_dhl, \"data/processed/clutter_static_dhl_avg.RDS\")\npvol_clutter_static_hrw <- readRDS(\"data/processed/clutter_static_hrw_avg.RDS\")\npvol_clutter_static_dhl <- readRDS(\"data/processed/clutter_static_dhl_avg.RDS\")"},{"path":"radar-data-preprocessing.html","id":"verify-static-clutter-map","chapter":"2 Radar Data Preprocessing","heading":"2.5.2.1 Verify static clutter map","text":", let’s see looks like basemap, using DBZH_AVG threshold \\(-10dbZ\\), following (Dokter et al. 2011).","code":"\nscan_hrw <- pvol_clutter_static_hrw$scans[[1]]\nscan_dhl <- pvol_clutter_static_dhl$scans[[1]]\n\nside_by_side_ppi(pvol_clutter_static_hrw, pvol_clutter_static_dhl, \"Herwijnen static clutter\", \"Den Helder static clutter\", \n                 params = \"DBZH_AVG\", range_max = 50000, scan_id = 1, basemap = TRUE, zlim = c(-11, -10))"},{"path":"radar-data-preprocessing.html","id":"remove-dynamic-and-static-clutter","chapter":"2 Radar Data Preprocessing","heading":"2.5.3 Remove dynamic and static clutter","text":"Now identified dynamic static clutter, can create final cleaned polar volume.","code":"\nsource(\"R/remove_groundclutter.R\")\npvol_hrw <- remove_groundclutter(remove_groundclutter(pvol_hrw, pvol_clutter_dynamic_hrw), pvol_clutter_static_hrw)\npvol_dhl <- remove_groundclutter(remove_groundclutter(pvol_dhl, pvol_clutter_dynamic_dhl), pvol_clutter_static_dhl)\n\nsaveRDS(pvol_hrw, file = \"data/processed/pvol_clean_hrw.RDS\")\nsaveRDS(pvol_dhl, file = \"data/processed/pvol_clean_dhl.RDS\")"},{"path":"radar-data-preprocessing.html","id":"range-bias-correction","chapter":"2 Radar Data Preprocessing","heading":"2.6 Range-bias correction","text":"identifiable sources clutter removed raw polar volume, can apply range-bias correction (Kranstauber et al. 2020). necessary calculate local vertical profile radars. Ideally, done using filtered pvol now generated, vol2bird algorithm (Dokter et al. 2011) takes pvol files input, rather R objects. implementation converter yet, now vp raw pvol files . precipitation within relevant distance radars (5-35km), calculated vp based raw pvol files differ wildly filtered pvol R object generated previous steps.Den Helder radar calculate vp setting azimuthal limits cover mainland North Holland, rather whole radar domain, latter result vps underestimate true density birds aloft. See [corresponding appendix][generating-vps--den-helder-radar] detailed explanation.can now plot final range-corrected PPIs.","code":"\nvp_hrw <- calculate_vp(file = pvol_hrw_path, vpfile = paste(\"data/processed/vp/\", basename(pvol_hrw_path), sep = \"\"), verbose = FALSE)\nvp_dhl <- calculate_vp(file = pvol_dhl_path, vpfile = paste(\"data/processed/vp/\", basename(pvol_dhl_path), sep = \"\"), \n                       verbose = FALSE, azim_min = 90, azim_max = 200)\n\ncorrected_ppi_hrw <- integrate_to_ppi(pvol_hrw, vp_hrw, res = 500, xlim = c(-150000, 150000), ylim = c(-150000, 150000))\ncorrected_ppi_dhl <- integrate_to_ppi(pvol_dhl, vp_dhl, res = 500, xlim = c(-150000, 150000), ylim = c(-150000, 150000))\n\nsaveRDS(corrected_ppi_hrw, file = \"data/processed/corrected_ppi_hrw.RDS\")\nsaveRDS(corrected_ppi_dhl, file = \"data/processed/corrected_ppi_dhl.RDS\")\np_vir_hrw <- plot(corrected_ppi_hrw, param = \"VIR\", zlim = c(0, 20000)) + labs(title = \"Herwijnen: VIR\")\np_vir_dhl <- plot(corrected_ppi_dhl, param = \"VIR\", zlim = c(0, 20000)) + labs(title = \"Den Helder: VIR\")\nggarrange(p_vir_hrw, p_vir_dhl, ncol = 2, nrow = 1, common.legend = TRUE, legend = \"right\")"},{"path":"radar-data-preprocessing.html","id":"keep-biologymeteorology-classification","chapter":"2 Radar Data Preprocessing","heading":"2.7 Keep biology/meteorology classification","text":"default range-bias correction returns values 0 upwards, way us distinguish anymore ‘pixels’ reflect filtered meteorology. ’s additionally add class parameter range-bias corrected PPIs. avoid misalignment differences vertical integration compared range-bias correction, can ‘trick’ RBC replacing DBZH values expects BIOLD(despeckled biology) values (either 0 meteorology 1 biology) multiplied 1000. result high integrated values VIR area classified biology low values classified meteorology.looks good, now add corrected PPIs. reclassify VIR follows:Biology gets class = 2,Meteorology gets class = 1,Background gets class = 0.","code":"\npvol_hrw_classified <- calculate_param(pvol_hrw, DBZH = BIOLD * 1000)\npvol_dhl_classified <- calculate_param(pvol_dhl, DBZH = BIOLD * 1000)\n\npvol_hrw_classified <- remove_groundclutter(remove_groundclutter(pvol_hrw_classified, pvol_clutter_dynamic_hrw), pvol_clutter_static_hrw)\npvol_dhl_classified <- remove_groundclutter(remove_groundclutter(pvol_dhl_classified, pvol_clutter_dynamic_dhl), pvol_clutter_static_dhl)\n\ncorrected_ppi_hrw_classified <- integrate_to_ppi(pvol_hrw_classified, vp_hrw, res = 500, xlim = c(-150000, 150000), ylim = c(-150000, 150000))\ncorrected_ppi_dhl_classified <- integrate_to_ppi(pvol_dhl_classified, vp_dhl, res = 500, xlim = c(-150000, 150000), ylim = c(-150000, 150000))\np_vir_hrw_classified <- plot(corrected_ppi_hrw_classified, param = \"VIR\", zlim = c(0, 50000)) + labs(title = \"Herwijnen: VIR\")\np_vir_dhl_classified <- plot(corrected_ppi_dhl_classified, param = \"VIR\", zlim = c(0, 50000)) + labs(title = \"Den Helder: VIR\")\nggarrange(p_vir_hrw_classified, p_vir_dhl_classified, ncol = 2, nrow = 1, common.legend = TRUE, legend = \"right\")\ncorrected_ppi_hrw_classified$data@data %>%\n  mutate(class = case_when(\n    VIR > 40000 ~ 2,\n    VIR <= 40000 & VIR > 0 ~ 1,\n    VIR == 0 ~ 0\n  )) %>%\n  dplyr::select(class) -> class_hrw\n\ncorrected_ppi_dhl_classified$data@data %>%\n  mutate(class = case_when(\n    VIR > 40000 ~ 2,\n    VIR <= 40000 & VIR > 0 ~ 1,\n    VIR == 0 ~ 0\n  )) %>%\n  dplyr::select(class) -> class_dhl\n\n\ncorrected_ppi_hrw$data$class <- unlist(class_hrw)\ncorrected_ppi_dhl$data$class <- unlist(class_dhl)"},{"path":"radar-data-preprocessing.html","id":"distance-to-radar","chapter":"2 Radar Data Preprocessing","heading":"2.8 Distance to radar","text":"account remaining range-bias effects, also useful calculate distance radar given PPI pixel. can include modelling efforts later .","code":"\nsource(\"R/calculate_distance_to_radar.R\")\n\ncorrected_ppi_hrw <- calculate_distance_to_radar(corrected_ppi_hrw)\ncorrected_ppi_dhl <- calculate_distance_to_radar(corrected_ppi_dhl)"},{"path":"radar-data-preprocessing.html","id":"spatial-coordinates","chapter":"2 Radar Data Preprocessing","heading":"2.9 Spatial coordinates","text":"Furthermore, can useful keep spatial coordinates correct spatial autocorrelation necessary, calculate well.","code":"\ncoords_hrw <- coordinates(corrected_ppi_hrw$data)\ncorrected_ppi_hrw$data$x <- coords_hrw[, 1]\ncorrected_ppi_hrw$data$y <- coords_hrw[, 2]\n\ncoords_dhl <- coordinates(corrected_ppi_dhl$data)\ncorrected_ppi_dhl$data$x <- coords_dhl[, 1]\ncorrected_ppi_dhl$data$y <- coords_dhl[, 2]\n\nsaveRDS(corrected_ppi_hrw, file = \"data/processed/corrected_ppi_hrw.RDS\")\nsaveRDS(corrected_ppi_dhl, file = \"data/processed/corrected_ppi_dhl.RDS\")"},{"path":"radar-data-preprocessing.html","id":"visualising-range-bias-correction","chapter":"2 Radar Data Preprocessing","heading":"2.10 Visualising range-bias correction","text":"Now can finally proper look range-corrected versions PPI overlaid interactive map. ’s little hard interpret PPI pixels contain birds set 0 landscape , let’s see looks like basemap removed. ships North Sea causing reflectivities orders magnitude higher thus stretching colormap, — now — need ‘clip’ values maximum set value 99th percentile.Unfortunately, due way leaflet stores maps produces, plot using K-M knitting generate document. Run chunks interactively work fine.","code":"\nsource(\"R/clip.R\")\nfiltered_corrected_ppi_hrw <- corrected_ppi_hrw\nfiltered_corrected_ppi_hrw$data@data <- as.data.frame(apply(filtered_corrected_ppi_hrw$data@data, 2, clip, bounds = c(0.05, 0.99)))\nfiltered_corrected_ppi_dhl <- corrected_ppi_dhl\nfiltered_corrected_ppi_dhl$data@data <- as.data.frame(apply(filtered_corrected_ppi_dhl$data@data, 2, clip, bounds = c(0.05, 0.99)))"},{"path":"radar-data-preprocessing.html","id":"range-corrected-ppi-of-herwijnen-radar","chapter":"2 Radar Data Preprocessing","heading":"2.10.1 Range-corrected PPI of Herwijnen radar","text":"","code":"\nmapview(corrected_ppi_hrw$data)"},{"path":"radar-data-preprocessing.html","id":"range-corrected-ppi-of-den-helder-radar","chapter":"2 Radar Data Preprocessing","heading":"2.10.2 Range-corrected PPI of Den Helder radar","text":"","code":"\nmapview(corrected_ppi_dhl$data)"},{"path":"radar-data-preprocessing.html","id":"preprocess-additional-scans","chapter":"2 Radar Data Preprocessing","heading":"2.11 Preprocess additional scans","text":"Now processing steps explained detail, can process additional scans dataset similar fashion. focus scans 22:00 CET 01:00 CET, corresponds 23:00 02:00 local Amsterdam time, ‘cover’ fireworks disturbance occurs (based plots Selecting firework take-moment).","code":"\nsource(\"R/preprocess_radar_data.R\")\n\nhrw_pvols <- Sys.glob(file.path(\"data/raw/pvol/fireworks-2017-2018\", \"*NL62*\"))\ndhl_pvols <- Sys.glob(file.path(\"data/raw/pvol/fireworks-2017-2018\", \"*NL61*\"))\n\ndynamic_groundclutter_hrw <- readRDS(\"data/processed/clutter_dynamic_hrw_avg.RDS\")\nstatic_groundclutter_hrw <- readRDS(\"data/processed/clutter_static_hrw_avg.RDS\")\n\ndynamic_groundclutter_dhl <- readRDS(\"data/processed/clutter_dynamic_dhl_avg.RDS\")\nstatic_groundclutter_dhl <- readRDS(\"data/processed/clutter_static_dhl_avg.RDS\")\n\nfor (pvol in hrw_pvols) {\n  preprocess_radar_data(pvol_path = pvol, \n                        ei_rays = ei_rays_hrw, \n                        pvol_dynamic_groundclutter = dynamic_groundclutter_hrw,\n                        pvol_static_groundclutter = static_groundclutter_hrw,\n                        dir_out = \"data/processed/corrected-ppis/\",\n                        res = 500)\n}\n\nfor (pvol in dhl_pvols) {\n  preprocess_radar_data(pvol_path = pvol,\n                        ei_rays = ei_rays_dhl,\n                        pvol_dynamic_groundclutter = dynamic_groundclutter_dhl,\n                        pvol_static_groundclutter = static_groundclutter_dhl,\n                        dir_out = \"data/processed/corrected-ppis/\",\n                        azim_limits = c(90, 200),\n                        res = 500)\n}"},{"path":"radar-data-preprocessing.html","id":"preprocess-baseline-disturbance-scans","chapter":"2 Radar Data Preprocessing","heading":"2.12 Preprocess baseline disturbance scans","text":"want able compare disturbance baseline level reflectivity nights time, downloaded 20 days polar volumes surrounding, directly adjacent nights near NYE. particular, ’ve downloaded polar volumes December 15th til 25th January 5th til 15th. compare polar volumes, treat , process files disturbance baseline well.","code":"\nhrw_pvols <- Sys.glob(file.path(\"data/raw/pvol/disturbance-baseline\", \"NLHRW*\"))\ndhl_pvols <- Sys.glob(file.path(\"data/raw/pvol/disturbance-baseline\", \"NLDHL*\"))\n\ndynamic_groundclutter_hrw <- readRDS(\"data/processed/clutter_dynamic_hrw_avg.RDS\")\nstatic_groundclutter_hrw <- readRDS(\"data/processed/clutter_static_hrw_avg.RDS\")\n\ndynamic_groundclutter_dhl <- readRDS(\"data/processed/clutter_dynamic_dhl_avg.RDS\")\nstatic_groundclutter_dhl <- readRDS(\"data/processed/clutter_static_dhl_avg.RDS\")\n\nfor (pvol in hrw_pvols) {\n  preprocess_radar_data(pvol_path = pvol, \n                        ei_rays = ei_rays_hrw, \n                        pvol_dynamic_groundclutter = dynamic_groundclutter_hrw,\n                        pvol_static_groundclutter = static_groundclutter_hrw,\n                        dir_out = \"data/processed/baseline-ppis/\",\n                        res = 500)\n}\n\nfor (pvol in dhl_pvols) {\n  preprocess_radar_data(pvol_path = pvol,\n                        ei_rays = ei_rays_dhl,\n                        pvol_dynamic_groundclutter = dynamic_groundclutter_dhl,\n                        pvol_static_groundclutter = static_groundclutter_dhl,\n                        dir_out = \"data/processed/baseline-ppis/\",\n                        azim_limits = c(90, 200),\n                        res = 500)\n}"},{"path":"annotating-land-use.html","id":"annotating-land-use","chapter":"3 Annotating land use","heading":"3 Annotating land use","text":"study aim quantify response fireworks across different bird communities, use take-habitat proxy. notebook classify land use, variety factors can serve proxy severity fireworks disturbance, distance nearest residential area PPI ‘pixels’.land use based CORINE Land Cover dataset specifically 2018 version (CLC2018), relevant 2017-2018 fireworks event.","code":""},{"path":"annotating-land-use.html","id":"processing-environment-2","chapter":"3 Annotating land use","heading":"3.1 Processing environment","text":"","code":"\nlibrary(raster)\nlibrary(sf)\nlibrary(stars)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(gridExtra)\nlibrary(viridis)\nlibrary(mapview)"},{"path":"annotating-land-use.html","id":"converting-the-land-use-map","chapter":"3 Annotating land use","heading":"3.2 Converting the land use map","text":"start, need convert land use map 1) resolution, 2) extent radar PPIs can simply ‘overlay’ rasters top merge . load PPIs extract CRS information contained proj4 strings.load prepare land use map ’s . aid classification process, also load legend land use classes contained entire CLC2018 dataset, otherwise classes remain anonymous numbers.","code":"\nppi_hrw <- readRDS(\"data/processed/corrected_ppi_hrw.RDS\")\nppi_dhl <- readRDS(\"data/processed/corrected_ppi_dhl.RDS\")\n\nppi_proj4_hrw <- ppi_hrw$data@proj4string\nppi_proj4_dhl <- ppi_dhl$data@proj4string\nlanduse <- raster(\"data/raw/landuse/clc2018_clc2018_v2018_20_raster100m/CLC2018_CLC2018_V2018_20.tif\")\nlanduse_classes <- read.csv(\"data/raw/landuse/clc2018_clc2018_v2018_20_raster100m/Legend/CLC2018_CLC2018_V2018_20_QGIS.txt\",\n                            col.names = c(\"landuse_id\", \"r\", \"g\", \"b\", \"x\", \"landuse_class\"), header = FALSE)[, c(\"landuse_id\", \"landuse_class\"),]"},{"path":"annotating-land-use.html","id":"cropping-the-land-use-map","chapter":"3 Annotating land use","heading":"3.2.1 Cropping the land use map","text":"CLC2018 dataset large fit memory steps , crop raster dataset processing. Even , still requires beefy machine process files. First, calculate bounding box landuse raster based bounding boxes radar data.can now crop plot land use maps centered radar sites, meter padding surrounding extent radar data.plot result:","code":"\npadding <- 25000  # Padding in m to make sure we crop out of the land use map with a wide margin to compensate for edge-effects later\nbbox_meters <- abs(ppi_dhl$data@bbox[[1]]) + padding  # Assuming the PPI range of DHL and HRW are the same\n\nbbox_hrw <- st_bbox(c(xmin = -bbox_meters, ymin = -bbox_meters, xmax = bbox_meters, ymax = bbox_meters), crs = ppi_proj4_hrw)\nbbox_dhl <- st_bbox(c(xmin = -bbox_meters, ymin = -bbox_meters, xmax = bbox_meters, ymax = bbox_meters), crs = ppi_proj4_dhl)\n\nbbox_hrw %>%\n  st_as_sfc() %>%\n  st_transform(crs(landuse)) %>%\n  st_bbox -> bbox_landuse_hrw\n\nbbox_dhl %>%\n  st_as_sfc() %>%\n  st_transform(crs(landuse)) %>%\n  st_bbox -> bbox_landuse_dhl\next_hrw <- extent(c(bbox_landuse_hrw[1], bbox_landuse_hrw[3], bbox_landuse_hrw[2], bbox_landuse_hrw[4]))\next_dhl <- extent(c(bbox_landuse_dhl[1], bbox_landuse_dhl[3], bbox_landuse_dhl[2], bbox_landuse_dhl[4]))\n\nlanduse_crop_hrw <- crop(landuse, ext_hrw)## Warning in showSRID(uprojargs, format = \"PROJ\", multiline = \"NO\", prefer_proj\n## = prefer_proj): Discarded datum Unknown based on GRS80 ellipsoid in Proj4\n## definition\nlanduse_crop_dhl <- crop(landuse, ext_dhl)## Warning in showSRID(uprojargs, format = \"PROJ\", multiline = \"NO\", prefer_proj\n## = prefer_proj): Discarded datum Unknown based on GRS80 ellipsoid in Proj4\n## definition\nsea_id <- match('Sea and ocean', landuse_classes$landuse_class)\nlanduse_crop_hrw[is.na(landuse_crop_hrw)] <- landuse_classes[sea_id, \"landuse_id\"]  # Convert NAs to the land use class of the sea\nlanduse_crop_dhl[is.na(landuse_crop_dhl)] <- landuse_classes[sea_id, \"landuse_id\"]\npar(pty = \"s\", mfrow = c(1, 2))\nimage(landuse_crop_hrw, main = \"Herwijnen\")\nimage(landuse_crop_dhl, main = \"Den Helder\")"},{"path":"annotating-land-use.html","id":"reprojecting-the-land-use-map","chapter":"3 Annotating land use","heading":"3.2.2 Reprojecting the land use map","text":"Now land use map cropped, can start reprojection CRS radar PPI. ’re dealing categorical data, set method = \"ngb\" use nearest neighbour interpolation. Despite using interpolation, reprojection change resolution base CLC2018 dataset PPI, ’ll next.reprojection went successful, CRS reprojected land use map radar PPI .Apparently case.","code":"\nlanduse_hrw_reprojected <- projectRaster(landuse_crop_hrw, crs = ppi_proj4_hrw, method = \"ngb\")\nlanduse_dhl_reprojected <- projectRaster(landuse_crop_dhl, crs = ppi_proj4_dhl, method = \"ngb\")\nlevels(landuse_hrw_reprojected) <- levels(landuse_crop_hrw)\nlevels(landuse_dhl_reprojected) <- levels(landuse_crop_dhl)\ncompareCRS(ppi_hrw$data@proj4string, landuse_hrw_reprojected@crs)\ncompareCRS(ppi_dhl$data@proj4string, landuse_dhl_reprojected@crs)## [1] TRUE\n## [1] TRUE"},{"path":"annotating-land-use.html","id":"reclassifying-land-use-types-to-functional-classes","chapter":"3 Annotating land use","heading":"3.2.3 Reclassifying land use types to functional classes","text":"CLC2018 dataset contains total 44 land use classes. purpose, reduce 44 5 classes biologically relevant groupings, specifically:Urban areaAgricultural areaSemi-open areaForestsWetlandsWater bodiesThe following table used convert/reclassify classes contained within CLC2018 dataset, original land use classes landuse_class reclassified landuse_target. also indicate whether areas inhabited (inhabited = 1), uninhabited (inhabited = 0). Netherlands inhabited areas classified “Discontinuous urban fabric” CLC2018 dataset, areas set uninhabited.sort-‘raster attribute table’ place, can now reclassify detailed landuse classes broader categories listed .leaves us following count ~100x100m cells per land use category","code":"\nlanduse_classes %<>%\n  mutate(landuse_target = case_when(\n    landuse_id >= 100 & landuse_id < 200 ~ \"Urban area\",\n    landuse_id >= 200 & landuse_id <= 213 ~ \"Agricultural area\",\n    landuse_id >= 221 & landuse_id <= 223 ~ \"Semi-open area\",\n    landuse_id >= 231 & landuse_id <= 243 ~ \"Agricultural area\",\n    landuse_id >= 244 & landuse_id < 300 ~ \"Forests\",\n    landuse_id >= 300 & landuse_id <= 313 ~ \"Forests\",\n    landuse_id >= 321 & landuse_id <= 335 ~ \"Semi-open area\",\n    landuse_id >= 400 & landuse_id < 500 ~ \"Wetlands\",\n    landuse_id >= 500 & landuse_id < 999 ~ \"Water bodies\",\n    landuse_id == 999 ~ \"NODATA\")) %>%\n  mutate(landuse_target_id = case_when(\n    landuse_target == \"Urban area\" ~ 1,\n    landuse_target == \"Agricultural area\" ~ 2,\n    landuse_target == \"Semi-open area\" ~ 3,\n    landuse_target == \"Forests\" ~ 4,\n    landuse_target == \"Wetlands\" ~ 5,\n    landuse_target == \"Water bodies\" ~ 6,\n    landuse_target == \"NODATA\" ~ 9\n  ))\n\nlanduse_classes$inhabited <- 0\nlanduse_classes$inhabited[landuse_classes$landuse_class == \"Discontinuous urban fabric\"] <- 1\n\nlanduse_classes\nlanduse_dhl_reclassified <- ratify(reclassify(landuse_dhl_reprojected, cbind(landuse_classes$landuse_id, landuse_classes$landuse_target_id)), count = TRUE)\nlanduse_hrw_reclassified <- ratify(reclassify(landuse_hrw_reprojected, cbind(landuse_classes$landuse_id, landuse_classes$landuse_target_id)), count = TRUE)\nwriteRaster(landuse_dhl_reclassified, \"data/processed/landuse/landuse_dhl_reclassified.tif\", overwrite = TRUE)\nwriteRaster(landuse_hrw_reclassified, \"data/processed/landuse/landuse_hrw_reclassified.tif\", overwrite = TRUE)\ncellcounts <- cbind(levels(landuse_hrw_reclassified)[[1]][\"COUNT\"], levels(landuse_dhl_reclassified)[[1]][\"COUNT\"])\ncolnames(cellcounts) <- c(\"Herwijnen\", \"Den Helder\")\nrownames(cellcounts) <- unique(landuse_classes$landuse_target)[-7]\ncellcounts"},{"path":"annotating-land-use.html","id":"resampling-the-land-use-map-to-a-lower-resolution","chapter":"3 Annotating land use","heading":"3.2.4 Resampling the land use map to a lower resolution","text":"cellsize PPIs 500x500 meters, land use map much finely detailed (~100x100m), need resample latter derive land use map 500x500 meter resolution well.resolution PPIs much higher land use map, need resample latter lower resolution. Instead classifying single pixel PPI belonging single land use class, using land use proportions. therefore calculate proportions belonging land use classes within area cells roughly size PPI pixels. Subsequently resample match 1:1 PPI pixels store land use proportions land use classes PPIs. done calculate_land_use_proportion() function .can now calculate proportions save raster files potential inspection GIS software.now resampled land use raster similar PPI raster, exception — course — values contained within.Ok, let’s save copy far.","code":"\ncalculate_land_use_proportion <- function(raster, reference_raster, overwrite = FALSE) {\n  values <- c(sort(unique(getValues(raster))))\n  \n  # classes: multidimensional logical array for the classes contained within the land use map\n  # 1 if a land use class is present on that position, 0 if not\n  classes <- layerize(raster, filename = paste(\"data/processed/landuse/layerize/\", substitute(raster), sep = \"\"),\n                      format = \"raster\", bylayer = TRUE, classes = values, overwrite = overwrite)\n  # factor: nr of cells in both horizontal and vertical direction to aggregate\n  factor <- round(dim(raster)[1:2] / dim(reference_raster)[1:2])\n  # agg: aggregated version of classes (aggregation factor defined by factor) containing mean coverage by a class in a given area\n  # 1 corresponds with full coverage, 0 with no coverage of that class within the pixel at all\n  agg <- aggregate(classes, factor, na.rm = TRUE, fun = mean)\n  # x: the agg and ppi pixels almost overlap exactly, but there is a teeny tiny difference which we can\n  # iron out by resampling once more.\n  x <- resample(agg, reference_raster)\n  \n  return(x)\n}\nlanduse_hrw <- calculate_land_use_proportion(landuse_hrw_reclassified, as(ppi_hrw$data, \"RasterLayer\"), overwrite = TRUE)\nlanduse_dhl <- calculate_land_use_proportion(landuse_dhl_reclassified, as(ppi_dhl$data, \"RasterLayer\"), overwrite = TRUE)\nnames(landuse_hrw) <- c(\"urban\", \"agricultural\", \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\")\nnames(landuse_dhl) <- c(\"urban\", \"agricultural\", \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\")\nwriteRaster(landuse_hrw, \"data/processed/landuse/landuse_hrw.tif\", overwrite = TRUE)\nwriteRaster(landuse_dhl, \"data/processed/landuse/landuse_dhl.tif\", overwrite = TRUE)\ncompareRaster(landuse_hrw, as(ppi_hrw$data, \"RasterLayer\"), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE)\ncompareRaster(landuse_dhl, as(ppi_dhl$data, \"RasterLayer\"), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE)## [1] TRUE\n## [1] TRUE\nsaveRDS(landuse_hrw, \"data/processed/landuse/landuse_hrw.RDS\")\nsaveRDS(landuse_dhl, \"data/processed/landuse/landuse_dhl.RDS\")"},{"path":"annotating-land-use.html","id":"adding-land-use-classifications-to-the-ppis","chapter":"3 Annotating land use","heading":"3.3 Adding land use classifications to the PPIs","text":"land use rasters overlapping exactly PPIs, can simply extract values resampled land use rasters add additional parameters PPIs.","code":"\nlanduse_hrw <- readRDS(\"data/processed/landuse/landuse_hrw.RDS\")\nlanduse_dhl <- readRDS(\"data/processed/landuse/landuse_dhl.RDS\")\n\nvalues_hrw <- rasterToPoints(landuse_hrw, spatial = TRUE)\nvalues_dhl <- rasterToPoints(landuse_dhl, spatial = TRUE)\n\nppi_hrw$data@data <- cbind(ppi_hrw$data@data, values_hrw@data)\nppi_dhl$data@data <- cbind(ppi_dhl$data@data, values_dhl@data)"},{"path":"annotating-land-use.html","id":"calculate-distance-to-nearest-urban-area","chapter":"3 Annotating land use","heading":"3.4 Calculate distance to nearest urban area","text":"can use distance nearest inhabited urban area proxy disturbance. calculate , reclassify raster cells containing inhabited urban area everything else. every cell raster cell just classified inhabited urban area, calculate distance (meters) nearest cell classified inhabited urban area. classify PPI cell uninhabited proportion constituent cells (finer resolution) inhabited > 0.95.add values PPIs .","code":"\ndhl_inhabited <- ratify(reclassify(landuse_dhl_reprojected, cbind(landuse_classes$landuse_id, landuse_classes$inhabited)), count = TRUE)\nhrw_inhabited <- ratify(reclassify(landuse_hrw_reprojected, cbind(landuse_classes$landuse_id, landuse_classes$inhabited)), count = TRUE)\n\ndhl_inhabited <- calculate_land_use_proportion(dhl_inhabited, as(ppi_dhl$data, \"RasterLayer\"), overwrite = TRUE)\nhrw_inhabited <- calculate_land_use_proportion(hrw_inhabited, as(ppi_hrw$data, \"RasterLayer\"), overwrite = TRUE)\n\nnames(dhl_inhabited) <- c(\"uninhabited\", \"inhabited\")\nnames(hrw_inhabited) <- c(\"uninhabited\", \"inhabited\")\n\ndist_dhl <- dhl_inhabited\ndist_dhl[dist_dhl$uninhabited > 0.95] <- NA\ndist_dhl <- distance(dist_dhl$inhabited)\n\ndist_hrw <- hrw_inhabited\ndist_hrw[dist_hrw$uninhabited > 0.95] <- NA\ndist_hrw <- distance(dist_hrw$inhabited)\n\nwriteRaster(dist_hrw, \"data/processed/landuse/dist_urban_hrw.tif\", overwrite = TRUE)\nwriteRaster(dist_dhl, \"data/processed/landuse/dist_urban_dhl.tif\", overwrite = TRUE)\nvalues_dist_hrw <- rasterToPoints(dist_hrw, spatial = TRUE)\nvalues_dist_dhl <- rasterToPoints(dist_dhl, spatial = TRUE)\n\nppi_hrw$data@data$dist_urban <- values_dist_hrw@data$layer\nppi_dhl$data@data$dist_urban <- values_dist_dhl@data$layer"},{"path":"annotating-land-use.html","id":"add-population-density","chapter":"3 Annotating land use","heading":"3.5 Add population density","text":"Another proxy disturbance explore simply number humans living certain area. Dutch Central Bureau Statistics (CBS) annually publishes dataset containing number inhabitants organized 500x500m grid cells. now add PPIs well., verify PPI pixels match exactly CBS population gridsNow final step calculate total population within neighborhood surrounding PPI pixels, get representative measure disturbance potential surrounding area.add PPIs.","code":"\ncbs_maps <- st_read(\"data/raw/population-density/2019-CBS_VK500_2018_v1/CBS_VK500_2018_v1.shp\")## Reading layer `CBS_VK500_2018_v1' from data source \n##   `/Users/barthoekstra/Development/fireworks/data/raw/population-density/2019-CBS_VK500_2018_v1/CBS_VK500_2018_v1.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 151108 features and 31 fields\n## Geometry type: POLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 13000 ymin: 306500 xmax: 278500 ymax: 619500\n## Projected CRS: Amersfoort / RD New\ncbs_hrw <- st_transform(cbs_maps, ppi_hrw$data@proj4string)\ncbs_dhl <- st_transform(cbs_maps, ppi_dhl$data@proj4string)\n\n# Template for the rasterization following the standard 500x500m resolution of the CBS grid\ntemplate_hrw <- st_as_stars(st_bbox(cbs_hrw[\"INWONER\"]), values = NA_real_, dx = 500, dy = 500)\ntemplate_dhl <- st_as_stars(st_bbox(cbs_dhl[\"INWONER\"]), values = NA_real_, dx = 500, dy = 500)\n\n# Now rasterize\npop_density_rasterized_hrw <- as(st_rasterize(cbs_hrw[\"INWONER\"], template = template_hrw), \"Raster\")\npop_density_rasterized_dhl <- as(st_rasterize(cbs_dhl[\"INWONER\"], template = template_dhl), \"Raster\")\n\n# Set negative or NA raster values to 0\npop_density_rasterized_hrw[pop_density_rasterized_hrw < 0] <- 0\npop_density_rasterized_dhl[pop_density_rasterized_dhl < 0] <- 0\n\n# Now aggregate by summing up values in cells to 'cover' the values that fit in a PPI pixel\nfactor_hrw <- round(dim(pop_density_rasterized_hrw)[1:2] / dim(as(ppi_hrw$data, \"RasterLayer\"))[1:2])\nfactor_dhl <- round(dim(pop_density_rasterized_dhl)[1:2] / dim(as(ppi_dhl$data, \"RasterLayer\"))[1:2])\nagg_hrw <- aggregate(pop_density_rasterized_hrw, factor_hrw, na.rm = TRUE, fun = sum)## Warning in .local(x, ...): all fact(s) were 1, nothing to aggregate\nagg_dhl <- aggregate(pop_density_rasterized_dhl, factor_dhl, na.rm = TRUE, fun = sum)## Warning in .local(x, ...): all fact(s) were 1, nothing to aggregate\n# Resample to make the PPI and CBS population grids line up 1:1\npop_density_rasterized_hrw <- resample(agg_hrw, as(ppi_hrw$data, \"RasterLayer\"))\npop_density_rasterized_dhl <- resample(agg_dhl, as(ppi_dhl$data, \"RasterLayer\"))\ncompareRaster(pop_density_rasterized_hrw, as(ppi_hrw$data, \"RasterLayer\"), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE)\ncompareRaster(pop_density_rasterized_dhl, as(ppi_dhl$data, \"RasterLayer\"), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE)## [1] TRUE\n## [1] TRUE\nweights <- matrix(1, nrow = 3, ncol = 3)\npop_hrw <- focal(pop_density_rasterized_hrw, w = weights, fun = sum, na.rm = TRUE)\npop_dhl <- focal(pop_density_rasterized_dhl, w = weights, fun = sum, na.rm = TRUE)\n\npop_hrw[is.na(pop_hrw)] <- 0\npop_dhl[is.na(pop_dhl)] <- 0\nvalues_pop_hrw <- rasterToPoints(pop_hrw, spatial = TRUE)\nvalues_pop_dhl <- rasterToPoints(pop_dhl, spatial = TRUE)\n\nppi_hrw$data@data$human_pop <- values_pop_hrw@data$layer\nppi_dhl$data@data$human_pop <- values_pop_dhl@data$layer"},{"path":"annotating-land-use.html","id":"add-land-area-logical","chapter":"3 Annotating land use","heading":"3.6 Add land area logical","text":"land created adequately filtered PPIs previous steps, North Sea can still dynamic clutter remaining caused ships wind parks. eventually quantify number birds affected fireworks scan, able filter VIR areas land, quite sure clutter filtered sufficiently. approach similar added population density previous step., verify PPI pixels match exactly gridded land area.can now add land area PPIs .finally save PPIs .","code":"\n# We get data from the CBS, which can be done dynamically through the command below, but because the geodata service occasionally hangs, we stored the \n# data locally as well in data/raw/municipalities/municipalities.json\n# mcp <- st_read(\"https://geodata.nationaalgeoregister.nl/wijkenbuurten2020/ows?request=GetFeature&service=WFS&version=1.1.0&typeName=gemeenten2020&outputFormat=json\")\nmcp <- st_read(\"data/raw/municipalities/municipalities.json\")## Reading layer `municipalities' from data source \n##   `/Users/barthoekstra/Development/fireworks/data/raw/municipalities/municipalities.json' \n##   using driver `GeoJSON'\n## Simple feature collection with 438 features and 35 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 10425.16 ymin: 306846.2 xmax: 278026.1 ymax: 621876.3\n## Projected CRS: Amersfoort / RD New\nmcp_hrw <- st_transform(mcp, ppi_hrw$data@proj4string)\nmcp_dhl <- st_transform(mcp, ppi_dhl$data@proj4string)\n\n# Template for the rasterization following the standard 500x500m resolution of the CBS grid\ntemplate_hrw <- st_as_stars(st_bbox(mcp_hrw[\"gemeentenaam\"]), values = NA_real_, dx = 500, dy = 500)\ntemplate_dhl <- st_as_stars(st_bbox(mcp_dhl[\"gemeentenaam\"]), values = NA_real_, dx = 500, dy = 500)\n\n# Now rasterize\nmcp_rasterized_hrw <- as(st_rasterize(mcp_hrw[\"gemeentenaam\"], template = template_hrw), \"Raster\")\nmcp_rasterized_dhl <- as(st_rasterize(mcp_dhl[\"gemeentenaam\"], template = template_dhl), \"Raster\")\n\n# Set NA to 0, non-NA to 1\nmcp_rasterized_hrw[!is.na(mcp_rasterized_hrw)] <- 1\nmcp_rasterized_hrw[is.na(mcp_rasterized_hrw)] <- 0\nmcp_rasterized_dhl[!is.na(mcp_rasterized_dhl)] <- 1\nmcp_rasterized_dhl[is.na(mcp_rasterized_dhl)] <- 0\n\n# Resample to PPI grid\nmcp_rasterized_hrw <- resample(mcp_rasterized_hrw, as(ppi_hrw$data, \"RasterLayer\"))\nmcp_rasterized_dhl <- resample(mcp_rasterized_dhl, as(ppi_dhl$data, \"RasterLayer\"))\n\n# Set NA to 0 again\nmcp_rasterized_hrw[is.na(mcp_rasterized_hrw)] <- 0\nmcp_rasterized_dhl[is.na(mcp_rasterized_dhl)] <- 0\ncompareRaster(mcp_rasterized_hrw, as(ppi_hrw$data, \"RasterLayer\"), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE)\ncompareRaster(mcp_rasterized_dhl, as(ppi_dhl$data, \"RasterLayer\"), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE)## [1] TRUE\n## [1] TRUE\nvalues_land_hrw <- rasterToPoints(mcp_rasterized_hrw, spatial = TRUE)\nvalues_land_dhl <- rasterToPoints(mcp_rasterized_dhl, spatial = TRUE)\n\nppi_hrw$data@data$land <- values_land_hrw@data$layer\nppi_dhl$data@data$land <- values_land_dhl@data$layer\nsaveRDS(ppi_hrw, file = \"data/processed/corrected_ppi_hrw_lu.RDS\")\nsaveRDS(ppi_dhl, file = \"data/processed/corrected_ppi_dhl_lu.RDS\")"},{"path":"annotating-land-use.html","id":"plotting-human-parameters-on-an-interactive-map","chapter":"3 Annotating land use","heading":"3.6.1 Plotting human parameters on an interactive map","text":"now generated proxies fireworks ‘severity’ later modelling stages. Let’s plot interactive map reference. Unfortunately, due way leaflet stores maps produces, plot using K-M knitting generate document. Run chunks interactively work fine.","code":""},{"path":"annotating-land-use.html","id":"interactive-map-of-herwijnen","chapter":"3 Annotating land use","heading":"3.6.1.1 Interactive map of Herwijnen","text":"","code":"\nhuman_parameters <- c(\"urban\", \"agricultural\", \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\", \"dist_urban\", \"human_pop\", \"land\")\n\nmapview(ppi_hrw$data[, , human_parameters], alpha.regions = 0.6, col.regions = inferno, maxpixels=2000000,\n        na.color = \"#00000000\", map.types = c(\"CartoDB.Positron\", \"CartoDB.DarkMatter\", \"Esri.WorldImagery\"),\n        layer.name = human_parameters)"},{"path":"annotating-land-use.html","id":"interactive-map-of-den-helder","chapter":"3 Annotating land use","heading":"3.6.1.2 Interactive map of Den Helder","text":"","code":"\nmapview(ppi_dhl$data[, , human_parameters], alpha.regions = 0.6, col.regions = inferno, maxpixels=2000000,\n        na.color = \"#00000000\", map.types = c(\"CartoDB.Positron\", \"CartoDB.DarkMatter\", \"Esri.WorldImagery\"),\n        layer.name = human_parameters)"},{"path":"annotating-count-areas.html","id":"annotating-count-areas","chapter":"4 Annotating count areas","heading":"4 Annotating count areas","text":"data following counts provided Sovon:Waterbird counts shapefile containing surveyed areas xlsx file count results. can linked using identifiers contained datasets.PTT counts, point transect counts, contained within xlsx file routes bird observations \\((X, Y)\\) location.make processing efficient, ‘annotate’ PPIs corresponding area codes waterbird counts identifier PTT counts. , can later calculate relevant count-based parameters (e.g. bird biomass, etc.) ‘join’ corresponding identifiers.","code":""},{"path":"annotating-count-areas.html","id":"processing-environment-3","chapter":"4 Annotating count areas","heading":"4.1 Processing environment","text":"","code":"\nlibrary(bioRad)\nlibrary(sf)\nlibrary(stars)\nlibrary(raster)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(stringr)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(viridis)\nlibrary(fasterize)\nppi_hrw <- readRDS(\"data/processed/corrected_ppi_hrw_lu.RDS\")\nppi_dhl <- readRDS(\"data/processed/corrected_ppi_dhl_lu.RDS\")"},{"path":"annotating-count-areas.html","id":"annotate-ppis-with-waterbird-area-codes","chapter":"4 Annotating count areas","heading":"4.2 Annotate PPIs with waterbird area codes","text":"rename veriables retained shapefile English add numerical wb_area_id can use link information retained shapefiles rasterized waterbird areas. shapefiles transformed CRS PPIs.rasterize specifically newly created wb_area_id (already numerical categorical value like wb_area_nr) following ‘template’ existing PPIs.Let’s see ’s gone far.Visually seems gone well, now let’s make sure rasterized waterbird areas share grid PPI ‘rasters’.Twice TRUE, rasters identical (except values), can merge datasets using join wb_area_id.Let’s verify occurred planned.looks comparable plots rasterized scans wb_area_id shows similar areas similar colors, worked fine.","code":"\nwb_areas <- st_read(\"data/raw/sovon/wavo_telgebieden.shp\") %>%\n  rename(wb_area_nr = GEBIEDNR, wb_area_ha = OPPHA, xcoor = XCOOR, ycoor = YCOOR)\nwb_areas$wb_area_id <- seq(1, length(wb_areas$wb_area_nr))\n\nwb_areas_hrw <- st_transform(wb_areas, ppi_hrw$data@proj4string)\nwb_areas_dhl <- st_transform(wb_areas, ppi_dhl$data@proj4string)## Reading layer `wavo_telgebieden' from data source \n##   `/Users/barthoekstra/Development/fireworks/data/raw/sovon/wavo_telgebieden.shp' \n##   using driver `ESRI Shapefile'\n## Simple feature collection with 4131 features and 4 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: 13551.48 ymin: 307546.8 xmax: 278027 ymax: 622790\n## Projected CRS: Amersfoort / RD New\ntpl_hrw <- st_as_stars(st_bbox(ppi_hrw$data), dx = ppi_hrw$data@grid@cellsize[1], dy = ppi_hrw$data@grid@cellsize[2], values = NA_real_)\ntpl_dhl <- st_as_stars(st_bbox(ppi_dhl$data), dx = ppi_dhl$data@grid@cellsize[1], dy = ppi_dhl$data@grid@cellsize[2], values = NA_real_)\n\nwb_areas_rasterized_hrw <- st_rasterize(wb_areas_hrw[\"wb_area_id\"], template = tpl_hrw)\nwb_areas_rasterized_dhl <- st_rasterize(wb_areas_dhl[\"wb_area_id\"], template = tpl_dhl)\npar(pty = \"s\", mfrow = c(1, 2))\nplot(wb_areas_rasterized_hrw, main = \"Herwijnen: wb_area_id\")\nplot(wb_areas_rasterized_dhl, main = \"Den Helder: wb_area_id\")\ncompareRaster(as(wb_areas_rasterized_hrw, \"Raster\"), as(ppi_hrw$data, \"RasterLayer\"), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE)\ncompareRaster(as(wb_areas_rasterized_dhl, \"Raster\"), as(ppi_dhl$data, \"RasterLayer\"), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE)## [1] TRUE\n## [1] TRUE\n# Add the wb_area_id to the PPIs\nppi_hrw$data$wb_area_id <- unlist(as.data.frame(as(wb_areas_rasterized_hrw, \"Raster\")))\nppi_dhl$data$wb_area_id <- unlist(as.data.frame(as(wb_areas_rasterized_dhl, \"Raster\")))\n\n# Join the additional contents of the shapefiles\nppi_hrw$data@data %>%\n  left_join(dplyr::select(as.data.frame(wb_areas_hrw), wb_area_id, wb_area_nr, wb_area_ha), by = c(\"wb_area_id\" = \"wb_area_id\")) -> ppi_hrw$data@data\nppi_hrw$data$geometry <- NULL\n\nppi_dhl$data@data %>%\n  left_join(dplyr::select(as.data.frame(wb_areas_dhl), wb_area_id, wb_area_nr, wb_area_ha), by = c(\"wb_area_id\" = \"wb_area_id\")) -> ppi_dhl$data@data\nppi_dhl$data$geometry <- NULL\nplot(ppi_hrw, param = \"wb_area_id\", zlim = c(min(ppi_hrw$data@data$wb_area_id, na.rm = TRUE), max(ppi_hrw$data@data$wb_area_id, na.rm = TRUE)))\nplot(ppi_dhl, param = \"wb_area_id\", zlim = c(min(ppi_dhl$data@data$wb_area_id, na.rm = TRUE), max(ppi_dhl$data@data$wb_area_id, na.rm = TRUE)))"},{"path":"annotating-count-areas.html","id":"annotate-ppis-with-point-transect-counts","chapter":"4 Annotating count areas","heading":"4.3 Annotate PPIs with point-transect-counts","text":"PTT point transect counts organized routes, consist points along transect/route. can follow approach waterbird counts, first creating coverage shapes (like shapefile features waterbird areas) routes. Using convex hull points within route seems like good starting point convert points areas. However, case appear birds counted looking ‘inwards’ shape. buffering convex hulls radius average distance successive points, representative coverage area can generated generalises well across landscapes (e.g. area covered dense forest tend smaller open agricultural areas).","code":""},{"path":"annotating-count-areas.html","id":"loading-ptt-points","chapter":"4 Annotating count areas","heading":"4.3.1 Loading PTT points","text":"load PTT data directly xlsx file provided Sovon rename variables English.’re interested data , load subset columns, specifically unique combinations routes points, yield corresponding xcoor ycoor coordinates count_point within route.","code":"\nptt <- read_excel(\"data/raw/sovon/tel_dec_jan_1718.xlsx\", sheet = \"ptt\") %>%\n  rename(count_id = tellingid, route = route, count_point = telpunt, season = seizoen, year = teljaar, month = maand, day = dag, species = soort, number = aantal)\nhead(ptt, 10)\nptt %>%\n  dplyr::select(route, count_point, xcoor, ycoor) %>%\n  group_by(route, count_point) %>%\n  slice(1) -> ptt\nhead(ptt, 10)"},{"path":"annotating-count-areas.html","id":"calculate-interpoint-distances","chapter":"4 Annotating count areas","heading":"4.3.2 Calculate interpoint distances","text":"routes within PTT dataset, calculate average distance subsequent points, buffer convex hull value.can now calculate convex hulls points grouped route.calculated average distance points, can now buffer convex hulls value attain representative sizes covered areas.Now taken care , can rasterize polygons using fasterize package. overlap areas covered routes using convex hulls raster can contain single value every pixel, need resolve overlap. case compare overlapping areas pick average distance points area lowest. biases towards counts cover smaller area, probably resulting accurate estimates birds around.rasterization done, let’s compare resultant raster see identical PPIs.Two TRUEs, ’s excellent. can now add ptt_route PPIs.Let’s verify occurred planned.seems fine, can now save PPIs, can start linking actual count data.","code":"\nptt %>%\n  group_by(route) %>%\n  mutate(xcoor2 = c(xcoor[-1], 0),\n         ycoor2 = c(ycoor[-1], 0)) %>%\n  rowwise() %>%\n  mutate(interpoint_distance = pointDistance(cbind(xcoor, ycoor), cbind(xcoor2, ycoor2), lonlat = FALSE)) %>%\n  ungroup() %>%\n  filter(xcoor2 != 0) %>% # Throw out last point from route where distance to next point is not relevant\n  group_by(route) %>%\n  summarise(avg_interpoint_distance = mean(interpoint_distance), .groups = \"keep\") -> ptt_interpoint_distances\n  \nptt %>%\n  left_join(ptt_interpoint_distances, by = c(\"route\" = \"route\")) -> ptt\n\nhead(ptt, 10)\nptt %>%\n  ungroup() %>%\n  st_as_sf(coords = c(\"xcoor\", \"ycoor\"), crs = 28992) %>%  # original CRS = EPSG:28992 (RD New)\n  st_transform(crs = ppi_hrw$data@proj4string) %>%\n  group_by(route, avg_interpoint_distance) %>%\n  summarise(.groups = \"drop\") %>%\n  st_convex_hull() %>%\n  st_as_sf() -> ptt_convex_hulls_hrw  # Somehow it's necessary to reconvert to sf?\n\nptt %>%\n  ungroup() %>%\n  st_as_sf(coords = c(\"xcoor\", \"ycoor\"), crs = 28992) %>%\n  st_transform(crs = ppi_dhl$data@proj4string) %>%\n  group_by(route, avg_interpoint_distance) %>%\n  summarise(.groups = \"drop\") %>%\n  st_convex_hull() %>%\n  st_as_sf() -> ptt_convex_hulls_dhl\n\nplot(ptt_convex_hulls_hrw[1], main = \"PTT Routes Herwijnen: Route\")\nplot(ptt_convex_hulls_hrw[2], main = \"PTT Routes Herwijnen: Avg interpoint dist.\")\nplot(ptt_convex_hulls_dhl[1], main = \"PTT Routes Den Helder: Route\")\nplot(ptt_convex_hulls_dhl[2], main = \"PTT Routes Den Helder: Avg interpoint dist.\")\nptt_convex_hulls_hrw %>%\n  st_buffer(dist = as.double(ptt_convex_hulls_hrw$avg_interpoint_distance)) -> ptt_convex_hulls_hrw\n\nptt_convex_hulls_dhl %>%\n  st_buffer(dist = as.double(ptt_convex_hulls_dhl$avg_interpoint_distance)) -> ptt_convex_hulls_dhl\n\nst_write(ptt_convex_hulls_hrw, \"data/processed/sovon/ptt_convex_hulls_hrw.shp\", delete_dsn = TRUE)\nst_write(ptt_convex_hulls_dhl, \"data/processed/sovon/ptt_convex_hulls_dhl.shp\", delete_dsn = TRUE)\n\nplot(ptt_convex_hulls_hrw[1], main = \"Buffered PTT Routes Herwijnen\")\nplot(ptt_convex_hulls_dhl[1], main = \"Buffered PTT Routes Den Helder\")## Deleting source `data/processed/sovon/ptt_convex_hulls_hrw.shp' using driver `ESRI Shapefile'\n## Writing layer `ptt_convex_hulls_hrw' to data source \n##   `data/processed/sovon/ptt_convex_hulls_hrw.shp' using driver `ESRI Shapefile'\n## Writing 591 features with 2 fields and geometry type Polygon.\n## Deleting source `data/processed/sovon/ptt_convex_hulls_dhl.shp' using driver `ESRI Shapefile'\n## Writing layer `ptt_convex_hulls_dhl' to data source \n##   `data/processed/sovon/ptt_convex_hulls_dhl.shp' using driver `ESRI Shapefile'\n## Writing 591 features with 2 fields and geometry type Polygon.\nptt_hrw <- raster(ppi_hrw$data)\nptt_dhl <- raster(ppi_dhl$data)\n\nptt_hrw <- fasterize(ptt_convex_hulls_hrw, ptt_hrw, field = \"route\", by = \"avg_interpoint_distance\")\nptt_dhl <- fasterize(ptt_convex_hulls_dhl, ptt_dhl, field = \"route\", by = \"avg_interpoint_distance\")\n\nptt_hrw <- suppressWarnings(stackApply(ptt_hrw, indices = rep(1, length(ptt_hrw)), fun = min, na.rm = TRUE))\nptt_dhl <- suppressWarnings(stackApply(ptt_dhl, indices = rep(1, length(ptt_dhl)), fun = min, na.rm = TRUE))\n\nplot(ptt_hrw, main = \"Rasterized PTT routes Herwijnen\")\nplot(ptt_dhl, main = \"Rasterized PTT routes Den Helder\")\ncompareRaster(as(ptt_hrw, \"Raster\"), as(ppi_hrw$data, \"RasterLayer\"), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE)\ncompareRaster(as(ptt_dhl, \"Raster\"), as(ppi_dhl$data, \"RasterLayer\"), extent = TRUE, rowcol = TRUE, crs = TRUE, res = TRUE, orig = TRUE)## [1] TRUE\n## [1] TRUE\nppi_hrw$data$ptt_route <- unlist(as.data.frame(as(ptt_hrw, \"Raster\")))\nppi_dhl$data$ptt_route <- unlist(as.data.frame(as(ptt_dhl, \"Raster\")))\nplot(ppi_hrw, param = \"ptt_route\", zlim = c(min(ppi_hrw$data@data$ptt_route, na.rm = TRUE), max(ppi_hrw$data@data$ptt_route, na.rm = TRUE)))\nplot(ppi_dhl, param = \"ptt_route\", zlim = c(min(ppi_dhl$data@data$ptt_route, na.rm = TRUE), max(ppi_dhl$data@data$ptt_route, na.rm = TRUE)))\nsaveRDS(ppi_hrw, file = \"data/processed/corrected-ppis-lu-sovon/corrected_ppi_hrw_lu_sovon.RDS\")\nsaveRDS(ppi_dhl, file = \"data/processed/corrected-ppis-lu-sovon/corrected_ppi_dhl_lu_sovon.RDS\")"},{"path":"processing-count-results.html","id":"processing-count-results","chapter":"5 Processing count results","heading":"5 Processing count results","text":"now, interested calculating following parameters count results:number birds within every PPI pixel.average mass birds within every PPI pixel.can derive total numbers birds comparatively easily bird counts Sovon, calculate average mass birds need link database life-history traits. latter first need translate vernacular (modern) names bird species (used Sovon) scientific ones, can link .","code":""},{"path":"processing-count-results.html","id":"processing-environment-4","chapter":"5 Processing count results","heading":"5.1 Processing environment","text":"","code":"\nlibrary(rgbif)\nlibrary(stringr)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(kableExtra)"},{"path":"processing-count-results.html","id":"loading-the-sovon-count-data","chapter":"5 Processing count results","heading":"5.2 Loading the Sovon count data","text":"count data spread sheets xlsx file, load . clarity, rename columns English filter counts (.e. areas) birds positively identified species level. Although possible ‘fill’ uncertain counts based proportions, determining necessary purposes. Instead, just remove counts altogether. Finally, subspecies identifiers species removed, assume variation limited database life-history traits contain parameters subspecies separately.Following logic, can process PTT counts similarly see species contained .","code":"\nsovon_data <- \"data/raw/sovon/tel_dec_jan_1718.xlsx\"\n\ndata <- data.frame()\nsheets <- excel_sheets(sovon_data)\nsheets <- sheets[-c(1, 5)]  # Sheet 1 and 5 contain PTT and roost counts respectively, so we ignore these for now, as they have to be processed differently\n\n# Explicit column types to suppress warnings thrown because of lacking euring codes for records with no birds\ncoltypes <- c(\"numeric\", \"text\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"text\", \"numeric\", \"numeric\", \"numeric\")\n\nfor (i in seq_along(sheets)) {\n  data <- rbind(data, read_excel(sovon_data, sheet = sheets[i], col_types = coltypes))\n}\n\ndata %>%\n  drop_na() %>%  # A few rows somehow contain no birds or species 'geen vogels'\n  rename(count_id = TELLING_ID, area_nr = GEBIEDSCODE, year = JAAR, month = MAAND, day = DAG, start_time = BEGINTIJD, end_time = EINDTIJD,\n         \"euring\" = \"EURING\", species = SOORT, number = Aantal, xcoor = XCOOR, ycoor = YCOOR) %>%\n  group_by(area_nr) %>%\n  filter(!any(str_ends(species, \"spec.\"))) %>%  # Filter out all counts with unidentified birds\n  filter(!any(length(str_subset(species, \" of \")) > 0)) %>%  # Filter out all counts with either/or totals\n  filter(!any(str_starts(species, \"hybride\"))) %>%  # Filter out all counts with hybrids\n  ungroup() %>%\n  rowwise() %>%\n  mutate(species = str_split(species, \"\\\\(\")[[1]][1] %>% str_trim()) -> wb_data  # And remove all subspecies identifications\n\nhead(wb_data, 10) %>%\n  kable(format = \"html\", col.names = colnames(wb_data)) %>%\n  kable_styling() %>%\n  kableExtra::scroll_box(width = \"100%\", height = \"400px\")\nread_excel(sovon_data, sheet = 1) %>%\n  rename(count_id = tellingid, route = route, count_point = telpunt, season = seizoen, year = teljaar, month = maand, \n         day = dag, euring = euring, species = soort, number = aantal, xcoor = xcoor, ycoor = ycoor) %>%\n  group_by(route, count_point) %>%\n  filter(!any(str_ends(species, \"spec.\"))) %>%  # Filter out all counts with unidentified birds\n  filter(!any(length(str_subset(species, \" of \")) > 0)) %>%  # Filter out all counts with either/or totals\n  filter(!any(str_starts(species, \"hybride\"))) %>%  # Filter out all counts with hybrids\n  ungroup() %>%\n  rowwise() %>%\n  mutate(species = str_split(species, \"\\\\(\")[[1]][1] %>% str_trim()) -> ptt_data  # And remove all subspecies identifications\n\nhead(ptt_data, 10) %>%\n  kable(format = \"html\", col.names = colnames(ptt_data)) %>%\n  kable_styling() %>%\n  kableExtra::scroll_box(width = \"100%\", height = \"400px\")"},{"path":"processing-count-results.html","id":"filteringpreprocessing-species-names","chapter":"5 Processing count results","heading":"5.3 Filtering/preprocessing species names","text":"following section result iterative process aimed matching species count data species database life-history characteristics. Unfortunately, automatic tools get us far, bit tweaking done hand. reduce manual corrections needed, species >1% birds belong single count corrected manually. words: species matched always accounts less 1% total number birds within count, species discarded whole dataset.Besides 1% criteria, waterbird PTT counts contain exotics (e.g. ‘Helmparelhoen’/Helmeted guineafowl) life-history characteristics dataset contain measurements anyways (others measurements ), species unlikely ever take flight NYE (e.g. ‘Kip’/Domesticated chicken) mammals applies. remove dataset manually.species removed adjusted, can create species lookup table. fetch scientific names corresponding GBIF species IDs Checklist Dutch Species Register, GBIF dataset key 4dd32523-a3a3-43b7-84df-4cda02f15cf7. furthermore remove unnecessary information, subspecies scientific names well.Finally, lookup table also contains scientific names unfortunately match life-history characteristics dataset, adjust manually.","code":"\nexotics <- c(\"Helmparelhoen\", \"Kaapse Casarca\", \"Manengans\", \"Ringtaling\", \"Buffelkopeend\", \"Kokardezaagbek\", \"Chileense Flamingo\",\n             \"Kaapse Taling\", \"Bahamapijlstaart\", \"Muskuseend\", \"Zwarte Zwaan\", \"Knobbelgans\", \"Zwaangans\")\nunlikely_flight_candidate <- c(\"Kip\")\nmammals <- c(\"Damhert\", \"Haas\", \"Ree\", \"Bever\", \"Bruine Rat\", \"Muskusrat\", \"Mol\", \"Vos\", \"Kat\", \"Otter\", \"Grijze Zeehond\", \"Konijn\",\n             \"Eekhoorn\", \"Edelhert\", \"Gewone Zeehond\", \"Wild Zwijn\", \"Steenmarter\", \"Moeflon\")\ninput_error <- c(\"Steltstrandloper\")\nremove_species <- c(exotics, unlikely_flight_candidate, mammals, input_error)\n\nptt_data %>%\n  filter(!species %in% remove_species) -> ptt_data\n\nwb_data %>%\n  filter(!species %in% remove_species) -> wb_data\nunique_species <- unique(c(wb_data$species, ptt_data$species))\n\nbuild_species_lut <- function(specieslist, datasetKey = NULL, class_name = NULL) {\n  # As this function can possibly return many different records, we pick the scientific name and GBIF ID (nubKey) that are the most\n  # common in the returned results. This should most often result in an OK result of the name lookup function.\n  Mode <- function(x) {\n    ux <- unique(na.omit(x))\n    ux[which.max(tabulate(match(x, ux)))]\n  }\n  \n  n <- length(specieslist)\n  \n  species_lut <- data.frame(lookupname = character(n), \n                            scientificname = character(n), \n                            gbif_key = numeric(n), stringsAsFactors = FALSE)\n  \n  # Somehow the higherTaxonKey changes regularly, so we have to query this first\n  higherTaxonKey <- NULL\n  if (!is.null(class_name)) {\n    class_record <- name_lookup(class_name, datasetKey = datasetKey)\n    higherTaxonKey <- class_record$data$classKey\n  }\n  \n  for(i in seq_along(specieslist)) {\n    gbif_data <- tryCatch({\n      gbif <- name_lookup(specieslist[i], \n                          datasetKey = datasetKey, \n                          higherTaxonKey = higherTaxonKey, \n                          return = \"data\")\n      list(paste(str_split(Mode(gbif$data$scientificName), pattern = \" \")[[1]][1:2], collapse = \" \"), Mode(gbif$data$nubKey))\n    }, error = function(e) {\n      list(\"\", NaN)\n    })\n    \n    species_lut[i, ] <- c(specieslist[i], gbif_data[1], as.numeric(as.character(gbif_data[2])))\n  }\n  \n  return(species_lut)\n}\n\nspecies_lut <- build_species_lut(unique_species, datasetKey = \"4dd32523-a3a3-43b7-84df-4cda02f15cf7\", class_name = \"Aves\")## Warning: `return` param in `name_lookup` function is defunct as of rgbif v3.0.0, and is ignored\n## See `?rgbif` for more information.\n## This warning will be thrown once per R session.## Warning: Unknown or uninitialised column: `scientificName`.\nhead(species_lut, 10) %>%\n  kable(format = \"html\", col.names = colnames(species_lut)) %>%\n  kable_styling() %>%\n  kableExtra::scroll_box(width = \"100%\", height = \"400px\")\n# Change to similar species which is in the LHT database\nspecies_lut[species_lut$lookupname == \"Toendrarietgans\", \"scientificname\"] <- \"Anser fabalis\"  # Taiga Bean Goose\nspecies_lut[species_lut$lookupname == \"Kleine Canadese Gans\", \"scientificname\"] <- \"Branta leucopsis\"  # Barnacle Goose\nspecies_lut[species_lut$lookupname == \"Kleine Barmsijs\", \"scientificname\"] <- \"Acanthis flammea\"  # Redpoll\nspecies_lut[species_lut$lookupname == \"Pontische Meeuw\", \"scientificname\"] <- \"Larus argentatus\"  # Herring Gull\nspecies_lut[species_lut$lookupname == \"Indische Gans\", \"scientificname\"] <- \"Anser albifrons\"  # Greater White-fronted Goose\nspecies_lut[species_lut$lookupname == \"Canadese Gans\", \"scientificname\"] <- \"Branta canadensis\"  # Canada Goose\nspecies_lut[species_lut$lookupname == \"Topper\", \"scientificname\"] <- \"Aythya marila\"  # Greater Scaup\nspecies_lut[species_lut$lookupname == \"Tafeleend\", \"scientificname\"] <- \"Aythya ferina\"  # Greater Scaup\n\n# Change scientific name for same species to match with the LHT database\nspecies_lut[species_lut$lookupname == \"Kleine Zwaan\", \"scientificname\"] <- \"Cygnus columbianus\"  # Bewick's Swan\nspecies_lut[species_lut$lookupname == \"Kokmeeuw\", \"scientificname\"] <- \"Larus ridibundus\"  # Black-headed Gull\nspecies_lut[species_lut$lookupname == \"Smient\", \"scientificname\"] <- \"Mareca penelope\"  # Wigeon\nspecies_lut[species_lut$lookupname == \"Krakeend\", \"scientificname\"] <- \"Mareca strepera\"  # Gadwall\nspecies_lut[species_lut$lookupname == \"Slobeend\", \"scientificname\"] <- \"Spatula clypeata\"  # Northern Shoveler\nspecies_lut[species_lut$lookupname == \"Winterkoning\", \"scientificname\"] <- \"Troglodytes troglodytes\"  # Wren\nspecies_lut[species_lut$lookupname == \"Grote Jager\", \"scientificname\"] <- \"Catharacta skua\"  # Great Skua\nspecies_lut[species_lut$lookupname == \"Roodborsttapuit\", \"scientificname\"] <- \"Saxicola torquatus\"  # Stonechat\nspecies_lut[species_lut$lookupname == \"Strandleeuwerik\", \"scientificname\"] <- \"Eremophila alpestris\"  # Horned Lark"},{"path":"processing-count-results.html","id":"adding-vernacular-family-names","chapter":"5 Processing count results","heading":"5.4 Adding vernacular family names","text":"Fetching vernacular names scientific families GBIF even convoluted name lookup done , instead manually derived list vernacular names families based generated species lookup table.","code":"\nread_delim(\"data/raw/sovon/familyvernacular_lut.csv\", delim = \";\", col_types = cols(lookupname = col_character(), familyvernacular = col_character())) %>%\n  right_join(species_lut, by = \"lookupname\") -> species_lut"},{"path":"processing-count-results.html","id":"linking-life-history-traits-to-species","chapter":"5 Processing count results","heading":"5.5 Linking life-history traits to species","text":"use Life-history characteristics European birds-dataset (Storchová Hořák 2018) calculate mean mass birds PPI pixel. dataset stored Dryad can download . Unfortunately time writing rdryad package severely --date new Dryad API, nicely automate download yet. Anyways, files downloaded manually added data/raw/life-history-characteristics/.calculate mean mass sexed unsexed birds assume represents mean mass species.Now can try link names can found GBIF.GBIF IDs/keys place life-history characteristics, well Sovon counts, can now link datasets together. start waterbirds.PTT counts.Now can verify 1% criteria (see ) species matching met. calculating proportions birds belonging certain species total numbers birds counted within count. result empty dataframe, stop code chunk running case., can PTT counts.way can finally remove remaining empty rows save PTT waterbird counts final form.save data use.","code":"\nread_tsv(\"data/raw/life-history-characteristics/Life-history characteristics of European birds.txt\", \n         col_types = cols_only('Species' = col_character(), 'WeightU_MEAN' = col_double(), 'WeightM_MEAN' = col_double(), 'WeightF_MEAN' = col_double())) %>%\n  rowwise %>%\n  mutate(mean_weight = mean(c(WeightU_MEAN, WeightF_MEAN, WeightM_MEAN))) %>%\n  dplyr::select(Species, mean_weight) %>%\n  rename(species = Species) %>%\n  filter(!any(str_ends(species, \"ssp\"))) %>%  # Filter out birds not identified to species\n  rowwise() %>%\n  mutate(species = paste(str_split(species, pattern = \" \")[[1]][1:2], collapse = \" \")) %>%\n  ungroup() %>%\n  group_by(species) %>%\n  summarise(mean_weight = mean(mean_weight), .groups = \"drop_last\",\n            mean_crs = mean_weight ^ (2/3)) %>%\n  drop_na() -> lhc\n\nlhc[lhc$species == \"Aquila nipalenis\", \"species\"] <- \"Aquila nipalensis\"  # Small error in dataset -> notified author\n\nhead(lhc, 10) %>%\n  kable(format = \"html\", col.names = colnames(lhc)) %>%\n  kable_styling() %>%\n  kableExtra::scroll_box(width = \"100%\", height = \"400px\")\nunique_species_lhc <- unique(lhc$species)\n\nlhc_species_lut <- build_species_lut(unique_species_lhc, dataset = NULL)\n\nhead(lhc_species_lut, 10) %>%\n  kable(format = \"html\", col.names = colnames(lhc_species_lut)) %>%\n  kable_styling() %>%\n  kableExtra::scroll_box(width = \"100%\", height = \"400px\")\nlhc %>%\n  left_join(lhc_species_lut, by = c(\"species\" = \"scientificname\")) %>%\n  dplyr::select(species, mean_weight, mean_crs, gbif_key) -> lhc\n\nwb_data %>%\n  left_join(species_lut, by = c(\"species\" = \"lookupname\")) %>%\n  left_join(dplyr::select(lhc, mean_weight, mean_crs, gbif_key), by = c(\"gbif_key\" = \"gbif_key\")) %>%\n  left_join(dplyr::select(lhc, mean_weight, mean_crs, species), by = c(\"scientificname\" = \"species\")) %>%\n  dplyr::select(-c(mean_weight.x, mean_crs.x)) %>%\n  rename(mean_weight = mean_weight.y, mean_crs = mean_crs.y) -> wb_data_lhc\n\nhead(wb_data_lhc, 10) %>%\n  kable(format = \"html\", col.names = colnames(wb_data_lhc)) %>%\n  kable_styling() %>%\n  kableExtra::scroll_box(width = \"100%\", height = \"400px\")\nptt_data %>%\n  left_join(species_lut, by = c(\"species\" = \"lookupname\")) %>%\n  left_join(dplyr::select(lhc, mean_weight, mean_crs, gbif_key), by = c(\"gbif_key\" = \"gbif_key\")) %>%\n  left_join(dplyr::select(lhc, mean_weight, mean_crs, species), by = c(\"scientificname\" = \"species\")) %>%\n  dplyr::select(-c(mean_weight.x, mean_crs.x)) %>%\n  rename(mean_weight = mean_weight.y, mean_crs = mean_crs.y) -> ptt_data_lhc\n\nhead(ptt_data_lhc, 10) %>%\n  kable(format = \"html\", col.names = colnames(ptt_data_lhc)) %>%\n  kable_styling() %>%\n  kableExtra::scroll_box(width = \"100%\", height = \"400px\")\nwb_data_lhc %>%\n  as.data.frame() %>%\n  group_by(count_id) %>%\n  mutate(total_birds_count = sum(number)) %>%\n  group_by(count_id, species) %>%\n  mutate(proportion_species = sum(number) / total_birds_count) %>%\n  ungroup() %>%\n  arrange(count_id) %>%\n  filter((is.na(mean_weight) & (proportion_species > 0.01))) -> wb_data_lhc_verify\n\nstopifnot(nrow(wb_data_lhc_verify) == 0)\nrm(wb_data_lhc_verify)\nptt_data_lhc %>%\n  as.data.frame() %>%\n  group_by(count_id) %>%\n  mutate(total_birds_count = sum(number)) %>%\n  group_by(count_id, species) %>%\n  mutate(proportion_species = sum(number) / total_birds_count) %>%\n  ungroup() %>%\n  arrange(count_id) %>%\n  filter((is.na(mean_weight) & (proportion_species > 0.01))) -> ptt_data_lhc_verify\n\nstopifnot(nrow(ptt_data_lhc_verify) == 0)\nrm(ptt_data_lhc_verify)\nptt_data_lhc %>%\n  drop_na() -> ptt_data\n\nwb_data_lhc %>%\n  drop_na() -> wb_data\nsaveRDS(ptt_data, file = \"data/processed/sovon/ptt.RDS\")\nsaveRDS(wb_data, file = \"data/processed/sovon/wb.RDS\")"},{"path":"processing-count-results.html","id":"calculating-total-bird-biomass","chapter":"5 Processing count results","heading":"5.6 Calculating total bird biomass","text":", already calculate total biomass contained within count areas, can add values PPIs IDs count areas/routes. use waterbird count January 2018, point-transect counts 2017, best terms coverage.now save datasets total_biomass well.","code":"\nwb_year <- 2018\nptt_year <- 2017\n\nwb_data %>%\n  mutate(area_nr = as.character(area_nr)) %>%\n  filter(year == wb_year) %>%\n  rowwise() %>%\n  mutate(specific_biomass = number * mean_weight,\n         specific_crs = number * mean_crs) %>%\n  ungroup() %>%\n  group_by(area_nr, year) %>%\n  summarise(total_biomass = sum(specific_biomass),\n            total_crs = sum(specific_crs),\n            weighted_mean_weight = weighted.mean(mean_weight, number),\n            weighted_mean_crs = weighted.mean(mean_crs, number),\n            total_birds = sum(number),\n            .groups = \"drop_last\") %>%\n  ungroup() %>%\n  group_by(area_nr) %>%  # Below is only required if year-filter is NOT set, otherwise does nothing\n  summarise(total_biomass = mean(total_biomass),\n            total_crs = mean(total_crs),\n            weighted_mean_weight = mean(weighted_mean_weight),\n            weighted_mean_crs = mean(weighted_mean_crs),\n            total_birds = mean(total_birds),\n            .groups = \"drop_last\") %>%\n  identity() -> wb_biomass\n\nptt_data %>%\n  filter(year == ptt_year) %>%\n  rowwise() %>%\n  mutate(specific_biomass = number * mean_weight,\n         specific_crs = number * mean_crs) %>%\n  ungroup() %>%\n  group_by(route, year) %>%\n  summarise(total_biomass = sum(specific_biomass),\n            total_crs = sum(specific_crs),\n            weighted_mean_weight = weighted.mean(mean_weight, number),\n            weighted_mean_crs = weighted.mean(mean_crs, number),\n            total_birds = sum(number),\n            .groups = \"drop_last\") %>%\n  ungroup() %>%\n  group_by(route) %>%  # Below is only required if year-filter is NOT set, otherwise does nothing\n  summarise(total_biomass = mean(total_biomass),\n            total_crs = mean(total_crs),\n            weighted_mean_weight = mean(weighted_mean_weight),\n            weighted_mean_crs = mean(weighted_mean_crs),\n            total_birds = mean(total_birds),\n            .groups = \"drop_last\") %>%\n  identity() -> ptt_biomass\nsaveRDS(wb_biomass, file = \"data/processed/sovon/wb_biomass.RDS\")\nsaveRDS(ptt_biomass, file = \"data/processed/sovon/ptt_biomass.RDS\")"},{"path":"processing-count-results.html","id":"calculating-proportions-across-bird-families","chapter":"5 Processing count results","heading":"5.7 Calculating proportions across bird families","text":"Now identified families birds belong , can calculate proportion birds belong families across PTT waterbird counts. can give idea spatial composition bird communities illustrate analysis results .now save datasets family proportions well.","code":"\nwb <- wb_data\nptt <- ptt_data\nfamilies <- unique(species_lut$familyvernacular)\n\nwb %>%\n  mutate(area_nr = as.character(area_nr)) %>%\n  filter(year == wb_year) %>%\n  group_by(area_nr, year) %>%\n  mutate(total_birds = sum(number)) %>%\n  ungroup() %>%\n  group_by(area_nr, year, familyvernacular) %>%\n  mutate(familyprop = sum(number) / total_birds) %>%\n  ungroup() %>%\n  dplyr::select(area_nr, familyvernacular, familyprop, total_birds) %>%\n  distinct() %>%\n  arrange(area_nr) %>%\n  pivot_wider(names_from = familyvernacular, values_from = familyprop) %>%\n  replace(is.na(.), 0) %>%\n  identity() -> wb_props\n\nptt %>%\n  filter(year == ptt_year) %>%\n  group_by(route, year) %>%\n  mutate(total_birds = sum(number)) %>%\n  ungroup() %>%\n  group_by(route, year, familyvernacular) %>%\n  mutate(familyprop = sum(number) / total_birds) %>%\n  ungroup() %>%\n  dplyr::select(route, familyvernacular, familyprop, total_birds) %>%\n  distinct() %>%\n  arrange(route) %>%\n  pivot_wider(names_from = familyvernacular, values_from = familyprop) %>%\n  replace(is.na(.), 0) %>%\n  identity() -> ptt_props\nsaveRDS(wb_props, file = \"data/processed/sovon/wb_props.RDS\")\nsaveRDS(ptt_props, file = \"data/processed/sovon/ptt_props.RDS\")"},{"path":"processing-count-results.html","id":"export-lookup-table-characteristic-groups","chapter":"5 Processing count results","heading":"5.8 Export lookup table characteristic groups","text":"store lookup table characteristic groups scientific names .csv WebTable paper.","code":"\nptt %>%\n  dplyr::select(species, scientificname, familyvernacular, mean_weight, mean_rcs = mean_crs) %>%\n  distinct(scientificname, .keep_all = TRUE) %>%\n  group_by(familyvernacular) %>%\n  mutate(family_mean_weight = mean(mean_weight)) %>%\n  ungroup() %>%\n  arrange(desc(family_mean_weight), desc(mean_weight)) %>%\n  write.csv(\"data/processed/sovon/lut_species_family.csv\")"},{"path":"processing-count-results.html","id":"summary-statistics-for-webpanel","chapter":"5 Processing count results","heading":"5.9 Summary statistics for WebPanel","text":"Number PTT counts includedNumber waterbird counts included","code":"\nptt %>%\n  distinct(count_id) %>%\n  nrow()## [1] 593\nwb %>%\n  distinct(area_nr) %>%\n  nrow()## [1] 3472"},{"path":"apply-processing-to-all-ppis.html","id":"apply-processing-to-all-ppis","chapter":"6 Apply processing to all PPIs","heading":"6 Apply processing to all PPIs","text":"far explained processing ‘pipeline’ PPIs Herwijnen Den Helder radars, applied single moment time, single volume scan. Now apply processing available PPIs simply copying annotations case ever need repeat analysis scans.far done following:Pre-processed radar data, removing clutter applying range-bias correction (Kranstauber et al. 2020).Annotated PPIs land use class proportions, distance inhabited areas human population.Annotated PPIs corresponding count locations Sovon data.Connected Sovon count data life-history characteristics species contained within calculated bird biomass.","code":""},{"path":"apply-processing-to-all-ppis.html","id":"processing-environment-5","chapter":"6 Apply processing to all PPIs","heading":"6.1 Processing environment","text":"","code":"\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(kableExtra)"},{"path":"apply-processing-to-all-ppis.html","id":"load-the-reference-ppis","chapter":"6 Apply processing to all PPIs","heading":"6.2 Load the reference PPIs","text":"Two PPIs processed way ‘reference’ PPIs copy data PPIs treatment.","code":"\nppi_hrw <- readRDS(\"data/processed/corrected-ppis-lu-sovon/corrected_ppi_hrw_lu_sovon.RDS\")\nppi_dhl <- readRDS(\"data/processed/corrected-ppis-lu-sovon/corrected_ppi_dhl_lu_sovon.RDS\")"},{"path":"apply-processing-to-all-ppis.html","id":"add-biomass-and-cross-sections-to-reference-ppis","chapter":"6 Apply processing to all PPIs","heading":"6.3 Add biomass and cross-sections to reference PPIs","text":"previously calculated total_biomass already count areas/routes, now annotate reference PPIs values well. correct size area count conducted ‘spreading’ total biomass number pixels annotated certain count area/route.","code":"\nwb <- readRDS(\"data/processed/sovon/wb_biomass.RDS\")\nptt <- readRDS(\"data/processed/sovon/ptt_biomass.RDS\")\n\nppi_hrw$data@data %<>%\n  left_join(dplyr::select(wb, area_nr, total_biomass, weighted_mean_weight, total_crs, weighted_mean_crs, total_birds), by = c(\"wb_area_nr\" = \"area_nr\")) %>%\n  rename(wb_total_biomass = total_biomass,\n         wb_total_crs = total_crs,\n         wb_weighted_mean_weight = weighted_mean_weight,\n         wb_weighted_mean_crs = weighted_mean_crs,\n         wb_total_birds = total_birds) %>%\n  group_by(wb_area_nr) %>%\n  mutate(wb_total_biomass = wb_total_biomass / n(),\n         wb_total_crs = wb_total_crs / n(),\n         wb_total_birds = wb_total_birds / n()) %>%  \n  ungroup() %>%\n  left_join(dplyr::select(ptt, route, total_biomass, weighted_mean_weight, total_crs, weighted_mean_crs, total_birds), by = c(\"ptt_route\" = \"route\")) %>%\n  rename(ptt_total_biomass = total_biomass,\n         ptt_total_crs = total_crs,\n         ptt_weighted_mean_weight = weighted_mean_weight,\n         ptt_weighted_mean_crs = weighted_mean_crs,\n         ptt_total_birds = total_birds) %>%\n  group_by(ptt_route) %>%\n  mutate(ptt_total_biomass = ptt_total_biomass / n(),\n         ptt_total_crs = ptt_total_crs / n(),\n         ptt_total_birds = ptt_total_birds / n()) %>% \n  ungroup() %>%\n  rowwise() %>%\n  mutate(total_biomass = sum(wb_total_biomass, ptt_total_biomass, na.rm = TRUE),\n         total_crs = sum(wb_total_crs, ptt_total_crs, na.rm = TRUE),\n         weighted_mean_weight = mean(c(wb_weighted_mean_weight, ptt_weighted_mean_weight), na.rm = TRUE),\n         weighted_mean_crs = mean(c(wb_weighted_mean_crs, ptt_weighted_mean_crs), na.rm = TRUE),\n         total_birds = round(sum(wb_total_birds, ptt_total_birds, na.rm = TRUE))) %>%\n  ungroup()## Loading required package: sp\nppi_dhl$data@data %<>%\n  left_join(dplyr::select(wb, area_nr, total_biomass, weighted_mean_weight, total_crs, weighted_mean_crs, total_birds), by = c(\"wb_area_nr\" = \"area_nr\")) %>%\n  rename(wb_total_biomass = total_biomass,\n         wb_total_crs = total_crs,\n         wb_weighted_mean_weight = weighted_mean_weight,\n         wb_weighted_mean_crs = weighted_mean_crs,\n         wb_total_birds = total_birds) %>%\n  group_by(wb_area_nr) %>%\n  mutate(wb_total_biomass = wb_total_biomass / n(),\n         wb_total_crs = wb_total_crs / n(),\n         wb_total_birds = wb_total_birds / n()) %>%\n  ungroup() %>%\n  left_join(dplyr::select(ptt, route, total_biomass, weighted_mean_weight, total_crs, weighted_mean_crs, total_birds), by = c(\"ptt_route\" = \"route\")) %>%\n  rename(ptt_total_biomass = total_biomass,\n         ptt_total_crs = total_crs,\n         ptt_weighted_mean_weight = weighted_mean_weight,\n         ptt_weighted_mean_crs = weighted_mean_crs,\n         ptt_total_birds = total_birds) %>%\n  group_by(ptt_route) %>%\n  mutate(ptt_total_biomass = ptt_total_biomass / n(),\n         ptt_total_crs = ptt_total_crs / n(),\n         ptt_total_birds = ptt_total_birds / n()) %>%\n  ungroup() %>%\n  rowwise() %>%\n  mutate(total_biomass = sum(wb_total_biomass, ptt_total_biomass, na.rm = TRUE),\n         total_crs = sum(wb_total_crs, ptt_total_crs, na.rm = TRUE),\n         weighted_mean_weight = mean(c(wb_weighted_mean_weight, ptt_weighted_mean_weight), na.rm = TRUE),\n         weighted_mean_crs = mean(c(wb_weighted_mean_crs, ptt_weighted_mean_crs), na.rm = TRUE),\n         total_birds = round(sum(wb_total_birds, ptt_total_birds, na.rm = TRUE))) %>%\n  ungroup()"},{"path":"apply-processing-to-all-ppis.html","id":"copy-annotations-from-reference-ppis-to-other-ppis","chapter":"6 Apply processing to all PPIs","heading":"6.4 Copy annotations from reference PPIs to other PPIs","text":"select variables related land use, distance inhabited areas population density, waterbird counts PTT counts add PPIs contain just variables resulting range-bias correction (Kranstauber et al. 2020).","code":"\ncolumns <- c(\"urban\", \"agricultural\", \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\", \"land\",\n             \"dist_urban\", \"human_pop\", \"wb_area_id\", \"wb_area_nr\", \"ptt_route\",\n             \"wb_area_id\", \"wb_area_nr\", \"wb_area_ha\", \"ptt_route\", \"wb_total_biomass\", \"ptt_total_biomass\", \"total_biomass\", \n             \"wb_weighted_mean_weight\", \"ptt_weighted_mean_weight\", \"weighted_mean_weight\", \n             \"wb_total_crs\", \"ptt_total_crs\", \"total_crs\", \"wb_weighted_mean_crs\", \"ptt_weighted_mean_crs\", \"weighted_mean_crs\",\n             \"wb_total_birds\", \"ptt_total_birds\", \"total_birds\")\n\nhrw <- ppi_hrw$data@data %>%\n  dplyr::select(all_of(columns))\n\ndhl <- ppi_dhl$data@data %>%\n  dplyr::select(all_of(columns))\n\nhrw_all <- ppi_hrw$data@data %>%\n  filter(row_number() == 0)\n\ndhl_all <- ppi_dhl$data@data %>%\n  filter(row_number() == 0)\n\nhrw_ppis <- Sys.glob(file.path(\"data/processed/corrected-ppis\", \"*NL62*\"))\ndhl_ppis <- Sys.glob(file.path(\"data/processed/corrected-ppis\", \"*NL61*\"))\n\nfor (ppi_path in hrw_ppis) {\n  ppi <- readRDS(ppi_path)\n  ppi$data@data <- bind_cols(ppi$data@data, hrw)\n  saveRDS(ppi, file = paste(\"data/processed/final-ppis/\", basename(ppi_path), sep = \"\"))\n}\n\nfor (ppi_path in dhl_ppis) {\n  ppi <- readRDS(ppi_path)\n  ppi$data@data <- bind_cols(ppi$data@data, dhl)\n  saveRDS(ppi, file = paste(\"data/processed/final-ppis/\", basename(ppi_path), sep = \"\"))\n}\n\nhrw_ppis <- Sys.glob(file.path(\"data/processed/baseline-ppis\", \"NLHRW*\"))\ndhl_ppis <- Sys.glob(file.path(\"data/processed/baseline-ppis\", \"NLDHL*\"))\n\nfor (ppi_path in hrw_ppis) {\n  ppi <- readRDS(ppi_path)\n  ppi$data@data <- bind_cols(ppi$data@data, hrw)\n  saveRDS(ppi, file = paste(\"data/processed/final-ppis-baseline/\", basename(ppi_path), sep = \"\"))\n}\n\nfor (ppi_path in dhl_ppis) {\n  ppi <- readRDS(ppi_path)\n  ppi$data@data <- bind_cols(ppi$data@data, dhl)\n  saveRDS(ppi, file = paste(\"data/processed/final-ppis-baseline/\", basename(ppi_path), sep = \"\"))\n}"},{"path":"composite-all-ppis.html","id":"composite-all-ppis","chapter":"7 Composite all PPIs","heading":"7 Composite all PPIs","text":"preprocessing done, can now make composites PPIs ‘solve’ overlapping areas Den Helder Herwijnen radars. ’re , also render composites VIR, visualise en-masse take-birds.","code":""},{"path":"composite-all-ppis.html","id":"processing-environment-6","chapter":"7 Composite all PPIs","heading":"7.1 Processing environment","text":"","code":"\nlibrary(bioRad)\nlibrary(ggplot2)\nlibrary(magick)\nlibrary(purrr)\nlibrary(viridis)\nlibrary(dplyr)\nlibrary(stringr)"},{"path":"composite-all-ppis.html","id":"generating-the-composite-ppis","chapter":"7 Composite all PPIs","heading":"7.2 Generating the composite PPIs","text":"loop Herwijnen Den Helder PPIs generated far create composite PPIs included parameters. generate composites 500m, 1000m 2000m resolution later test resolution models perform best. Additionally save composites bunch .png files can use separately inclued animated GIF .also generate composite PPIs baseline PPIs using procedure.","code":"\nsource(\"R/comp_ppi.R\")\nhrw_ppis <- Sys.glob(file.path(\"data/processed/final-ppis\", \"*NL62*\"))\ndhl_ppis <- Sys.glob(file.path(\"data/processed/final-ppis\", \"*NL61*\"))\n\ngenerate_composites <- function(hrw_ppis, dhl_ppis, res, maxrange, output_dir_ppi, output_dir_vis) {\n  basemap <- NULL\n  \n  for (i in seq_along(hrw_ppis)) {\n    ppi_hrw <- readRDS(hrw_ppis[i])\n    print(hrw_ppis[i])\n    ppi_dhl <- readRDS(dhl_ppis[i])\n    print(dhl_ppis[i])\n    \n    # Set all columns to NA if further than maxrange from radar\n    ppi_hrw$data@data[ppi_hrw$data@data$dist_radar > maxrange, ] <- NA\n    ppi_dhl$data@data[ppi_dhl$data@data$dist_radar > maxrange, ] <- NA\n    \n    params <- c(\"VIR\", \"VID\", \"R\", \"overlap\", \"eta_sum\", \"eta_sum_expected\", \"dist_radar\", \"class\", \"land\",\n                \"urban\", \"agricultural\", \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\", \"dist_urban\", \"human_pop\",\n                \"wb_area_id\", \"wb_area_nr\", \"ptt_route\", \"wb_area_ha\", \"wb_total_biomass\", \"ptt_total_biomass\", \"total_biomass\", \n                \"wb_weighted_mean_weight\", \"ptt_weighted_mean_weight\", \"weighted_mean_weight\",\n                \"wb_total_crs\", \"ptt_total_crs\", \"total_crs\",\n                \"wb_weighted_mean_crs\", \"ptt_weighted_mean_crs\", \"weighted_mean_crs\",\n                \"wb_total_birds\", \"ptt_total_birds\", \"total_birds\")\n    # All mean methods except for factors and urban area (set to max), because we want to strictly filter out fireworks\n    methods <- c(\"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"min\", \"min\", \"min\",\n                 \"max\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \n                 \"factor\", \"factor\", \"factor\", \"factor\", \"mean\", \"mean\", \"mean\",\n                 \"mean\", \"mean\", \"mean\", \n                 \"mean\", \"mean\", \"mean\",\n                 \"mean\", \"mean\", \"mean\",\n                 \"mean\", \"mean\", \"mean\")\n    cppi <- comp_ppi(list(ppi_hrw, ppi_dhl), param = params, method = methods, res = c(res, res), coverage = \"count\")\n    \n    # Set rain and background pixels to NA\n    cppi$data$VIR[cppi$data$class < 2] <- NA\n    \n    # Add coordinates\n    coords_cppi <- raster::coordinates(cppi$data)\n    cppi$data$x <- coords_cppi[, 1]\n    cppi$data$y <- coords_cppi[, 2]\n    \n    # Add pixel ID\n    cppi$data@data %>%\n      mutate(pixel = row_number()) -> cppi$data@data\n    \n    # Solve different factors\n    solve_factors <- function(x) {\n      r <- x[1]\n      if (is.na(x[1]) && is.na(x[2])) { r <- NA }\n      if (is.na(x[1]) && !is.na(x[2])) { r <- x[2] }\n      if (!is.na(x[1]) && is.na(x[2])) { r <- x[1] }\n      if (!is.na(x[1]) && !is.na(x[2])) {\n        if (x[1] != x[2]) {\n          r <- NA\n        } else {\n          r <- x[1]\n        }\n      }\n      r\n    }\n    \n    for (j in which(methods == \"factor\")) {\n      cppi$data@data[params[j]] <- apply(cppi$data@data[params[j]], 1, solve_factors)\n    }\n    \n    saveRDS(cppi, file = paste(output_dir_ppi, res, \"m/\", strftime(ppi_hrw$datetime, format = \"%Y%m%d%H%M\"), \".RDS\", sep = \"\"))\n    \n    if (i == 1) {\n      basemap <- download_basemap(cppi, alpha = 0.3)\n    }\n    \n    cppi$data$VIR <- log10(cppi$data$VIR)\n    cppi$data$VIR[is.na(cppi$data$VIR)] <- 0\n    \n    bioRad::map(cppi, map = basemap, radar_size = 1, xlim = c(3.1, 6.8), ylim = c(51, 54), zlim = c(0, 4.5),\n                palette = viridis(256, option = \"viridis\", alpha = 0.6)) +\n      labs(title = \"Fireworks NYE 2017-2018\",\n           subtitle = paste(ppi_hrw$datetime, ' UTC', sep = \"\"))\n\n    ggsave(paste(output_dir_vis, res, \"m/\", strftime(ppi_hrw$datetime, format = \"%Y%m%d%H%M\"), \".png\", sep = \"\"))\n  }\n}\n\nr <- lapply(c(500, 1000, 2000), function(x) { generate_composites(hrw_ppis, dhl_ppis, res = x, maxrange = 66000,\n                                                                  output_dir_ppi = \"data/processed/composite-ppis/\",\n                                                                  output_dir_vis = \"data/plots/vir-ppis/\")})\nhrw_ppis <- Sys.glob(file.path(\"data/processed/final-ppis-baseline\", \"NLHRW*\"))\ndhl_ppis <- Sys.glob(file.path(\"data/processed/final-ppis-baseline\", \"NLDHL*\"))\n\nextract_dt <- function(filepath) {\n  file <- basename(filepath)\n  str_split(basename(file), \"_\")[[1]][3]\n}\nhrw_dts <- unlist(lapply(hrw_ppis, extract_dt))\ndhl_dts <- unlist(lapply(dhl_ppis, extract_dt))\n\nhrw_selection <- sort(hrw_ppis[hrw_dts %in% dhl_dts])\ndhl_selection <- sort(dhl_ppis[dhl_dts %in% hrw_dts])\n\nr <- lapply(c(500, 1000, 2000), function(x) { generate_composites(\n  hrw_selection, dhl_selection, res = x, maxrange = 66000,\n  output_dir_ppi = \"data/processed/composite-ppis-baseline/\",\n  output_dir_vis = \"data/plots/vir-ppis-baseline/\")})"},{"path":"composite-all-ppis.html","id":"visualising-the-composites","chapter":"7 Composite all PPIs","heading":"7.3 Visualising the composites","text":"order run comparatively simple conversion GIF PPIs, may necessary increase memory available ImageMagick changing memory policy /etc/ImageMagick-6/policy.xml. Additionally, reduce resolution animated GIF ’ll stick 1000m resolution PPIs.","code":"\nwidth <- 800\n\ncomposites <- list.files(path = \"data/plots/vir-ppis/1000m/\", pattern = \"*.png\", full.names = TRUE)\n\nprocess_image <- function(img_path) {\n  image_read(img_path) %>%\n    image_resize(geometry_size_pixels(width = width)) %>%\n    image_write(path = paste(tools::file_path_sans_ext(img_path), \".jpeg\", sep = \"\"), format = \"jpeg\")\n}\n\nfor (file in list.files(path = \"data/plots/vir-ppis/\", pattern = \"*.png\", full.names = TRUE)) {\n  process_image(file)\n}\n\nlist.files(path = \"data/plots/vir-ppis/\", pattern = \"*.jpeg\", full.names = T) %>%\n  purrr::map(image_read) %>%\n  image_join() %>%\n  image_animate(fps = 2) %>%\n  image_write(\"data/plots/vir-ppis/NYE-2017-2018.gif\")"},{"path":"modelling-fireworks-disturbance.html","id":"modelling-fireworks-disturbance","chapter":"8 Modelling fireworks disturbance","heading":"8 Modelling fireworks disturbance","text":"far:Pre-processed radar data removing clutter applying range-bias correction (Kranstauber et al. 2020).Annotated PPIs land use proportions indicators disturbance, .e. distance inhabited urban areas (human) population density.Annotated PPIs total biomass calculated Sovon counts.dataset annotated PPIs, can start explore relation fireworks disturbance birds measured aloft NYE 2017-2018.following parameters assume important predictors measured bird densities aloft:total radar cross-section birds ground.take-habitat birds.human population vicinity birds.distance nearest inhabited urban area.","code":""},{"path":"modelling-fireworks-disturbance.html","id":"processing-environment-7","chapter":"8 Modelling fireworks disturbance","heading":"8.1 Processing environment","text":"previous chapter, created datasets encompassing data contained within individual PPIs different resolutions. determine optimal resolution continue using dataset modelling.","code":"\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(tidyr)\nlibrary(parallel)\nlibrary(ggridges)\nlibrary(pgirmess)\nlibrary(mboost)\nlibrary(leaflet)\nlibrary(leaflet.opacity)\nlibrary(leafem)\nlibrary(usdm)\nlibrary(mapview)\nlibrary(spdep)\nlibrary(stringr)\nselected_scan <- load(\"data/processed/pvol_selection.RData\")\nscan_dt <- str_extract(basename(pvol_dhl_path), \"[0-9]{12}\")\nresolutions <- file.path(\"data/processed/composite-ppis\", c(\"500m\", \"1000m\", \"2000m\"), paste0(scan_dt, \".RDS\"))\ndata <- lapply(resolutions, function(x) readRDS(x)[[\"data\"]]@data)\nnames(data) <- c(\"500m\", \"1000m\", \"2000m\")"},{"path":"modelling-fireworks-disturbance.html","id":"preparing-a-dataset-for-modelling","chapter":"8 Modelling fireworks disturbance","heading":"8.2 Preparing a dataset for modelling","text":"’re mostly interested moment en masse take-birds, want limit effects dispersal, limit analysis first 5 minutes 00:05 January 1st, 2018 (23:05 December 31st, 2017 UTC), radar sites (Den Helder Herwijnen) show low VIR prior rapid increase VIR period (see Identifying moment take-). Making sure birds thus still sufficiently ‘linked’ take-sites requires limit analysis one scan.Furthermore, want make sure :area ‘covered’ least 1 radar,estimate total_rcs (thus total_biomass) sites,proportion urban area (urban) PPI pixel less .1,VIR > 0 (otherwise log-conversion return -Inf), replace 0-values 1e-3,radar beam overshoot birds much based vp.","code":"\nclean_data <- function(data, max_distance) {\n  mdl_variables <- c(\"VIR\", \"dist_radar\", \"total_biomass\", \"total_crs\",\n                     \"agricultural\", \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\", \"urban\",\n                     \"dist_urban\", \"human_pop\", \"disturb_pot\", \"pixel\", \"coverage\", \"class\", \"x\", \"y\")\n  log10_variables <- c(\"dist_urban\", \"human_pop\", \"total_biomass\", \"dist_urban\", \"disturb_pot\")\n  \n  data %>%\n    dplyr::filter(coverage > 0,\n                  class != 1,\n                  total_biomass > 0,\n                  dist_radar < max_distance,\n                  urban < 0.1) %>%\n    mutate(VIR = replace_na(VIR, 0.1),\n           VIR = if_else(VIR == 0, 0.1, VIR),\n           VIR = log10(VIR),\n           disturb_pot = human_pop / dist_urban,\n           total_biomass = total_biomass / 1000) %>%\n    dplyr::select(all_of(mdl_variables)) %>%\n    filter_all(all_vars(is.finite(.))) %>%\n    rename(total_rcs = total_crs) %>%\n    identity() -> data_cleaned\n  \n  data_cleaned\n}\n\ndata_cleaned <- lapply(data, function(x) clean_data(x, 66000))\nrm(data)"},{"path":"modelling-fireworks-disturbance.html","id":"determine-model-resolution-based-on-performance-in-simple-total_crs-model","chapter":"8 Modelling fireworks disturbance","heading":"8.3 Determine model resolution based on performance in simple total_crs model","text":"want account influence total_rcs measured response radars, test performance simple model using just dist_radar correct range-biased measurement error total_rcs resolutions generated composte PPIs far (500m, 1000m 2000m).Let’s start calculation RMSE.can also use percentage deviance explainedTurns models perform quite similarly. However, make link birds habitat take strong possible, makes sense continue just 500m model.","code":"\nresolution_models <- lapply(data_cleaned, function(x) mboost(VIR ~ bbs(dist_radar) + bbs(total_rcs), \n                                                             data = x, control = boost_control(mstop = 10000, trace = TRUE)))\nsaveRDS(resolution_models, file = \"data/models/resolution_models.RDS\")\nresolution_models <- readRDS(\"data/models/resolution_models.RDS\")\nRMSE <- function(error) { sqrt(mean(error^2)) }\nsapply(resolution_models, function(x) RMSE(residuals(x)))##     500m    1000m    2000m \n## 1.236034 1.239162 1.248618\ndeviance_explained <- function(observed, predicted) {\n  p <- predicted\n  o <- observed\n  i <- rep(mean(observed), length(observed))  # Intercept\n  total.deviance <- sum((o - i) * (o - i)) / length(observed)  # Deviance from an intercept-only model\n  resid.deviance <- sum((o - p) * (o - p)) / length(observed)  # Deviance from the fitted model\n  (total.deviance - resid.deviance) / total.deviance\n}\n\nmapply(function(data, model) { deviance_explained(data$VIR, predict(model))}, data = data_cleaned, model = resolution_models)##      500m     1000m     2000m \n## 0.2233546 0.2247612 0.2255258\ndata_cleaned <- data_cleaned$`500m`\nsaveRDS(data_cleaned, file = \"data/models/data_cleaned.RDS\")\nrm(resolution_models)"},{"path":"modelling-fireworks-disturbance.html","id":"check-for-correlations-among-predictors","chapter":"8 Modelling fireworks disturbance","heading":"8.4 Check for correlations among predictors","text":"see variables strongly correlated thus unfit included model, calculate Spearman correlation coefficients numerical predictors. ecological data, degree correlation course inevitable variables.obviously correlation disturbance proxies agricultural land use proportions. disturbance proxies make sense determine performant (including make sense), can continue using agricultural predictor boosted models suffer multicollinearity problems like traditional (e.g.) GAMs.","code":"\nmdl_variables <- c(\"VIR\", \"dist_radar\", \"datetime\", \"total_biomass\", \"total_rcs\", \"agricultural\", \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\",\n                   \"urban\", \"dist_urban\", \"human_pop\", \"disturb_pot\", \"pixel\", \"coverage\", \"class\")\npredictors <- mdl_variables[!mdl_variables %in% c(\"VIR\", \"datetime\", \"pixel\", \"x\", \"y\", \"coverage\", \"class\")]\ncorr_radar <- ggstatsplot::ggcorrmat(data_cleaned, output = \"plot\", type = \"spearman\", cor.vars = all_of(predictors), colors = c(\"#2166AC\", \"#F7F7F7\", \"#B2182B\"))\ncorr_radar"},{"path":"modelling-fireworks-disturbance.html","id":"correlated-land-use-proportions","chapter":"8 Modelling fireworks disturbance","heading":"8.5 Correlated land use proportions","text":"’re , let’s see distributions values different land use proportions.can expected Netherlands, dominant land use class clearly agricultural prominent peak full PPI pixel coverage (values close 1) land use classes peaking strongly low proportions. essentially means one land use classes increases proportion, almost always come cost proportion agricultural vice versa.","code":"\ndata_cleaned %>%\n  dplyr::select(agricultural, semiopen, forests, wetlands, waterbodies) %>%\n  pivot_longer(cols = everything(), names_to = \"landuse\", values_to = \"value\") %>%\n  ggplot(aes(x = value, y = landuse, fill = stat(x))) +\n  geom_density_ridges_gradient(scale = 1, rel_min_height = 0.0) +\n  scale_fill_viridis_c(name = \"LU Prop.\", option = \"C\") +\n  labs(title = \"Distribution of land use proportions in modelling dataset\") +\n  xlab(\"Land use proportion\") +\n  ylab(\"Land use class\")"},{"path":"modelling-fireworks-disturbance.html","id":"determine-the-most-suitable-proxy-for-disturbance","chapter":"8 Modelling fireworks disturbance","heading":"8.6 Determine the most suitable proxy for disturbance","text":"Now compare disturbance proxies similar fashion compared performance model using different PPI resolutions, calculating deviance explained RMSE.clear dist_urban performs best, though just slight margin. probably interpretable proxy policy perspective, can thus continue using without regrets.","code":"\nfm_dist_urban <- VIR ~ bbs(dist_radar) + bbs(total_rcs) + bbs(semiopen) + bbs(forests) + bbs(wetlands) + bbs(waterbodies) +\n  bbs(agricultural) + bbs(dist_urban)\nfm_human_pop <- VIR ~ bbs(dist_radar) + bbs(total_rcs) + bbs(semiopen) + bbs(forests) + bbs(wetlands) + bbs(waterbodies) + \n  bbs(agricultural) + bbs(human_pop)\nfm_disturb_pot <- VIR ~ bbs(dist_radar) + bbs(total_rcs) + bbs(semiopen) + bbs(forests) + bbs(wetlands) + bbs(waterbodies) + \n  bbs(agricultural) + bbs(disturb_pot)\nformulas <- list(fm_dist_urban, fm_human_pop, fm_disturb_pot)\n\ndisturbance_models <- lapply(formulas, function(formula) mboost(formula, data = data_cleaned, control = boost_control(mstop = 10000, trace = TRUE)))\nnames(disturbance_models) <- c(\"dist_urban\", \"human_pop\", \"disturb_pot\")\nsaveRDS(disturbance_models, file = \"data/models/disturbance_models.RDS\")\ndisturbance_models <- readRDS(\"data/models/disturbance_models.RDS\")\nRMSE <- function(error) { sqrt(mean(error^2)) }\nrmse <- sapply(disturbance_models, function(x) RMSE(residuals(x)))\nd2 <- mapply(function(model) { deviance_explained(data_cleaned$VIR, predict(model))}, model = disturbance_models)\nperf_original <- as.data.frame(list(\"RMSE\" = as.matrix(rmse), \"Dev.Exp\" = as.matrix(d2)))\nperf_original\nmodel <- disturbance_models$dist_urban\nsaveRDS(model, file = \"data/models/model.RDS\")\nrm(disturbance_models)"},{"path":"modelling-fireworks-disturbance.html","id":"determine-the-optimal-number-of-boosting-steps","chapter":"8 Modelling fireworks disturbance","heading":"8.7 Determine the optimal number of boosting steps","text":"main hyperparameter tuned boosted GAMs using mboost number boosting iterations/steps. stopping boosting model performance (measured using cross-validation) worsens, can avoid overfitting. limit test model performance maximum 50,000 boosts.can see model performance improves little beyond thousand boosting iterations. quantify model uncertainty using bootstrapping techniques, makes little computational sense push much beyond 10000 boosts, just make bootstrapping procedure last much longer.","code":"\nmodel_boosts <- mboost(fm_dist_urban, data = data_cleaned, control = boost_control(mstop = 1000, trace = FALSE))\nsaveRDS(model_boosts, file = \"data/models/model_boosts.RDS\")\n\ngrid <- c(1.68^(1:20), 50000)  # Generate a non-linear grid of mstop values to avoid slow convergence\n\ncv10f <- mboost::cv(model.weights(model_boosts), type = \"kfold\")\nsaveRDS(cv10f, file = \"data/models/boost_cv10f.RDS\")\n\ncvm <- cvrisk(model_boosts, folds = cv10f, grid = grid, papply = lapply)\nsaveRDS(cvm, file = \"data/models/cvm_boosts.RDS\")\ncvm <- readRDS(\"data/models/cvm_boosts.RDS\")\nclass(cvm) <- NULL\nas.data.frame(cvm) %>%\n  tibble::rownames_to_column(var = \"fold\") %>%\n  pivot_longer(-c(fold), names_to = \"boosts\", values_to = \"risk\") %>%\n  mutate(boosts = as.numeric(boosts),\n         fold = as.factor(fold)) %>%\n  identity() %>%\n  ggplot(aes(x = boosts, y = risk, group = fold, color = fold)) +\n    geom_line() +\n    labs(title = paste0(attr(cvm, \"type\")), x = \"boosts (mstop)\", y = attr(cvm, \"risk\")) +\n  scale_x_continuous(trans = \"log10\")"},{"path":"modelling-fireworks-disturbance.html","id":"variable-importance","chapter":"8 Modelling fireworks disturbance","heading":"8.8 Variable importance","text":"can quantify importance variables within model using varimp function returns variable importance, measure total improvement model deviance variable responsible .","code":"\nplot(varimp(model))"},{"path":"modelling-fireworks-disturbance.html","id":"model-marginal-effects","chapter":"8 Modelling fireworks disturbance","heading":"8.9 Model marginal effects","text":"Let’s quickly visualise marginal effects model, showing individual variables influence model outcome variables held constant.","code":"\npar(mfrow = c(2, 4))\nplot(model)"},{"path":"modelling-fireworks-disturbance.html","id":"spatial-autocorrelation","chapter":"8 Modelling fireworks disturbance","heading":"8.10 Spatial autocorrelation","text":"Model residuals show strong autocorrelation independency errors assumption violated (see example ). Additionally, model strong autocorrelation residuals suggests lacks spatial component within predictors. computationally difficult calculate spatial autocorrelation entire dataset , subsample 20% datapoints calculations. Results may thus vary degree.shows ’s spatial autocorrelation residuals remaining. use plot residuals assess occurs indicates model missing important spatial effect, another explanation.Unfortunately, due way leaflet stores maps produces, plot using K-M knitting generate document. Run chunks interactively work fine. , ’ll resort static representation model residuals.","code":"\ndf <- data_cleaned\ndf$residual <- resid(model)\n\ndf %>%\n  filter(dist_radar < 66000) %>%\n  slice_sample(prop = 0.20) -> df_sample\n\ncorrelogram <- correlog(df_sample[, c(\"x\", \"y\")], df_sample[, \"residual\"], method = \"Moran\", nbclass = NULL)\nsaveRDS(correlogram , file = \"data/models/correlogram.RDS\")\ncorrelogram <- readRDS(\"data/models/correlogram.RDS\")\nplot(correlogram)\ndf <- data_cleaned\ndf$residual <- resid(model)\ndf$preds <- predict.mboost(model, newdata = data_cleaned)\nppi <- readRDS(\"data/processed/composite-ppis/500m/201712312305.RDS\")\n \nppi$data@data %>%\n  left_join(dplyr::select(df, pixel, preds, residual), by = \"pixel\") -> ppi$data@data\nppi$data@data$VIR_log <- log10(ppi$data@data$VIR)\nppi$data@data$total_biomass_log <- log10(ppi$data@data$total_biomass / 1000)\n\npal_resid <- colorspace::diverging_hcl(50, \"Blue-Red 3\", power = 2)\nz_lims_resid <- c(-3, 3)\npalette_resid <- colorNumeric(pal_resid, na.color = \"#00000005\", domain = z_lims_resid)\nraster_resid <- as(ppi$data[\"residual\"], \"RasterLayer\")\nraster_resid[raster_resid <= z_lims_resid[1]] <- z_lims_resid[1]\nraster_resid[raster_resid >= z_lims_resid[2]] <- z_lims_resid[2]\nleaflet() %>%\n  addTiles(group = \"OSM (default)\") %>%\n  addRasterImage(raster_resid, colors = palette_resid, layerId = \"resid\", group = \"resid\") %>%\n  addImageQuery(raster_resid, layerId = \"resid\") %>%\n  addLegend(pal = palette_resid, values = z_lims_resid) %>%\n  addOpacitySlider(layerId = \"resid\") %>%\n  identity()\nas.data.frame(raster_resid, xy = TRUE) %>%\n  drop_na() %>%\n  ggplot() +\n  geom_raster(aes(x = x, y = y, fill = residual)) +\n  scale_fill_distiller(type = \"div\", palette = \"RdBu\") +\n  theme_dark()"},{"path":"modelling-fireworks-disturbance.html","id":"correct-for-residual-spatial-autocorrelation","chapter":"8 Modelling fireworks disturbance","heading":"8.10.1 Correct for residual spatial autocorrelation","text":"correlogram spatial plots residuals show clearly residuals spatially autocorrelated. correct effect using Crase et al. (2012), calculating autocovariate (distance weighted mean) residuals using 1500m neighborhood radius. look correlogram , can see spatial autocorrelation still visible distances 30-50km, calculating autocovariate neighborhoods computationally intensive. points won’t neighborhoods , fine.calculated autocovariate included dataset, can retrain model, time inclusion autocov parameter.Let’s plot model variable importance modelled effects newly trained model.recalculate Moran’s new model residuals.looks much better! Residual spatial autocorrelation still present significant (red circles plot ), now decreased ~0.3 ~0.02. now pretty much negligible.completeness, let’s make residuals spatially explicit againAnd finally can recalculate model performance compare original model.","code":"\nnbs <- 1500  # Kilometers if longlat = TRUE\nacov <- autocov_dist(resid(model), as.matrix(cbind(data_cleaned$x, data_cleaned$y)), nbs = nbs, zero.policy = TRUE)## Warning in autocov_dist(resid(model), as.matrix(cbind(data_cleaned$x,\n## data_cleaned$y)), : With value 1500 some points have no neighbours## Warning in nb2listw(nb, glist = gl, style = style, zero.policy = zero.policy):\n## zero sum general weights\ndata_cleaned$acov <- acov\nformula <- VIR ~ bbs(dist_radar) + bbs(total_rcs) + bbs(semiopen) + bbs(forests) + bbs(wetlands) + bbs(waterbodies) +\n  bbs(agricultural) + bbs(dist_urban) + bbs(acov)\nmodel_rac <- mboost(formula, data = data_cleaned, control = boost_control(mstop = 10000, trace = TRUE))\nsaveRDS(model_rac, file = \"data/models/model_rac.RDS\")\nmodel_rac <- readRDS(\"data/models/model_rac.RDS\")\nplot(varimp(model_rac))\npar(mfrow = c(3, 4))\nplot(model_rac)\ndf <- data_cleaned\ndf$residual <- resid(model_rac)\n\ndf %>%\n  filter(dist_radar < 66000) %>%\n  slice_sample(prop = 0.2) -> df_sample\n\ncorrelogram <- correlog(df_sample[, c(\"x\", \"y\")], df_sample[, \"residual\"], method = \"Moran\", nbclass = NULL)\nsaveRDS(correlogram , file = \"data/models/correlogram_rac.RDS\")\ncorrelogram <- readRDS(\"data/models/correlogram_rac.RDS\")\nplot(correlogram)\ndf <- data_cleaned\ndf$residual <- resid(model_rac)\ndf$preds <- predict.mboost(model_rac, newdata = data_cleaned)\nppi <- readRDS(\"data/processed/composite-ppis/500m/201712312305.RDS\")\n \nppi$data@data %>%\n  left_join(dplyr::select(df, pixel, preds, residual), by = \"pixel\") -> ppi$data@data\nppi$data@data$VIR_log <- log10(ppi$data@data$VIR)\nppi$data@data$total_biomass_log <- log10(ppi$data@data$total_biomass / 1000)\n\npal_resid <- colorspace::diverging_hcl(50, \"Blue-Red 3\", power = 2)\nz_lims_resid <- c(-3, 3)\npalette_resid <- colorNumeric(pal_resid, na.color = \"#00000005\", domain = z_lims_resid)\nraster_resid <- as(ppi$data[\"residual\"], \"RasterLayer\")\nraster_resid[raster_resid <= z_lims_resid[1]] <- z_lims_resid[1]\nraster_resid[raster_resid >= z_lims_resid[2]] <- z_lims_resid[2]\nleaflet() %>%\n  addTiles(group = \"OSM (default)\") %>%\n  addRasterImage(raster_resid, colors = palette_resid, layerId = \"resid\", group = \"resid\") %>%\n  addImageQuery(raster_resid, layerId = \"resid\") %>%\n  addLegend(pal = palette_resid, values = z_lims_resid) %>%\n  addOpacitySlider(layerId = \"resid\") %>%\n  identity()\nas.data.frame(raster_resid, xy = TRUE) %>%\n  drop_na() %>%\n  ggplot() +\n  geom_raster(aes(x = x, y = y, fill = residual)) +\n  scale_fill_distiller(type = \"div\", palette = \"RdBu\") +\n  theme_dark()\nRMSE <- function(error) { sqrt(mean(error^2)) }\nrmse <- RMSE(residuals(model_rac))\nde <- deviance_explained(data_cleaned$VIR, predict(model_rac))\nperf_rac <- as.data.frame(list(\"RMSE\" = as.matrix(rmse), \"Dev.Exp\" = as.matrix(de)))\n\nperf <- bind_rows(perf_original[\"dist_urban\", ], perf_rac)\nrownames(perf) <- c(\"dist_urban_original\", \"dist_urban_rac\")\nperf"},{"path":"quantifying-model-uncertainty.html","id":"quantifying-model-uncertainty","chapter":"9 Quantifying model uncertainty","heading":"9 Quantifying model uncertainty","text":"use boostrapping approach quantify model uncertainty. Luckily, mboost already contains functions .\npartial dependence plots generated previous chapter visualise marginal effect certain predictors outcome log(VIR). use bootstrapping approach quantify model uncertainty.","code":""},{"path":"quantifying-model-uncertainty.html","id":"processing-environment-8","chapter":"9 Quantifying model uncertainty","heading":"9.1 Processing environment","text":"","code":"\nlibrary(parallel)\nlibrary(tibble)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(patchwork)"},{"path":"quantifying-model-uncertainty.html","id":"bootstrapped-uncertainty-analysis","chapter":"9 Quantifying model uncertainty","heading":"9.2 Bootstrapped uncertainty analysis","text":"Using bootstrapping procedure provided mboost, tweaked use case, can derive uncertainty estimates trained model.make changes default functioning confint.mboost function.let bootstrap folds determined outside function call, can stored separately processing can parallellised easily.include variable importance variable bootstrapped, uncertainty estimates around value can quantified .calculate model predictions finer grid along variables interest (1000 values instead 100).","code":""},{"path":"quantifying-model-uncertainty.html","id":"determine-bootstrap-folds","chapter":"9 Quantifying model uncertainty","heading":"9.2.1 Determine bootstrap folds","text":"folds contain indexes datapoints resampled 1000 bootstrap iterations.","code":"\nmodel <- readRDS(\"data/models/model_rac.RDS\")\nfolds <- mboost::cv(model.weights(model), B = 1000)\nsaveRDS(folds, file = \"data/models/confints/folds.RDS\")"},{"path":"quantifying-model-uncertainty.html","id":"running-the-bootstrapping-procedure","chapter":"9 Quantifying model uncertainty","heading":"9.2.2 Running the bootstrapping procedure","text":"computationally intensive execute bootstrapping procedure, hence best executed manually tweaking settings local machine (memory, CPU cores, etc). See R/mboost_uncertainty_analysis.R file example . case 2-3 RStudio jobs running script batch folds, can combined later results stored data/models/confints/. Execution took 3 days.","code":"\nsource(\"R/mboost_uncertainty_analysis.R\")"},{"path":"quantifying-model-uncertainty.html","id":"recombine-bootstrapped-results","chapter":"9 Quantifying model uncertainty","heading":"9.3 Recombine bootstrapped results","text":"adjusted bootstrapping procedure bit, now recombine data R object matches format mboost functions expect. Additionally, include variable importance now well.Let’s confirm worked plotting bootstrapped confidence intervals.Voilà, seems done trick.","code":"\nn_confint_files <- length(Sys.glob(\"data/models/confints/modelci*\"))\nconfint_files <- paste0(\"data/models/confints/modelci_\", 2:n_confint_files, \".RDS\")\ncis <- lapply(confint_files, readRDS)\nci_boot_pred <- lapply(cis, function(x) x$boot_pred)\nci_varimp <- lapply(cis, function(x) x$varimp)\n\nmodelci <- readRDS(\"data/models/confints/modelci_1.RDS\")\nmodelci$boot_pred[2:n_confint_files-1] <- ci_boot_pred\nmodelci$boot_pred[1] <- NULL\nmodelci$data <- cis[[1]]$data\nmodelci$varimp <- ci_varimp\n\nsaveRDS(modelci, file = \"data/models/confints/final_modelci.RDS\")\nvars <- c(\"dist_radar\", \"total_rcs\", \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\", \"agricultural\", \"dist_urban\", \"acov\")\npar(mfrow = c(3, 4))\nlapply(vars, function(x) plot(modelci, which = x, raw = TRUE))## [[1]]\n## NULL\n## \n## [[2]]\n## NULL\n## \n## [[3]]\n## NULL\n## \n## [[4]]\n## NULL\n## \n## [[5]]\n## NULL\n## \n## [[6]]\n## NULL\n## \n## [[7]]\n## NULL\n## \n## [[8]]\n## NULL\n## \n## [[9]]\n## NULL"},{"path":"determine-baseline-disturbance.html","id":"determine-baseline-disturbance","chapter":"10 Determine baseline disturbance","heading":"10 Determine baseline disturbance","text":"compare disturbance caused fireworks flight activity normal nights, select (mostly) rain-free nights baseline dataset.previously calculated classes targets using depolarization ratio (Kilambi, Fabry, Meunier 2018) can now visualise .visual inspection ’ve determined following PPIs sufficient serve disturbance baseline. may still contain forms non-meteorological clutter, problem long clutter intersect count sites.Process baseline PPIs way disturbed PPIs processed.","code":"\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(tidyr)\nlibrary(bioRad)\nfiles <- Sys.glob(file.path(\"data/processed/composite-ppis-baseline/500m\", \"*\"))\nlapply(files, function(x) {\n  ppi <- readRDS(x)\n  plot(ppi, param = \"class\", zlim = c(0, 2)) + ggtitle(basename(x))\n})## [[1]]## \n## [[2]]## \n## [[3]]## \n## [[4]]## \n## [[5]]## \n## [[6]]## \n## [[7]]## \n## [[8]]## \n## [[9]]## \n## [[10]]\nfiles_selected <- files[c(2, 4, 6, 7, 8)]\ndata_disturbance <- readRDS(\"data/models/data_cleaned.RDS\")\n\ndata_baseline <- lapply(files_selected, function(x) {\n  df <- readRDS(x)[[\"data\"]]@data\n  df[\"dt\"] <- basename(tools::file_path_sans_ext(x))\n  df\n})\n\nclean_data_baseline <- function(data, max_distance, pixels) {\n  mdl_variables <- c(\"VIR\", \"dist_radar\", \"total_biomass\", \"total_crs\",\n                     \"agricultural\", \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\", \"urban\",\n                     \"dist_urban\", \"human_pop\", \"pixel\", \"coverage\", \"class\", \"x\", \"y\", \"dt\", \"VIDc\")\n  log10_variables <- c(\"dist_urban\", \"human_pop\", \"total_biomass\", \"dist_urban\")\n  \n  data %>%\n    dplyr::filter(pixel %in% pixels) %>%\n    mutate(VIR = replace_na(VIR, 0.1),\n           VIR = if_else(VIR == 0, 0.1, VIR),\n           VIR = log10(VIR),\n           VIDc = (10^VIR) / weighted_mean_crs,\n           VIDc = if_else(VIDc > 10000000, 1e-6, VIDc, 1e-6),\n           dt = as.factor(dt)) %>%\n    dplyr::select(all_of(mdl_variables)) %>%\n    filter_all(all_vars(is.finite(.))) %>%\n    rename(total_rcs = total_crs) %>%\n    identity() -> data_cleaned\n  \n  data_cleaned\n}\n\nbaseline_ppis <- lapply(data_baseline, function(x) clean_data_baseline(x, 66000, data_disturbance$pixel))\nsaveRDS(baseline_ppis, \"data/processed/baseline_ppis.RDS\")\nbaseline_response_VIR <- unlist(lapply(baseline_ppis, function(x) mean(x$VIR)))\nbaseline_response_VIDc <- unlist(lapply(baseline_ppis, function(x) mean(x$VIDc)))\nbr <- c(\"VIR\" = mean(baseline_response_VIR), \"VIDc\" = mean(baseline_response_VIDc))\nsaveRDS(br, file = \"data/processed/disturbance_baseline.RDS\")\nbr##        VIR       VIDc \n## -0.3654903  2.7240716"},{"path":"figure-1-data-overview.html","id":"figure-1-data-overview","chapter":"11 Figure 1: Data overview","heading":"11 Figure 1: Data overview","text":"Figure 1 paper made using QGIS Adobe Illustrator, export VIR total_biomass estimates. Furthermore, use land use map stored data/processed/landuse/landuse_hrw_reclassified.tif, doesn’t need exporting anymore.","code":""},{"path":"figure-1-data-overview.html","id":"processing-environment-9","chapter":"11 Figure 1: Data overview","heading":"11.1 Processing environment","text":"","code":"\nlibrary(bioRad)\nlibrary(raster)\nlibrary(magrittr)\nsource(\"R/comp_ppi.R\")"},{"path":"figure-1-data-overview.html","id":"workflow","chapter":"11 Figure 1: Data overview","heading":"11.2 Workflow","text":"load radar PPIs.Composite PPIs log-transform VIR total_biomass improved visualisation.Make plots confirm composite transformation works intended.now write raster files containing parameters, can stitch together QGIS Adobe Illustrator.visualize disturbance event movie, let’s generate raster files timestamps can animate AI/AE.","code":"\nhrw <- readRDS(\"data/processed/final-ppis/RAD_NL62_VOL_NA_201712312305_ODIM.RDS\")\ndhl <- readRDS(\"data/processed/final-ppis/RAD_NL61_VOL_NA_201712312305_ODIM.RDS\")\ncppi <- comp_ppi(list(hrw, dhl), param = c(\"VIR\", \"total_crs\", \"dist_urban\"), res = 500, \n                 method = c(\"mean\", \"mean\", \"min\"))\ncppi$data$VIR <- log10(cppi$data$VIR)\ncppi$data$VIR[is.infinite(cppi$data$VIR)] <- 0\ncppi$data$VIR[cppi$data$VIR == 0] <- NA\ncppi$data$total_crs[cppi$data$total_crs == 0] <- NA\ncppi$data$total_crs <- log10(cppi$data$total_crs)\nplot(cppi, param = \"VIR\", zlim = c(0, 10))\nplot(cppi, param = \"total_crs\", zlim = c(0, 6))\nplot(cppi, param = \"dist_urban\", zlim = c(0, 10000))\nraster::writeRaster(as(cppi$data[\"VIR\"], \"RasterLayer\"), filename = \"data/plots/paper/fig1_VIR.tif\", overwrite = TRUE)\nraster::writeRaster(as(cppi$data[\"total_crs\"], \"RasterLayer\"), filename = \"data/plots/paper/fig1_total_crs.tif\", overwrite = TRUE)\nraster::writeRaster(as(cppi$data[\"dist_urban\"], \"RasterLayer\"), filename = \"data/plots/paper/fig1_dist_urban.tif\", overwrite = TRUE)\nhrw_ppis <- Sys.glob(file.path(\"data/processed/final-ppis\", \"*NL62*\"))\ndhl_ppis <- Sys.glob(file.path(\"data/processed/final-ppis\", \"*NL61*\"))\n\ncreate_raster <- function(hrw_fp, dhl_fp) {\n  hrw <- readRDS(hrw_fp)\n  dhl <- readRDS(dhl_fp)\n  cppi <- comp_ppi(list(hrw, dhl), param = c(\"VIR\"), res = 500, \n                 method = c(\"mean\"))\n  \n  cppi$data$VIR <- log10(cppi$data$VIR)\n  cppi$data$VIR[is.infinite(cppi$data$VIR)] <- 0\n  cppi$data$VIR[cppi$data$VIR == 0] <- NA\n  \n  filename <- paste(\"data/plots/vir-ppis-raster/\", strftime(hrw$datetime, format = \"%Y%m%d%H%M\"), \".tif\", sep = \"\")\n  \n  raster::writeRaster(as(cppi$data[\"VIR\"], \"RasterLayer\"), filename = filename, overwrite = TRUE)\n}\n\nmapply(create_raster, hrw_ppis, dhl_ppis)"},{"path":"figure-2-model-output.html","id":"figure-2-model-output","chapter":"12 Figure 2: Model output","heading":"12 Figure 2: Model output","text":"now quantified uncertainty model using bootstrapping can finally visualise outcome.","code":""},{"path":"figure-2-model-output.html","id":"processing-environment-10","chapter":"12 Figure 2: Model output","heading":"12.1 Processing environment","text":"tweaked mboost default functionality, case facilitate plotting using ggplot2.","code":"\nlibrary(ggplot2)\nlibrary(mboost)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(magrittr)\nlibrary(patchwork)\nlibrary(ggdist)\nlibrary(MASS)\nmodelci <- readRDS(\"data/models/confints/final_modelci.RDS\")\ndata_cleaned <- readRDS(\"data/models/data_cleaned.RDS\")\nbaseline <- readRDS(\"data/processed/disturbance_baseline.RDS\")\nsource(\"R/mboost_bootstrapped_quantiles.R\")\nsource(\"R/plot.mboost_adjusted.R\")"},{"path":"figure-2-model-output.html","id":"variable-importance-1","chapter":"12 Figure 2: Model output","heading":"12.2 Variable importance","text":"start calculating summary statistics bootstrapped variable importance, ’ll organise final figure according descending variable importance.can plot distribution variable importance measures predictors, model containing predictors one containing just biologically-relevant predictors. latter rescaled variable importance back 100% removal dist_radar.can now also calculate mean variable importance predictors determine rank final figure.","code":"\nbootstrapped_varimp <- function(modelci, exclude = c(\"dist_radar\", \"acov\"), round = 0) {\n  ind_vis <- lapply(modelci$varimp, function(x) {\n    x %>%\n      filter(!variable %in% exclude) %>%\n      mutate(vi = reduction / sum(reduction) * 100)\n  })\n  vis_out <- ind_vis[[1]] %>%\n    dplyr::select(variable, vi) %>%\n    mutate(variable = as.character(variable))\n  \n  agg_vis <- lapply(ind_vis[2:length(ind_vis)], function(x) {\n    x %>%\n      dplyr::select(vi)\n  })\n  \n  vis_out[2:length(ind_vis)] <- bind_cols(agg_vis)\n  vis_out\n}\n\nbvi_biol <- bootstrapped_varimp(modelci)\nbvi_all <- bootstrapped_varimp(modelci, exclude = NULL)\nbvi_biol %>%\n  pivot_longer(!variable, names_to = \"bootstrap\", values_to = \"vi\") %>%\n  ggplot(aes(x = vi, y = variable)) +\n  stat_eye() +\n  labs(x = \"Variable importance (%)\", y = \"Predictor\", title = \"Biologically-relevant predictors\")\nbvi_all %>%\n  pivot_longer(!variable, names_to = \"bootstrap\", values_to = \"vi\") %>%\n  ggplot(aes(x = vi, y = variable)) +\n  stat_eye() +\n  labs(x = \"Variable importance (%)\", y = \"Predictor\", title = \"All model predictors\")\nbvi_biol %>%\n  pivot_longer(!variable, names_to = \"bootstrap\", values_to = \"vi\") %>%\n  group_by(variable) %>%\n  summarise(mean_vi = mean(vi), q025 = quantile(vi, probs = 0.025), q975 = quantile(vi, probs = 0.975), .groups = \"drop_last\") %>%\n  mutate(mean_round = round(mean_vi, 0)) %>%\n  arrange(desc(mean_vi)) -> bvi_biol\n\nbvi_all %>%\n  pivot_longer(!variable, names_to = \"bootstrap\", values_to = \"vi\") %>%\n  group_by(variable) %>%\n  summarise(mean_vi = mean(vi), q025 = quantile(vi, probs = 0.025), q975 = quantile(vi, probs = 0.975), .groups = \"drop_last\") %>%\n  mutate(mean_round = round(mean_vi, 0)) %>%\n  arrange(desc(mean_vi)) -> bvi_all\n\nbvi_biol\nbvi_all"},{"path":"figure-2-model-output.html","id":"compare-groups","chapter":"12 Figure 2: Model output","heading":"12.3 Compare groups","text":"’s quite overlap confidence intervals, let’s see variables actually different variable importance.Indeed, mean variable importance dist_urban significantly different total_rcs applies waterbodies wetlands.","code":"\nbvi_all %>%\n  pivot_longer(!variable, names_to = \"bootstrap\", values_to = \"vi\") -> all\n\nsummary(aov(vi ~ variable, data = all))\npttest <- pairwise.t.test(all$vi, all$variable)\nwrite.matrix(pttest$p.value, file = \"data/models/varimp.pttest.csv\", sep = \",\")\npttest##             Df Sum Sq Mean Sq F value Pr(>F)    \n## variable     8  11300  1412.5    2164 <2e-16 ***\n## Residuals   27     18     0.7                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##  Pairwise comparisons using t tests with pooled SD \n## \n## data:  all$vi and all$variable \n## \n##              acov    agricultural dist_radar dist_urban forests semiopen\n## agricultural < 2e-16 -            -          -          -       -       \n## dist_radar   < 2e-16 1.4e-15      -          -          -       -       \n## dist_urban   < 2e-16 1.1e-13      < 2e-16    -          -       -       \n## forests      < 2e-16 1.3e-15      < 2e-16    0.03822    -       -       \n## semiopen     < 2e-16 1.5e-15      < 2e-16    0.06126    1.00000 -       \n## total_rcs    < 2e-16 6.1e-14      < 2e-16    1.00000    0.08410 0.12804 \n## waterbodies  < 2e-16 < 2e-16      < 2e-16    0.00041    0.38295 0.33673 \n## wetlands     < 2e-16 < 2e-16      < 2e-16    0.00049    0.38295 0.35385 \n##              total_rcs waterbodies\n## agricultural -         -          \n## dist_radar   -         -          \n## dist_urban   -         -          \n## forests      -         -          \n## semiopen     -         -          \n## total_rcs    -         -          \n## waterbodies  0.00104   -          \n## wetlands     0.00125   1.00000    \n## \n## P value adjustment method: holm"},{"path":"figure-2-model-output.html","id":"visualise-marginal-effects","chapter":"12 Figure 2: Model output","heading":"12.4 Visualise marginal effects","text":"Now calculated marginal effects ordered, can generate final plots.","code":""},{"path":"figure-2-model-output.html","id":"biologically-relevant-marginal-effects","chapter":"12 Figure 2: Model output","heading":"12.4.1 Biologically-relevant marginal effects","text":"save PDF can tweak plot manually Adobe Illustrator.","code":"\nconfidence.intervals <- c(0.95, 0.8, 0.5)\ncolors <- c(\"urban\" = \"#94346E\", \n            \"agricultural\" = \"#73AF48\", \n            \"semiopen\" = \"#EDAD08\", \n            \"forests\" = \"#0F8554\", \n            \"wetlands\" = \"#38A6A5\", \n            \"waterbodies\" = \"#1D6996\",\n            \"dist_urban\" = \"#94346E\", \n            \"total_rcs\" = \"#CC503E\", \n            \"dist_radar\" = \"#666666\")\nx_labels <- c(\"urban\" = \"Urban\", \n              \"agricultural\" = \"Agricultural\", \n              \"semiopen\" = \"Semi-open\", \n              \"forests\" = \"Forests\", \n              \"wetlands\" = \"Wetlands\", \n              \"waterbodies\" = \"Water bodies\", \n              \"dist_urban\" = \"Distance to fireworks (m)\", \n              \"total_rcs\" = \"Total RCS (g^(2/3))\", \n              \"dist_radar\" = \"Distance from radar (m)\")\nlimit_quantiles <- c(\"dist_urban\", \"total_rcs\")\nmanual_limits <- list(\"dist_urban\" = c(min(data_cleaned$dist_urban), max(data_cleaned$dist_urban)),\n                      \"total_rcs\" = c(0, quantile(data_cleaned$total_rcs, probs = 0.975)))\n# ylims <- c(-1.8, 1.5) + modelci$model$offset\nylims <- c(-1, 1)\n\nplot_mboost_pdp <- function(modelci, data, which, confints, colors = NULL, ylims = ylims, varimp = NULL, offset = FALSE) {\n  # Extract bootstrapped quantiles\n  quants <- t(mboost_bootstrapped_quantiles(modelci, confidence.intervals, which = which))\n  if (offset) quants <- quants + modelci$model$offset\n  bootstrapped_quantiles <- as.data.frame(quants)\n  # bootstrapped_quantiles <- as.data.frame(t(mboost_bootstrapped_quantiles(modelci, confidence.intervals, which = which)))\n  bootstrapped_quantiles$x <- modelci$data[modelci$model$which(which)][[1]][, 1]\n  bootstrapped_quantiles$y <- plot.mboost_adjusted(modelci$model, which = which, newdata = modelci$data[[modelci$model$which(which)]])[[2]]\n  if (offset) {\n    bootstrapped_quantiles$y <- bootstrapped_quantiles$y + modelci$model$offset\n    ylims <- ylims + modelci$model$offset\n  }\n  \n  p <- ggplot(bootstrapped_quantiles)\n  i <- 1\n  sorted_confints <- sort(confints, decreasing = TRUE)\n  \n  # Add variable importance\n  if (is.null(varimp)) {\n    variable_importance <- function(model, which, exclude = c(\"dist_radar\"), round = 0) {\n      vi <- as.data.frame(varimp(model)) %>%\n        filter(!variable %in% exclude)\n      vi$vi <- vi$reduction / sum(vi$reduction) * 100\n      vi %>%\n        filter(variable == which) %>%\n        dplyr::select(vi) %>%\n        as.numeric() %>%\n        round(round)\n    }\n    vi <- variable_importance(modelci$model, which)\n  } else {\n    vi <- varimp %>%\n      filter(variable == which) %>%\n      dplyr::select(mean_round)\n  }\n  \n  offset_right <- 0.95\n  offset_top <- 0.35\n  if (which == \"dist_urban\") {\n    p <- p +\n      annotate(\"text\", x = manual_limits$dist_urban[[2]] * offset_right, y = ylims[2] - offset_top, label = paste0(vi, \"%\"), hjust = 1, color = colors[which],\n               fontface = \"bold\", size = 12, alpha = 0.5)\n  } else if(which == \"total_rcs\") {\n    p <- p +\n      annotate(\"text\", x = manual_limits$total_rcs[[2]] * offset_right, y = ylims[2] - offset_top, label = paste0(vi, \"%\"), hjust = 1, color = colors[which],\n               fontface = \"bold\", size = 12, alpha = 0.5)\n  } else {\n    p <- p +\n      annotate(\"text\", x = 1 * offset_right, y = ylims[2] - offset_top, label = paste0(vi, \"%\"), hjust = 1, color = colors[which], \n               fontface = \"bold\", size = 12, alpha = 0.5)\n  }\n  \n  # Add density\n  if (which == \"dist_urban\") {\n    dens <- density(data[, which], bw = 225, from = manual_limits$dist_urban[[1]], to = manual_limits$dist_urban[[2]])\n  } else if (which == \"total_rcs\") {\n    dens <- density(data[, which], bw = 2000, from = manual_limits$total_rcs[[1]], to = manual_limits$total_rcs[[2]])\n  } else {\n    dens <- density(data[, which], bw = 0.03556, from = 0, to = 1)\n  }\n  scale_lims <- c(ylims[1] + 0.05, ylims[2] - 0.05)\n  dens$y <- scales::rescale(dens$y, to = scale_lims)\n  dens <- as.data.frame(list(as.matrix(dens$x), as.matrix(dens$y)))\n  colnames(dens) <- c(\"x\", \"y\")\n  p <- p +\n    geom_line(aes(x = x, y = y), data =  dens, color = \"grey50\", lineend = \"round\", linetype = 3) +\n    scale_y_continuous(sec.axis = sec_axis(~ ., name = \"Predictor frequency\", breaks = scale_lims, labels = c(\"min\", \"max\")))\n  \n  ## Add horizontal line\n  if (offset) {\n    yintercept <- modelci$model$offset\n  } else {\n    yintercept <- 0\n  }\n  p <- p +\n    geom_hline(yintercept = yintercept, col = \"darkgrey\")\n  \n  for (ci in sorted_confints) {\n    alphas <- rev(factor(sorted_confints))\n    ymax <- as.name(paste((1 - (1 - ci) / 2) * 100, \"%\", sep = \"\"))\n    ymax <- enquo(ymax)\n    ymin <- as.name(paste(((1 - ci) / 2) * 100, \"%\", sep = \"\"))\n    ymin <- enquo(ymin)\n    \n    p <- p +\n      geom_ribbon(aes(x = x, ymin = !!ymin, ymax = !!ymax, alpha = !!alphas[i]), fill = colors[which]) +\n      geom_line(aes(x = x, y = y), color = colors[which], size = 0.75, lineend = \"round\")\n    \n    if (offset) {\n      p <- p + scale_y_continuous(labels = function(x) {10^x})\n    }\n\n    i <- i + 1\n  }\n  \n  p <- p +\n    scale_alpha_discrete(range = c(0.2, 0.5)) +\n    coord_cartesian(ylim = ylims, expand = FALSE) +\n    guides(alpha = FALSE)\n  \n  if (which == \"dist_urban\") {\n    xlabel <- x_labels[which]\n    p <- p +\n      coord_cartesian(xlim = manual_limits$dist_urban, ylim = ylims, expand = FALSE)\n      # scale_x_continuous(breaks = c(0, 10000, 20000, 30000), labels = c(0, 10, 20, 30))\n  } else if (which == \"total_rcs\") {\n    xlabel <- x_labels[which]\n    p <- p +\n      coord_cartesian(xlim = manual_limits$total_rcs, ylim = ylims, expand = FALSE)\n      # scale_x_continuous(breaks = c(250, 500, 750), labels = c(250*4, 500*4, 750*4))\n  } else {\n    xlabel <- paste(\"%\", x_labels[which])\n    p <- p + \n      scale_x_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1), labels = c(\"0%\", \"25%\", \"50%\", \"75%\", \"100%\"))\n  }\n  \n  p <- p +\n    theme_classic(base_size = 10) +\n    labs(x = xlabel, y = expression(paste(\"Flight response \", log[10], \"(VIR)\"))) +\n    theme(axis.line.y.left = element_line(color = colors[which], size = 0.5),\n          axis.line.y.right = element_line(color = \"grey\"),\n          axis.ticks.y.left = element_line(color = colors[which], size = 0.5),\n          axis.ticks.y.right = element_line(color = \"grey\"),\n          axis.title.y = element_text())\n  \n  if (which(varimp$variable == which) %% 2 == 0) {\n    p <- p +\n      theme(axis.title.y.left = element_blank())\n  } else {\n    p <- p +\n      theme(axis.title.y.right = element_blank())\n  }\n\n  if (!which %in% limit_quantiles) {\n    p <- p +\n      theme(axis.title.x = element_text(vjust = 0.5))\n  }\n\n  p\n}\n\npredictors <- bvi_biol$variable\nplots <- mapply(function(predictors) {plot_mboost_pdp(modelci, data_cleaned, which = predictors, confidence.intervals, colors, ylims, bvi_biol, \n                                                      offset = FALSE)}, \n                predictors = predictors,\n                SIMPLIFY = FALSE)\n\np <- wrap_plots(plots, ncol = 2)\n\np\nggsave(filename = \"data/plots/paper/fig2_biol.pdf\", plot = p, width = 16, height = 20, dpi = 300, units = \"cm\")"},{"path":"figure-2-model-output.html","id":"all-marginal-effects","chapter":"12 Figure 2: Model output","heading":"12.5 All marginal effects","text":"save plot PDF.","code":"\nconfidence.intervals <- c(0.95, 0.8, 0.5)\ncolors <- c(\"urban\" = \"#94346E\", \n            \"agricultural\" = \"#73AF48\", \n            \"semiopen\" = \"#EDAD08\", \n            \"forests\" = \"#0F8554\", \n            \"wetlands\" = \"#38A6A5\", \n            \"waterbodies\" = \"#1D6996\",\n            \"dist_urban\" = \"#94346E\", \n            \"total_rcs\" = \"#CC503E\", \n            \"dist_radar\" = \"#666666\",\n            \"acov\" = \"#666666\")\nx_labels <- c(\"urban\" = \"Urban\", \n              \"agricultural\" = \"Agricultural\", \n              \"semiopen\" = \"Semi-open\", \n              \"forests\" = \"Forests\", \n              \"wetlands\" = \"Wetlands\", \n              \"waterbodies\" = \"Water bodies\", \n              \"dist_urban\" = \"Distance to fireworks [m]\", \n              \"total_rcs\" = \"Total RCS [cm^2]\", \n              \"dist_radar\" = \"Distance from radar [m]\",\n              \"acov\" = \"Residual autocovariate [cm^2]\")\nlimit_quantiles <- c(\"dist_urban\", \"total_rcs\")\nmanual_limits <- list(\"dist_urban\" = c(min(data_cleaned$dist_urban), max(data_cleaned$dist_urban)),\n                      \"total_rcs\" = c(0, max(data_cleaned$total_rcs)),\n                      \"dist_radar\" = c(0, 66000))\n# ylims <- c(-1.8, 1.5) + modelci$model$offset\nylims <- c(-1, 1)\n\nplot_mboost_pdp <- function(modelci, data, which, confints, colors = NULL, ylims = ylims, varimp = NULL, offset = FALSE) {\n  # Extract bootstrapped quantiles\n  quants <- t(mboost_bootstrapped_quantiles(modelci, confidence.intervals, which = which))\n  if (offset) quants <- quants + modelci$model$offset\n  bootstrapped_quantiles <- as.data.frame(quants)\n  # bootstrapped_quantiles <- as.data.frame(t(mboost_bootstrapped_quantiles(modelci, confidence.intervals, which = which)))\n  bootstrapped_quantiles$x <- modelci$data[modelci$model$which(which)][[1]][, 1]\n  bootstrapped_quantiles$y <- plot.mboost_adjusted(modelci$model, which = which, newdata = modelci$data[[modelci$model$which(which)]])[[2]]\n  if (offset) {\n    bootstrapped_quantiles$y <- bootstrapped_quantiles$y + modelci$model$offset\n    ylims <- ylims + modelci$model$offset\n  }\n  \n  p <- ggplot(bootstrapped_quantiles)\n  i <- 1\n  sorted_confints <- sort(confints, decreasing = TRUE)\n  \n  # Add variable importance\n  if (is.null(varimp)) {\n    variable_importance <- function(model, which, exclude = c(\"dist_radar\"), round = 0) {\n      vi <- as.data.frame(varimp(model)) %>%\n        filter(!variable %in% exclude)\n      vi$vi <- vi$reduction / sum(vi$reduction) * 100\n      vi %>%\n        filter(variable == which) %>%\n        dplyr::select(vi) %>%\n        as.numeric() %>%\n        round(round)\n    }\n    vi <- variable_importance(modelci$model, which)\n  } else {\n    vi <- varimp %>%\n      filter(variable == which) %>%\n      dplyr::select(mean_round, q025, q975)\n  }\n  \n  offset_right <- 0.95\n  offset_top <- 0.35\n  vi_string <- paste0(vi$mean_round, \"% [\", round(vi$q025, digits = 2), \";\", round(vi$q975, digits = 2), \"]\")\n  fontsize <- 6\n  if (which == \"dist_urban\") {\n    p <- p +\n      annotate(\"text\", x = manual_limits$dist_urban[[2]] * offset_right, y = ylims[2] - offset_top, label = vi_string, hjust = 1, color = colors[which],\n               fontface = \"bold\", size = fontsize, alpha = 0.5)\n  } else if(which == \"total_rcs\") {\n    p <- p +\n      annotate(\"text\", x = manual_limits$total_rcs[[2]] * offset_right, y = 5 * (ylims[2] - offset_top), label = vi_string, hjust = 1, color = colors[which],\n               fontface = \"bold\", size = fontsize, alpha = 0.5)\n  } else if (which == \"acov\") {\n    d <- model.frame(modelci$model)\n    acov <- as.matrix(d[[\"bbs(acov)\"]])\n    p <- p +\n      annotate(\"text\", x = max(acov) * offset_right, y = 6.5 *(ylims[2] - offset_top), label = vi_string, hjust = 1, color = colors[which], fontface = \"bold\", \n               size = fontsize, alpha = 0.5)\n  } else if(which == \"dist_radar\") {\n    p <- p +\n      annotate(\"text\", x = manual_limits$dist_radar[[2]] * offset_right, y = 2 *(ylims[2] - offset_top), label = vi_string, hjust = 1, color = colors[which],\n               fontface = \"bold\", size = fontsize, alpha = 0.5)\n  } else {\n    p <- p +\n      annotate(\"text\", x = 1 * offset_right, y = ylims[2] - offset_top, label = vi_string, hjust = 1, color = colors[which], \n               fontface = \"bold\", size = fontsize, alpha = 0.5)\n  }\n  \n  # Add density\n  if (which == \"dist_urban\") {\n    dens <- density(data[, which], bw = 225, from = manual_limits$dist_urban[[1]], to = manual_limits$dist_urban[[2]])\n  } else if (which == \"total_rcs\") {\n    dens <- density(data[, which], bw = 2000, from = manual_limits$total_rcs[[1]], to = manual_limits$total_rcs[[2]])\n  } else if (which == \"acov\") {\n    d <- model.frame(modelci$model)\n    acov <- as.matrix(d[[\"bbs(acov)\"]])\n    dens <- density(acov, from = min(acov), to = max(acov))\n  } else if (which == \"dist_radar\") {\n    dens <- density(data[, which], from = manual_limits$dist_radar[[1]], to = manual_limits$dist_radar[[2]])\n  } else {\n    dens <- density(data[, which], bw = 0.03556, from = 0, to = 1)\n  }\n  \n  if (which == \"dist_urban\") { scale_lims <- c(-3 + 0.05, 1.5 - 0.05) }\n  else if (which == \"total_rcs\") { scale_lims <- c(-8 + 0.05, 5 - 0.05) }\n  else if (which == \"dist_radar\") { scale_lims <- c(-2 + 0.05, 2 - 0.05) }\n  else if (which == \"acov\") { scale_lims <- c(-4 + 0.05, 6 - 0.05)}\n  else {scale_lims <- c(ylims[1] + 0.05, ylims[2] - 0.05)}\n  \n  dens$y <- scales::rescale(dens$y, to = scale_lims)\n  dens <- as.data.frame(list(as.matrix(dens$x), as.matrix(dens$y)))\n  colnames(dens) <- c(\"x\", \"y\")\n  p <- p +\n    geom_line(aes(x = x, y = y), data =  dens, color = \"grey50\", lineend = \"round\", linetype = 3) +\n    scale_y_continuous(sec.axis = sec_axis(~ ., name = \"Predictor frequency\", breaks = scale_lims, labels = c(\"min\", \"max\")))\n  \n  ## Add horizontal line\n  if (offset) {\n    yintercept <- modelci$model$offset\n  } else {\n    yintercept <- 0\n  }\n  p <- p +\n    geom_hline(yintercept = yintercept, col = \"darkgrey\")\n  \n  for (ci in sorted_confints) {\n    alphas <- rev(factor(sorted_confints))\n    ymax <- as.name(paste((1 - (1 - ci) / 2) * 100, \"%\", sep = \"\"))\n    ymax <- enquo(ymax)\n    ymin <- as.name(paste(((1 - ci) / 2) * 100, \"%\", sep = \"\"))\n    ymin <- enquo(ymin)\n    \n    p <- p +\n      geom_ribbon(aes(x = x, ymin = !!ymin, ymax = !!ymax, alpha = !!alphas[i]), fill = colors[which]) +\n      geom_line(aes(x = x, y = y), color = colors[which], size = 0.75, lineend = \"round\")\n    \n    if (offset) {\n      p <- p + scale_y_continuous(labels = function(x) {10^x})\n    }\n\n    i <- i + 1\n  }\n  \n  p <- p +\n    scale_alpha_discrete(range = c(0.2, 0.5)) +\n    coord_cartesian(ylim = ylims, expand = FALSE) +\n    guides(alpha = FALSE)\n  \n  if (which == \"dist_urban\") {\n    xlabel <- x_labels[which]\n    p <- p +\n      coord_cartesian(xlim = manual_limits$dist_urban, ylim = c(-3, 1.5), expand = FALSE)\n      # scale_x_continuous(breaks = c(0, 10000, 20000, 30000), labels = c(0, 10, 20, 30))\n  } else if (which == \"total_rcs\") {\n    xlabel <- x_labels[which]\n    p <- p +\n      coord_cartesian(xlim = manual_limits$total_rcs, ylim = c(-8, 5), expand = FALSE)\n      # scale_x_continuous(breaks = c(250, 500, 750), labels = c(250*4, 500*4, 750*4))\n  } else if (which == \"dist_radar\") {\n    xlabel <- x_labels[which]\n    p <- p +\n      coord_cartesian(ylim = c(-2, 2), expand = FALSE)\n  } else if (which == \"acov\") {\n    xlabel <- x_labels[which]\n    p <- p +\n      coord_cartesian(ylim = c(-4, 6), expand = FALSE, xlim = c(min(acov), max(acov)))\n  } else {\n    xlabel <- paste(\"%\", x_labels[which])\n    p <- p + \n      scale_x_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1), labels = c(\"0%\", \"25%\", \"50%\", \"75%\", \"100%\"))\n  }\n  \n  p <- p +\n    theme_classic(base_size = 10) +\n    labs(x = xlabel, y = expression(paste(\"Flight response \", log[10], \"(VIR)\"))) +\n    theme(axis.line.y.left = element_line(color = colors[which], size = 0.5),\n          axis.line.y.right = element_line(color = \"grey\"),\n          axis.ticks.y.left = element_line(color = colors[which], size = 0.5),\n          axis.ticks.y.right = element_line(color = \"grey\"),\n          axis.title.y = element_text())\n  \n  if (which(varimp$variable == which) %% 2 == 0) {\n    p <- p +\n      theme(axis.title.y.left = element_blank())\n  } else {\n    p <- p +\n      theme(axis.title.y.right = element_blank())\n  }\n\n  if (!which %in% limit_quantiles) {\n    p <- p +\n      theme(axis.title.x = element_text(vjust = 0.5))\n  }\n\n  p\n}\n\npredictors <- bvi_all$variable\nplots <- mapply(function(predictors) {plot_mboost_pdp(modelci, data_cleaned, which = predictors, confidence.intervals, colors, ylims, bvi_all, \n                                                      offset = FALSE)}, \n                predictors = predictors,\n                SIMPLIFY = FALSE)\n\np <- wrap_plots(plots, ncol = 2)\n\np\nggsave(filename = \"data/plots/paper/fig2_all.pdf\", plot = p, width = 16, height = 20, dpi = 300, units = \"cm\")"},{"path":"figure-2-model-output.html","id":"landscapes-side-by-side","chapter":"12 Figure 2: Model output","heading":"12.6 Landscapes side-by-side","text":"","code":"\nconfidence.intervals <- c(0.95, 0.8, 0.5)\ncolors <- c(\"urban\" = \"#94346E\", \n            \"agricultural\" = \"#73AF48\", \n            \"semiopen\" = \"#EDAD08\", \n            \"forests\" = \"#0F8554\", \n            \"wetlands\" = \"#38A6A5\", \n            \"waterbodies\" = \"#1D6996\",\n            \"dist_urban\" = \"#94346E\", \n            \"total_rcs\" = \"#CC503E\", \n            \"dist_radar\" = \"#666666\")\nx_labels <- c(\"urban\" = \"Urban\", \n              \"agricultural\" = \"Agricultural\", \n              \"semiopen\" = \"Semi-open\", \n              \"forests\" = \"Forests\", \n              \"wetlands\" = \"Wetlands\", \n              \"waterbodies\" = \"Water bodies\", \n              \"dist_urban\" = \"Distance to fireworks (m)\", \n              \"total_rcs\" = \"Total RCS (g^(2/3))\", \n              \"dist_radar\" = \"Distance from radar (m)\")\nlimit_quantiles <- c(\"dist_urban\", \"total_rcs\")\nmanual_limits <- list(\"dist_urban\" = c(min(data_cleaned$dist_urban), quantile(data_cleaned$dist_urban, probs = 0.975)),\n                      \"total_rcs\" = c(0, quantile(data_cleaned$total_rcs, probs = 0.975)))\n# ylims <- c(-1.8, 1.5) + modelci$model$offset\nylims <- c(-1, 1)\n\nplot_mboost_pdp <- function(modelci, data, which, confints, colors = NULL, ylims = ylims, varimp = NULL, offset = FALSE) {\n  # Extract bootstrapped quantiles\n  quants <- t(mboost_bootstrapped_quantiles(modelci, confidence.intervals, which = which))\n  if (offset) quants <- quants + modelci$model$offset\n  bootstrapped_quantiles <- as.data.frame(quants)\n  # bootstrapped_quantiles <- as.data.frame(t(mboost_bootstrapped_quantiles(modelci, confidence.intervals, which = which)))\n  bootstrapped_quantiles$x <- modelci$data[modelci$model$which(which)][[1]][, 1]\n  bootstrapped_quantiles$y <- plot.mboost_adjusted(modelci$model, which = which, newdata = modelci$data[[modelci$model$which(which)]])[[2]]\n  if (offset) {\n    bootstrapped_quantiles$y <- bootstrapped_quantiles$y + modelci$model$offset\n    ylims <- ylims + modelci$model$offset\n  }\n  \n  p <- ggplot(bootstrapped_quantiles)\n  i <- 1\n  sorted_confints <- sort(confints, decreasing = TRUE)\n  \n  # Add variable importance\n  if (is.null(varimp)) {\n    variable_importance <- function(model, which, exclude = c(\"dist_radar\"), round = 0) {\n      vi <- as.data.frame(varimp(model)) %>%\n        filter(!variable %in% exclude)\n      vi$vi <- vi$reduction / sum(vi$reduction) * 100\n      vi %>%\n        filter(variable == which) %>%\n        dplyr::select(vi) %>%\n        as.numeric() %>%\n        round(round)\n    }\n    vi <- variable_importance(modelci$model, which)\n  } else {\n    vi <- varimp %>%\n      filter(variable == which) %>%\n      dplyr::select(mean_round)\n  }\n  \n  offset_right <- 0.95\n  offset_top <- 0.35\n  if (which == \"dist_urban\") {\n    p <- p +\n      annotate(\"text\", x = manual_limits$dist_urban[[2]] * offset_right, y = ylims[2] - offset_top, label = paste0(vi, \"%\"), hjust = 1, color = colors[which],\n               fontface = \"bold\", size = 12, alpha = 0.5)\n  } else if(which == \"total_rcs\") {\n    p <- p +\n      annotate(\"text\", x = manual_limits$total_rcs[[2]] * offset_right, y = ylims[2] - offset_top, label = paste0(vi, \"%\"), hjust = 1, color = colors[which],\n               fontface = \"bold\", size = 12, alpha = 0.5)\n  } else {\n    p <- p +\n      annotate(\"text\", x = 1 * offset_right, y = ylims[2] - offset_top, label = paste0(x_labels[which], \": \", vi, \"%\"), hjust = 1, color = colors[which], \n               fontface = \"bold\", size = 12, alpha = 0.5)\n  }\n  \n  # Add density\n  if (which == \"dist_urban\") {\n    dens <- density(data[, which], bw = 225, from = manual_limits$dist_urban[[1]], to = manual_limits$dist_urban[[2]])\n  } else if (which == \"total_rcs\") {\n    dens <- density(data[, which], bw = 2000, from = manual_limits$total_rcs[[1]], to = manual_limits$total_rcs[[2]])\n  } else {\n    dens <- density(data[, which], bw = 0.03556, from = 0, to = 1)\n  }\n  scale_lims <- c(ylims[1] + 0.05, ylims[2] - 0.05)\n  dens$y <- scales::rescale(dens$y, to = scale_lims)\n  dens <- as.data.frame(list(as.matrix(dens$x), as.matrix(dens$y)))\n  colnames(dens) <- c(\"x\", \"y\")\n  p <- p +\n    geom_line(aes(x = x, y = y), data =  dens, color = \"grey\", lineend = \"round\", linetype = 3) +\n    scale_y_continuous(sec.axis = sec_axis(~ ., name = \"Predictor frequency\", breaks = scale_lims, labels = c(\"min\", \"max\")))\n  \n  ## Add horizontal line\n  if (offset) {\n    yintercept <- modelci$model$offset\n  } else {\n    yintercept <- 0\n  }\n  p <- p +\n    geom_hline(yintercept = yintercept, col = \"darkgrey\")\n  \n  for (ci in sorted_confints) {\n    alphas <- rev(factor(sorted_confints))\n    ymax <- as.name(paste((1 - (1 - ci) / 2) * 100, \"%\", sep = \"\"))\n    ymax <- enquo(ymax)\n    ymin <- as.name(paste(((1 - ci) / 2) * 100, \"%\", sep = \"\"))\n    ymin <- enquo(ymin)\n    \n    p <- p +\n      geom_ribbon(aes(x = x, ymin = !!ymin, ymax = !!ymax, alpha = !!alphas[i]), fill = colors[which]) +\n      geom_line(aes(x = x, y = y), color = colors[which], size = 0.75, lineend = \"round\")\n    \n    if (offset) {\n      p <- p + scale_y_continuous(labels = function(x) {10^x})\n    }\n\n    i <- i + 1\n  }\n  \n  p <- p +\n    scale_alpha_discrete(range = c(0.2, 0.5)) +\n    coord_cartesian(ylim = ylims, expand = FALSE) +\n    guides(alpha = FALSE)\n  \n  if (which == \"dist_urban\") {\n    xlabel <- x_labels[which]\n    p <- p +\n      coord_cartesian(xlim = manual_limits$dist_urban, ylim = ylims, expand = FALSE)\n      # scale_x_continuous(breaks = c(0, 10000, 20000, 30000), labels = c(0, 10, 20, 30))\n  } else if (which == \"total_rcs\") {\n    xlabel <- x_labels[which]\n    p <- p +\n      coord_cartesian(xlim = manual_limits$total_rcs, ylim = ylims, expand = FALSE)\n      # scale_x_continuous(breaks = c(250, 500, 750), labels = c(250*4, 500*4, 750*4))\n  } else {\n    xlabel <- paste(\"% Coverage\")\n    p <- p + \n      scale_x_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1), labels = c(\"0%\", \"25%\", \"50%\", \"75%\", \"100%\"))\n  }\n  \n  p <- p +\n    theme_classic(base_size = 10) +\n    labs(x = xlabel, y = expression(paste(\"Flight response \", log[10], \"(VIR)\"))) +\n    theme(axis.line.y.left = element_line(color = colors[which], size = 0.5),\n          axis.line.y.right = element_line(color = \"grey\"),\n          axis.ticks.y.left = element_line(color = colors[which], size = 0.5),\n          axis.ticks.y.right = element_line(color = \"grey\"),\n          axis.title.y = element_text(),\n          axis.title.y.right = element_blank())\n  \n  if (!which == \"forests\") {\n    p <- p +\n      theme(axis.title.y.left = element_blank())\n  }\n  \n  if (!which == \"waterbodies\") {\n    p <- p +\n      theme(axis.title.x = element_blank())\n  }\n\n  p\n}\n\npredictors <- c(\"agricultural\", \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\")\nplots <- mapply(function(predictors) {plot_mboost_pdp(modelci, data_cleaned, which = predictors, confidence.intervals, colors, ylims, bvi_biol, \n                                                      offset = FALSE)}, \n                predictors = predictors,\n                SIMPLIFY = FALSE)\n\nsaveRDS(plots, file = \"data/plots/paper/fig_landscapes.RDS\")\n\np <- wrap_plots(plots, ncol = 1)\n\np"},{"path":"figure-2-model-output.html","id":"pseudo-rcs-distance-to-fireworks","chapter":"12 Figure 2: Model output","heading":"12.7 Pseudo-RCS & Distance to fireworks","text":"","code":"\nconfidence.intervals <- c(0.95, 0.8, 0.5)\ncolors <- c(\"urban\" = \"#94346E\", \n            \"agricultural\" = \"#73AF48\", \n            \"semiopen\" = \"#EDAD08\", \n            \"forests\" = \"#0F8554\", \n            \"wetlands\" = \"#38A6A5\", \n            \"waterbodies\" = \"#1D6996\",\n            \"dist_urban\" = \"#94346E\", \n            \"total_rcs\" = \"#CC503E\", \n            \"dist_radar\" = \"#666666\")\nx_labels <- c(\"urban\" = \"Urban\", \n              \"agricultural\" = \"Agricultural\", \n              \"semiopen\" = \"Semi-open\", \n              \"forests\" = \"Forests\", \n              \"wetlands\" = \"Wetlands\", \n              \"waterbodies\" = \"Water bodies\", \n              \"dist_urban\" = \"Distance to fireworks (m)\", \n              \"total_rcs\" = \"Total RCS (cm^2)\", \n              \"dist_radar\" = \"Distance from radar (m)\")\nlimit_quantiles <- c(\"dist_urban\", \"total_rcs\")\nmanual_limits <- list(\"dist_urban\" = c(min(data_cleaned$dist_urban), max(data_cleaned$dist_urban)),\n                      \"total_rcs\" = c(0, quantile(data_cleaned$total_rcs, probs = 0.995)))\n# ylims <- c(-1.8, 1.5) + modelci$model$offset\nylims <- c(-3, 1)\n\nplot_mboost_pdp <- function(modelci, data, which, confints, colors = NULL, ylims = ylims, varimp = NULL, offset = FALSE) {\n  # Extract bootstrapped quantiles\n  quants <- t(mboost_bootstrapped_quantiles(modelci, confidence.intervals, which = which))\n  if (offset) quants <- quants + modelci$model$offset\n  bootstrapped_quantiles <- as.data.frame(quants)\n  # bootstrapped_quantiles <- as.data.frame(t(mboost_bootstrapped_quantiles(modelci, confidence.intervals, which = which)))\n  bootstrapped_quantiles$x <- modelci$data[modelci$model$which(which)][[1]][, 1]\n  bootstrapped_quantiles$y <- plot.mboost_adjusted(modelci$model, which = which, newdata = modelci$data[[modelci$model$which(which)]])[[2]]\n  if (offset) {\n    bootstrapped_quantiles$y <- bootstrapped_quantiles$y + modelci$model$offset\n    ylims <- ylims + modelci$model$offset\n  }\n  \n  p <- ggplot(bootstrapped_quantiles)\n  i <- 1\n  sorted_confints <- sort(confints, decreasing = TRUE)\n  \n  # Add variable importance\n  if (is.null(varimp)) {\n    variable_importance <- function(model, which, exclude = c(\"dist_radar\"), round = 0) {\n      vi <- as.data.frame(varimp(model)) %>%\n        filter(!variable %in% exclude)\n      vi$vi <- vi$reduction / sum(vi$reduction) * 100\n      vi %>%\n        filter(variable == which) %>%\n        dplyr::select(vi) %>%\n        as.numeric() %>%\n        round(round)\n    }\n    vi <- variable_importance(modelci$model, which)\n  } else {\n    vi <- varimp %>%\n      filter(variable == which) %>%\n      dplyr::select(mean_round)\n  }\n  \n  offset_right <- 0.95\n  offset_top <- 0.35\n  if (which == \"dist_urban\") {\n    p <- p +\n      annotate(\"text\", x = manual_limits$dist_urban[[2]] * offset_right, y = ylims[2] - offset_top, label = paste0(vi, \"%\"), hjust = 1, color = colors[which],\n               fontface = \"bold\", size = 12, alpha = 0.5)\n  } else if(which == \"total_rcs\") {\n    p <- p +\n      annotate(\"text\", x = manual_limits$total_rcs[[2]] * offset_right, y = ylims[2] - offset_top, label = paste0(vi, \"%\"), hjust = 1, color = colors[which],\n               fontface = \"bold\", size = 12, alpha = 0.5)\n  } else {\n    p <- p +\n      annotate(\"text\", x = 1 * offset_right, y = ylims[2] - offset_top, label = paste0(x_labels[which], \": \", vi, \"%\"), hjust = 1, color = colors[which], \n               fontface = \"bold\", size = 12, alpha = 0.5)\n  }\n  \n  # Add density\n  if (which == \"dist_urban\") {\n    dens <- density(data[, which], bw = 225, from = manual_limits$dist_urban[[1]], to = manual_limits$dist_urban[[2]])\n  } else if (which == \"total_rcs\") {\n    dens <- density(data[, which], bw = 2000, from = manual_limits$total_rcs[[1]], to = manual_limits$total_rcs[[2]])\n  } else {\n    dens <- density(data[, which], bw = 0.03556, from = 0, to = 1)\n  }\n  scale_lims <- c(ylims[1] + 0.05, ylims[2] - 0.05)\n  dens$y <- scales::rescale(dens$y, to = scale_lims)\n  dens <- as.data.frame(list(as.matrix(dens$x), as.matrix(dens$y)))\n  colnames(dens) <- c(\"x\", \"y\")\n  p <- p +\n    geom_line(aes(x = x, y = y), data =  dens, color = \"grey\", lineend = \"round\", linetype = 3) +\n    scale_y_continuous(sec.axis = sec_axis(~ ., name = \"Predictor frequency\", breaks = scale_lims, labels = c(\"min\", \"max\")))\n  \n  ## Add horizontal line\n  if (offset) {\n    yintercept <- modelci$model$offset\n  } else {\n    yintercept <- 0\n  }\n  p <- p +\n    geom_hline(yintercept = yintercept, col = \"darkgrey\")\n  \n  for (ci in sorted_confints) {\n    alphas <- rev(factor(sorted_confints))\n    ymax <- as.name(paste((1 - (1 - ci) / 2) * 100, \"%\", sep = \"\"))\n    ymax <- enquo(ymax)\n    ymin <- as.name(paste(((1 - ci) / 2) * 100, \"%\", sep = \"\"))\n    ymin <- enquo(ymin)\n    \n    p <- p +\n      geom_ribbon(aes(x = x, ymin = !!ymin, ymax = !!ymax, alpha = !!alphas[i]), fill = colors[which]) +\n      geom_line(aes(x = x, y = y), color = colors[which], size = 0.75, lineend = \"round\")\n    \n    if (offset) {\n      p <- p + scale_y_continuous(labels = function(x) {10^x})\n    }\n\n    i <- i + 1\n  }\n  \n  p <- p +\n    scale_alpha_discrete(range = c(0.2, 0.5)) +\n    coord_cartesian(ylim = ylims, expand = FALSE) +\n    guides(alpha = FALSE)\n  \n  if (which == \"dist_urban\") {\n    xlabel <- x_labels[which]\n    p <- p +\n      coord_cartesian(xlim = manual_limits$dist_urban, ylim = ylims, expand = FALSE) +\n      scale_x_continuous(breaks = c(0, 5000, 10000, 15000))\n  } else if (which == \"total_rcs\") {\n    xlabel <- x_labels[which]\n    p <- p +\n      coord_cartesian(xlim = manual_limits$total_rcs, ylim = ylims, expand = FALSE)\n      # scale_x_continuous(breaks = c(250, 500, 750), labels = c(250*4, 500*4, 750*4))\n  } else {\n    xlabel <- paste(\"% Coverage\")\n    p <- p + \n      scale_x_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1), labels = c(\"0%\", \"25%\", \"50%\", \"75%\", \"100%\"))\n  }\n  \n  p <- p +\n    theme_classic(base_size = 10) +\n    labs(x = xlabel, y = expression(paste(\"Flight response \", log[10], \"(VIR)\"))) +\n    theme(axis.line.y.left = element_line(color = colors[which], size = 0.5),\n          axis.line.y.right = element_line(color = \"grey\"),\n          axis.ticks.y.left = element_line(color = colors[which], size = 0.5),\n          axis.ticks.y.right = element_line(color = \"grey\"),\n          axis.title.y = element_text(),\n          axis.title.y.right = element_blank())\n  \n  if (!which == \"forests\") {\n    p <- p +\n      theme(axis.title.y.left = element_blank())\n  }\n  \n  if (!which == \"waterbodies\") {\n    p <- p +\n      theme(axis.title.x = element_blank())\n  }\n\n  p\n}\n\npredictors <- c(\"dist_urban\", \"total_rcs\")\nplots <- mapply(function(predictors) {plot_mboost_pdp(modelci, data_cleaned, which = predictors, confidence.intervals, colors, ylims, bvi_biol, \n                                                      offset = FALSE)}, \n                predictors = predictors,\n                SIMPLIFY = FALSE)\n\nsaveRDS(plots, file = \"data/plots/paper/fig_rcs_disturban.RDS\")\n\nplots[[1]] + plots[[2]] +\nplot_layout(widths = c(1, 1), nrow = 1) & \ntheme(axis.text.x = element_text(size = 10),\n      axis.title.x = element_text(size = 12),\n      axis.text.y = element_text(size = 10)) -> plots_rcs_disturban\n\nggsave(filename = \"data/plots/paper/fig_rcs_disturban.pdf\", plot = plots_rcs_disturban, width = 14, height = 5, dpi = 300, units = \"cm\")\n\nplots_rcs_disturban"},{"path":"figure-3-species-composition.html","id":"figure-3-species-composition","chapter":"13 Figure 3: Species composition","heading":"13 Figure 3: Species composition","text":"illustrate species composition changes habitat types, make variety plots:top-5 taxonomic families per habitat type.proportions birds belong selection families representative entire Dutch landscape.quantify necessary variables rely mostly point-transect counts Sovon cover species (instead waterbird counts).","code":""},{"path":"figure-3-species-composition.html","id":"processing-environment-11","chapter":"13 Figure 3: Species composition","heading":"13.1 Processing environment","text":"load study PPI proportions taxonomic groups counts.select PPI pixels (corresponding counts) covered >99% single habitat type.","code":"\nlibrary(bioRad)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(ggpointdensity)\nlibrary(patchwork)\nlibrary(GGally)\nlibrary(tibble)\nlibrary(ggpubr)\nlibrary(forcats)\nppi <- readRDS(\"data/processed/composite-ppis/500m/201712312305.RDS\")\nwb_props <- readRDS(\"data/processed/sovon/wb_props.RDS\")\nptt <- readRDS(\"data/processed/sovon/ptt.RDS\")\nptt_props <- readRDS(\"data/processed/sovon/ptt_props.RDS\")\n\nppi$data@data %>%\n  # left_join(wb_props, by = c(\"wb_area_nr\" = \"area_nr\")) %>%\n  left_join(ptt_props, by = c(\"ptt_route\" = \"route\")) %>%\n  filter(coverage > 0,\n       class != 1,\n       total_biomass > 0,\n       dist_radar < 66000,\n       urban < 0.1) %>%\n  identity() -> data\nlanduse_limit <- 0.99"},{"path":"figure-3-species-composition.html","id":"characteristic-families","chapter":"13 Figure 3: Species composition","heading":"13.2 Characteristic families","text":"Geese, ducks, pigeons, thrushes, tits, waders, crows finches represent substantial part Dutch avifauna across large range body sizes. select illustrate taxonomic proportions change habitats.","code":"\nselected_families <- c(\"Geese\", \"Ducks\", \"Pigeons\", \"Thrushes\", \"Tits\", \"Waders\", \"Crows\", \"Finches\")\n\ndata %>%\n  dplyr::select(all_of(c(colnames(ptt_props)[3:45], \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\", \"agricultural\"))) %>%\n  pivot_longer(cols = all_of(colnames(ptt_props)[3:45]), names_to = \"family\", values_to = \"family_prop\") %>%\n  pivot_longer(cols = all_of(c(\"agricultural\", \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\")), names_to = \"landuse\", values_to = \"landuse_prop\") %>%\n  drop_na() %>%\n  filter(family %in% selected_families,\n         landuse_prop >= landuse_limit) %>%\n  group_by(family, landuse) %>%\n  summarise(mean_family_prop = mean(family_prop), .groups = \"drop_last\") %>%\n  pivot_wider(names_from = landuse, values_from = mean_family_prop) %>%\n  mutate(family_sc = case_when(family == \"Geese\" ~ \"Anatidae\",\n                               family == \"Ducks\" ~ \"Anatinae\",\n                               family == \"Pigeons\" ~ \"Columbidae\", \n                               family == \"Thrushes\" ~ \"Turdidae\",\n                               family == \"Tits\" ~ \"Paridae\",\n                               family == \"Waders\" ~ \"Charadrii\",\n                               family == \"Crows\" ~ \"Corvidae\",\n                               family == \"Finches\" ~ \"Fringillidae\")) %>%\n  identity() -> characteristic_families\ncharacteristic_families"},{"path":"figure-3-species-composition.html","id":"mean-habitat-biomass-and-weight","chapter":"13 Figure 3: Species composition","heading":"13.3 Mean habitat biomass and weight","text":"calculate mean biomass areas covered >99% single habitat type calculate mean bird weight areas point-transect counts.","code":"\ndata %>%\n  dplyr::select(all_of(c(\"total_biomass\", \"ptt_weighted_mean_weight\", \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\", \"agricultural\"))) %>%\n  pivot_longer(cols = all_of(c(\"semiopen\", \"forests\", \"wetlands\", \"waterbodies\", \"agricultural\")), names_to = \"landuse\", values_to = \"proportion\") %>%\n  filter(proportion >= landuse_limit) %>%\n  mutate(total_biomass = total_biomass / 1000) %>%\n  group_by(landuse) %>%\n  summarise(mean_biomass = mean(total_biomass),\n            mean_weight = mean(ptt_weighted_mean_weight, na.rm = TRUE),\n            .groups = \"drop_last\") %>%\n  arrange(desc(mean_weight)) %>%\n  identity() -> habitat_mass\nhabitat_mass"},{"path":"figure-3-species-composition.html","id":"sorting-of-families-by-weight","chapter":"13 Figure 3: Species composition","heading":"13.4 Sorting of families by weight","text":"Now sort families according weight","code":"\nptt %>%\n  distinct(species, .keep_all = TRUE) %>%\n  group_by(familyvernacular) %>%\n  summarise(mean_weight = mean(mean_weight), .groups = \"drop_last\") %>%\n  filter(familyvernacular %in% selected_families) %>%\n  arrange(desc(mean_weight)) %>%\n  rowid_to_column()-> family_weights\n\ncharacteristic_families %>%\n  left_join(family_weights, by = c(\"family\" = \"familyvernacular\")) %>%\n  arrange(desc(mean_weight)) -> characteristic_families\n\ncharacteristic_families$rank <- factor(characteristic_families$mean_weight, ordered = TRUE, levels = characteristic_families$mean_weight)"},{"path":"figure-3-species-composition.html","id":"prepare-plot","chapter":"13 Figure 3: Species composition","heading":"13.5 Prepare plot","text":"plot simple barplot figure.save .pdf editing Illustrator.","code":"\ncharacteristic_families %>%\n  pivot_longer(cols = !c(\"family\", \"rowid\", \"mean_weight\", \"rank\", \"family_sc\"), names_to = \"landuse\", values_to = \"family_prop\") -> cf_long\n\ncolors <- c(\"urban\" = \"#94346E\", \"agricultural\" = \"#73AF48\", \"semiopen\" = \"#EDAD08\", \"forests\" = \"#0F8554\", \"wetlands\" = \"#38A6A5\", \"waterbodies\" = \"#1D6996\",\n            \"dist_urban\" = \"#94346E\", \"total_biomass\" = \"#CC503E\", \"dist_radar\" = \"#666666\")\nlanduse_names <- c(\"agricultural\" = \"Agricultural\", \"semiopen\" = \"Semi-open\", \"forests\" = \"Forests\", \"wetlands\" = \"Wetlands\", \"waterbodies\" = \"Water bodies\")\n\nplot_family_proportions <- function(props, which) {\n  landuse_labeller <- function(variable, value) {\n    label <- paste0(landuse_names[value], \" \", round(habitat_mass[habitat_mass$landuse == which, ]$mean_weight, digits = 0), \"g\")\n    return(label)\n  }\n  \n  proportion_labeller <- function(value) paste0(value * 100, \"%\")\n  \n  props %>%\n  filter(landuse == which) %>%\n  ggplot() +\n    geom_col(aes(x = family_prop, y = reorder(family, mean_weight), alpha = family_prop), fill = colors[which]) +\n    labs(x = \"Proportion of birds\", y = \"Taxonomic group\") +\n    coord_cartesian(expand = FALSE, xlim = c(0, ceiling(max(cf_long$family_prop) * 100) / 100)) +\n    scale_x_continuous(breaks = c(0, 0.1, 0.2, 0.3), labels = proportion_labeller) +\n    scale_alpha_continuous(range = c(0.4, 1)) +\n    facet_wrap(vars(landuse), strip.position = \"top\") +\n    theme_classic(base_size = 12) +\n    theme(legend.position = \"none\",\n          axis.title.y = element_blank(),\n          strip.background = element_blank(),\n          strip.text.x = element_blank())\n}\n\nlanduses <- c(\"agricultural\", \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\")  # Same order as model outputs\n\nplots <- mapply(function(landuses) { plot_family_proportions(cf_long, landuses) }, landuses = landuses,\n            SIMPLIFY = FALSE)\n\n# characteristic_families$title <- \"Mean weight (g)\"\n# ggplot(characteristic_families) +\n#   geom_col(aes(x = mean_weight, y = reorder(family, mean_weight))) +\n#   labs(x = \"Mean weight (g)\", y = \"Taxonomic group\") +\n#     coord_cartesian(expand = FALSE) +\n#     scale_x_continuous(breaks = c(0, 1000, 2000, 3000)) +\n#     facet_wrap(vars(title), strip.position = \"top\") +\n#     theme_classic(base_size = 12) +\n#     theme(legend.position = \"none\",\n#           axis.title.y = element_blank(),\n#           strip.background = element_blank(),\n#           strip.text.x = element_text(hjust = 0, size = 12, family = \"Helvetica\", face = \"bold\")) -> plots[[6]]\np <- wrap_plots(plots, ncol = 1)\np\np_models <- readRDS(\"data/plots/paper/fig_landscapes.RDS\")\n\np_models[[1]] + p_models[[2]] + p_models[[3]] + p_models[[4]] + p_models[[5]] +\n  plots[[1]] + plots[[2]] + plots[[3]] + plots[[4]] + plots[[5]] +\n  plot_layout(widths = c(1, 1), nrow = 5, byrow = FALSE) & \n  theme(axis.text.x = element_text(size = 10),\n        axis.title.x = element_text(size = 12),\n        axis.text.y = element_text(size = 10)) -> p_landscape_characterisation\n\nggsave(filename = \"data/plots/paper/fig2_landscape.pdf\", plot = p_landscape_characterisation, width = 14, height = 25, dpi = 300, units = \"cm\")\np_landscape_characterisation\nwidths <- c(1, 1)\n(p_models[[1]] / plots[[1]] * theme(axis.text.x = element_blank(), axis.title.x = element_blank(), axis.text.y = element_text(size = 10)) +\n   plot_layout(widths = widths, ncol = 2)) /\n  (p_models[[2]] / plots[[2]] * theme(axis.text.x = element_blank(), axis.title.x = element_blank(), axis.text.y = element_text(size = 10)) +\n     plot_layout(widths = widths, ncol = 2)) /\n  (p_models[[3]] / plots[[3]] * theme(axis.text.x = element_blank(), axis.title.x = element_blank(), axis.text.y = element_text(size = 10)) +\n     plot_layout(widths = widths, ncol = 2)) /\n  (p_models[[4]] / plots[[4]] * theme(axis.text.x = element_blank(), axis.title.x = element_blank(), axis.text.y = element_text(size = 10)) +\n     plot_layout(widths = widths, ncol = 2)) / \n  (p_models[[5]] / plots[[5]] * theme(axis.text.x = element_text(size = 10), axis.title.x = element_text(size = 12), axis.text.y = element_text(size = 10)) +\n     plot_layout(widths = widths, ncol = 2)) -> p_landscape_characterisation\n\np_landscape_characterisation\nggsave(filename = \"data/plots/paper/fig2_landscape.pdf\", plot = p_landscape_characterisation, width = 12, height = 18, dpi = 300, units = \"cm\")"},{"path":"figure-4-distance-to-fireworks.html","id":"figure-4-distance-to-fireworks","chapter":"14 Figure 4: Distance to fireworks","heading":"14 Figure 4: Distance to fireworks","text":"Finally, also want visualize far away fireworks birds located. calculate raster, birds close fireworks, distances increasing discrete steps, whereas ’re away becomes continuous (possible distances grid points). makes ugly plot, stick good ol’ donutchart visualize changing distributions birds relative fireworks.","code":""},{"path":"figure-4-distance-to-fireworks.html","id":"processing-environment-12","chapter":"14 Figure 4: Distance to fireworks","heading":"14.1 Processing environment","text":"","code":"\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(ggpubr)\nlibrary(forcats)\nlibrary(stringr)\nlibrary(broom)\nlibrary(patchwork)\nlibrary(ggridges)\nlibrary(ggpointdensity)\ndata_cleaned <- readRDS(\"data/models/data_cleaned.RDS\")\nbaseline_ppis <- readRDS(\"data/processed/baseline_ppis.RDS\")\nbaseline_all <- bind_rows(baseline_ppis)\n\ndata_all <- readRDS(\"data/processed/composite-ppis/500m/201712312305.RDS\")$data@data %>%\n  dplyr::select(\"pixel\", \"wb_area_nr\", \"ptt_route\", \"wb_total_birds\", \"ptt_total_birds\", \"total_birds\", \"weighted_mean_crs\") %>%\n  rename(mean_rcs = weighted_mean_crs)\n\ndata_cleaned %>%\n  left_join(data_all, by = \"pixel\") -> data_cleaned\n\nwb_props <- readRDS(\"data/processed/sovon/wb_props.RDS\") %>%\n  dplyr::select(\"area_nr\", \"Geese\", \"Ducks\", \"Crows\", \"Pigeons\", \"Waders\", \"Thrushes\", \"Finches\", \"Tits\")\n\nptt_props <- readRDS(\"data/processed/sovon/ptt_props.RDS\") %>%\n  dplyr::select(\"route\", \"Geese\", \"Ducks\", \"Crows\", \"Pigeons\", \"Waders\", \"Thrushes\", \"Finches\", \"Tits\")\n\ndata_cleaned %>%\n  left_join(wb_props, by = c(\"wb_area_nr\" = \"area_nr\")) %>%\n  left_join(ptt_props, by = c(\"ptt_route\" = \"route\")) %>%\n  rowwise() %>%\n  mutate(Geese = mean(c(Geese.x, Geese.y), na.rm = TRUE),\n         Ducks = mean(c(Ducks.x, Ducks.y), na.rm = TRUE),\n         Crows = mean(c(Crows.x, Crows.y), na.rm = TRUE),\n         Pigeons = mean(c(Pigeons.x, Pigeons.y), na.rm = TRUE),\n         Waders = mean(c(Waders.x, Waders.y), na.rm = TRUE),\n         Thrushes = mean(c(Thrushes.x, Thrushes.y), na.rm = TRUE),\n         Finches = mean(c(Finches.x, Finches.y), na.rm = TRUE),\n         Tits = mean(c(Tits.x, Tits.y), na.rm = TRUE)) %>%\n  ungroup() %>%\n  mutate(VIDc = (10^VIR) / mean_rcs,\n         VIDc = if_else(VIDc > 10000000, 1e-6, VIDc, 1e-6)) %>%\n  dplyr::select(-c(\"Geese.x\", \"Geese.y\", \"Ducks.x\", \"Ducks.y\", \"Crows.x\", \"Crows.y\", \"Pigeons.x\", \"Pigeons.y\",\n                   \"Waders.x\", \"Waders.y\", \"Thrushes.x\", \"Thrushes.y\", \"Finches.x\", \"Finches.y\", \"Tits.x\", \"Tits.y\")) -> data_cleaned\n\nprop_classes <- c(\"Geese\", \"Ducks\", \"Crows\", \"Pigeons\", \"Waders\", \"Thrushes\", \"Finches\", \"Tits\")\ndata_cleaned[\"domprop\"] <- names(data_cleaned)[which(names(data_cleaned) %in% prop_classes)][max.col(data_cleaned[prop_classes], \"first\")]\n\nlanduse_classes <- c(\"agricultural\", \"semiopen\", \"forests\", \"wetlands\", \"waterbodies\")\ndata_cleaned[\"domclass\"] <- names(data_cleaned)[which(names(data_cleaned) %in% landuse_classes)][max.col(data_cleaned[landuse_classes], \"first\")]\n\ndata_cleaned$VIR[data_cleaned$VIR < -1] <- -1\n\nbaseline_all %>%\n  mutate(VIR = 10^VIR,\n         prop_flight = VIR / total_rcs,\n         VIR = log10(VIR)) %>%\n  identity() -> baseline_all\nreadRDS(\"data/processed/sovon/ptt_props.RDS\") %>%\n  dplyr::select(total_birds, route) %>%\n  filter(total_birds > 0) %>%\n  left_join(dplyr::select(data_cleaned, ptt_route, dist_urban), by = c(\"route\" = \"ptt_route\")) %>%\n  drop_na() %>%\n  distinct(route, total_birds, dist_urban, .keep_all = TRUE) %>%\n  uncount(total_birds) %>%\n  # slice_sample(n = 2000000) %>%\n  mutate(family = \"All\") %>%\n  dplyr::select(family, dist_urban) %>%\n  identity() -> ptt_all\n\nreadRDS(\"data/processed/sovon/wb_props.RDS\") %>%\n  dplyr::select(total_birds, area_nr) %>%\n  filter(total_birds > 0) %>%\n  left_join(dplyr::select(data_cleaned, wb_area_nr, dist_urban), by = c(\"area_nr\" = \"wb_area_nr\")) %>%\n  drop_na() %>%\n  distinct(area_nr, total_birds, dist_urban, .keep_all = TRUE) %>%\n  uncount(total_birds) %>%\n  # slice_sample(n = 2000000) %>%\n  mutate(family = \"All\") %>%\n  dplyr::select(family, dist_urban) %>%\n  identity() -> wb_all\n\nwb_all %>%\n  bind_rows(ptt_all) -> all\na <- ecdf(all$dist_urban)\na(2500)## [1] 0.6208102\na(5000)## [1] 0.8943964\nprop_classes <- c(\"Geese\", \"Ducks\", \"Crows\", \"Pigeons\", \"Shorebirds\", \"Thrushes\", \"Finches\", \"Tits\", \"All\")\nwb <- readRDS(\"data/processed/sovon/wb_props.RDS\") %>%\n  dplyr::select(total_birds, area_nr, Geese, Ducks, Crows, Pigeons, Shorebirds = Waders, Thrushes, Finches, Tits) %>%\n  pivot_longer(cols = Geese:Tits, names_to = \"family\", values_to = \"prop_family\") %>%\n  mutate(birds = round(total_birds * prop_family),\n         family = fct_relevel(as.factor(family), rev(prop_classes))) %>%\n  filter(birds > 0) %>%\n  left_join(dplyr::select(data_cleaned, wb_area_nr, dist_urban), by = c(\"area_nr\" = \"wb_area_nr\")) %>%\n  drop_na() %>%\n  distinct(area_nr, family, dist_urban, .keep_all = TRUE) %>%\n  uncount(birds) %>%\n  slice_sample(n = 1000000) %>%\n  dplyr::select(family, dist_urban) %>%\n  identity()## Warning: Unknown levels in `f`: All\nptt <- readRDS(\"data/processed/sovon/ptt_props.RDS\") %>%\n  dplyr::select(total_birds, route, Geese, Ducks, Crows, Pigeons, Shorebirds = Waders, Thrushes, Finches, Tits) %>%\n  pivot_longer(cols = Geese:Tits, names_to = \"family\", values_to = \"prop_family\") %>%\n  mutate(birds = round(total_birds * prop_family),\n         family = fct_relevel(as.factor(family), rev(prop_classes))) %>%\n  filter(birds > 0) %>%\n  left_join(dplyr::select(data_cleaned, ptt_route, dist_urban), by = c(\"route\" = \"ptt_route\")) %>%\n  drop_na() %>%\n  distinct(route, family, dist_urban, .keep_all = TRUE) %>%\n  uncount(birds) %>%\n  slice_sample(n = 1000000) %>%\n  dplyr::select(family, dist_urban) %>%\n  identity()## Warning: Unknown levels in `f`: All\nwb %>%\n  bind_rows(ptt) %>%\n  mutate(family = fct_relevel(as.factor(family), rev(prop_classes))) %>%\n  ggplot() +\n  geom_density_ridges(aes(x = dist_urban, y = family, fill = family), scale = 2.5, bandwidth = 275, rel_min_height = 0.005, color = \"#ffffff\", quantile_lines = TRUE, quantiles = 4) +\n  scale_x_continuous(limits = c(0, max(data_cleaned$dist_urban)), breaks = c(0, 5000, 10000, 15000)) +\n  scale_y_discrete(position = \"left\") +\n  scale_fill_cyclical(values = c(\"#E17C05\", \"#CC503E\")) +\n  coord_cartesian(expand = FALSE) +\n  theme_classic(base_size = 10) +\n  theme(legend.position = \"none\") +\n  labs(x = \"Distance to fireworks [m]\", y = \"Rel. occurrence\") %>%\n  identity() -> p_bird_families## Warning: Unknown levels in `f`: All\np_bird_families\ndata_cleaned %>%\n  dplyr::select(agricultural:urban, domclass, dist_urban) %>%\n  pivot_longer(cols = -c(domclass, dist_urban)) %>%\n  filter(domclass == name) %>%\n  ggplot(aes(x = dist_urban, y = fct_reorder(domclass, dist_urban, .fun = median, .desc = TRUE),\n             fill = domclass)) +\n  # geom_stream() +\n  geom_density_ridges(scale = 4, rel_min_height = .005, color = \"#ffffff\", quantile_lines = TRUE, quantiles = 4) +\n  scale_fill_manual(values = c(\"#73AF48\", \"#0F8554\", \"#EDAD08\", \"#1D6996\", \"#38A6A5\")) +\n  scale_color_manual(values = c(\"#73AF48\", \"#0F8554\", \"#EDAD08\", \"#1D6996\", \"#38A6A5\")) +\n  scale_x_continuous(limits = c(0, max(data_cleaned$dist_urban)), breaks = c(0, 5000, 10000, 15000)) +\n  scale_y_discrete(position = \"left\", labels = function(x) stringr::str_to_sentence(x)) +\n  coord_cartesian(expand = FALSE) +\n  theme_classic(base_size = 10) +\n  theme(legend.position = \"none\") + \n  labs(x = \"Distance to fireworks [m]\", y = \"Rel. occurrence\") -> p_landuse\n\np_landuse## Picking joint bandwidth of 389\ndisturbance_baseline <- readRDS(\"data/processed/disturbance_baseline.RDS\")\n\nmin_VID <- 0.01\n\nbppi <- lapply(baseline_ppis, function(x) {\n  x %>%\n    # mutate(VIDc = if_else(VIDc < min_VID, min_VID, VIDc, min_VID)) %>%\n    identity()\n})\n\nset.seed(42)\n\ndb <- bind_rows(bppi)\n\ndisturbance_baseline <- mean(bind_rows(bppi)$VIDc, trim = 0.05)\n\nalpha_baseline <- 0.5\nalpha_ribbon <- 0.3\n\ncolor_normal <- \"blue\"\ncolor_disturbed <- \"red\"\n\nscientific_10 <- function(x) {\n  parse(text = str_replace(gsub(\"e\", \" %*% 10^\", scales::scientific_format()(x)), \"\\\\+\", \"\"))\n}\n\ndata_cleaned %>%\n  # mutate(VIDc = if_else(VIDc < min_VID, min_VID, VIDc, min_VID)) %>%\n  identity() %>%\n  ggplot() +\n  # geom_pointdensity(aes(x = dist_urban, y = VIDc, size = total_rcs), alpha = 0.05, adjust = 2.5, method = \"default\") +\n  geom_point(aes(x = dist_urban, y = VIDc), data = . %>% sample_frac(1/5), alpha = 0.05, color = color_disturbed) +\n  # geom_pointdensity(aes(x = dist_urban, y = VIR, size = total_rcs), alpha = 0.05) +\n  # geom_point(aes(x = dist_urban, y = VIR, size = total_rcs), color = \"gray80\", shape = 20, alpha = 0.2,\n  #            data = data_cleaned %>% slice_sample(n = 10000)) +\n  # geom_point(aes(x = dist_urban, y = VIR, size = total_rcs), color = \"indianred2\", alpha = 0.05,\n  #            data = data_cleaned %>% slice_sample(n = 10000)) +\n  # stat_density_2d(aes(x = dist_urban, y = VIR, color = after_stat(density)), geom = \"point\",\n  #                 contour = FALSE, data = data_cleaned, n = 100) +\n  # geom_density_2d(aes(x = dist_urban, y = VIR, color = domclass), data = data_cleaned) +\n  # geom_density_2d_filled(aes(x = dist_urban, y = VIR), data = data_cleaned) +\n  \n  # Horizontal lines\n  # geom_hline(yintercept = disturbance_baseline, color = \"blue\", linetype = \"dashed\") +\n  # geom_hline(yintercept = mean(data_cleaned$VIDc, trim = 0.25), color = \"red\", linetype = \"dashed\") +\n  # Smooths Undisturbed\n  geom_point(aes(x = dist_urban, y = VIDc), data = db %>% dplyr::sample_frac(1/(5*length(bppi))), \n             color = color_normal, alpha = 0.05) +\n  geom_ribbon(aes(x = dist_urban, y = VIDc), data = bppi[[1]], method = \"gam\", stat = \"smooth\",\n              fill = color_normal, alpha = alpha_ribbon, color = \"white\", size = 0.2) +\n  geom_line(aes(x = dist_urban, y = VIDc), data = bppi[[1]], method = \"gam\", stat = \"smooth\", color = color_normal, \n            alpha = 1) +\n  geom_ribbon(aes(x = dist_urban, y = VIDc), data = bppi[[2]], method = \"gam\", stat = \"smooth\",\n              fill = color_normal, alpha = alpha_ribbon, color = \"white\", size = 0.2) +\n  geom_line(aes(x = dist_urban, y = VIDc), data = bppi[[2]], method = \"gam\", stat = \"smooth\", color = color_normal, \n            alpha = 1) +\n  geom_ribbon(aes(x = dist_urban, y = VIDc), data = bppi[[3]], method = \"gam\", stat = \"smooth\",\n              fill = color_normal, alpha = alpha_ribbon, color = \"white\", size = 0.2) +\n  geom_line(aes(x = dist_urban, y = VIDc), data = bppi[[3]], method = \"gam\", stat = \"smooth\", color = color_normal, \n            alpha = 1) +\n  geom_ribbon(aes(x = dist_urban, y = VIDc), data = bppi[[4]], method = \"gam\", stat = \"smooth\",\n              fill = color_normal, alpha = alpha_ribbon, color = \"white\", size = 0.2) +\n  geom_line(aes(x = dist_urban, y = VIDc), data = bppi[[4]], method = \"gam\", stat = \"smooth\", color = color_normal, \n            alpha = 1) +\n  geom_ribbon(aes(x = dist_urban, y = VIDc), data = bppi[[5]], method = \"gam\", stat = \"smooth\",\n              fill = color_normal, alpha = alpha_ribbon, color = \"white\", size = 0.2) +\n  geom_line(aes(x = dist_urban, y = VIDc), data = bppi[[5]], method = \"gam\", stat = \"smooth\", color = color_normal, \n            alpha = 1) +\n  # annotate(\"text\", x = 14500, y = disturbance_baseline - 0.4, label = \"Normal nights\", hjust = 1, color = \"blue\", fontface = \"bold\") +\n  # Smooths disturbed\n  geom_ribbon(aes(x = dist_urban, y = VIDc), method = \"gam\", stat = \"smooth\", fill = color_disturbed, alpha = 0.2, \n              color = \"white\", size = 0.4) +\n  geom_line(aes(x = dist_urban, y = VIDc), method = \"gam\", stat = \"smooth\", color = color_disturbed, alpha = 1) +\n  # annotate(\"text\", x = 15500, y = mean(data_cleaned$VIDc) + 0.4, label = \"NYE\", hjust = 1, color = \"red\", fontface = \"bold\") +\n  scale_color_viridis_c(option = \"inferno\") +\n  scale_y_continuous(trans = \"log10\", breaks = c(0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000), \n                     labels = c(\"0.0001\", \"0.001\", \"0.01\", \"0.1\", \"1\", \"10\", \"100\", \"1000\", \"10000\")) +\n  # scale_y_continuous(trans = scales::pseudo_log_trans(base = 10), labels = function(x) {10^x}, breaks = c(-1, 0, 1, 2, 3, 4, 5, 6)) +\n  # scale_y_continuous(labels = function(x) {10^x}, breaks = c(-1, 0, 1, 2, 3, 4, 5, 6)) +\n  scale_x_continuous(breaks = c(0, 5000, 10000, 15000), labels = c(0, 5000, 10000, 15000), expand = c(0, 0), limits = c(0, NA)) +\n  # scale_size_continuous(breaks = c(10, 100, 1000, 10000, 100000), labels = scientific_10) +\n  scale_size_continuous(breaks = c(100, 10000, 100000), labels = scales::label_number()) +\n  theme_classic(base_size = 10) +\n  # labs(x = \"Distance to residential area [m]\", y = expression(~Birds~\"in\"~flight~~\"[individuals\"~km^{-2}~\"]\")) +\n  labs(x = \"Distance to fireworks [m]\", y = expression(\"Birds in flight\"~~group(\"[\", individuals~km^{-2}, \"]\"))) +\n  guides(color = guide_colorbar(\"Density\"),\n         size = guide_legend(title = expression(Total~RCS~~group(\"[\", cm^2, \"]\")))) +\n  coord_cartesian(ylim = c(0.90e-4, 1e4)) +\n  theme(legend.position = \"right\") -> p_response\n\np_response## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n(p_landuse / p_response / p_bird_families +\n  plot_layout(heights = c(1.5, 2.5, 1.5), guides = \"collect\"))## Picking joint bandwidth of 389## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\nggsave(\"data/plots/distance_effect_absolute.pdf\", width = 7, height = 7)## Picking joint bandwidth of 389\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n(p_landuse / p_bird_families / p_response  +\n  plot_layout(heights = c(1.5, 1.5, 2.5), guides = \"collect\"))## Picking joint bandwidth of 389## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\nggsave(filename = \"data/plots/paper/distance_effect_nrbirds.pdf\", width = 11.4, height = 17, dpi = 300, units = \"cm\")## Picking joint bandwidth of 389\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n## `geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'"},{"path":"context-1-number-of-birds-affected.html","id":"context-1-number-of-birds-affected","chapter":"15 Context 1: Number of birds affected","heading":"15 Context 1: Number of birds affected","text":"can use RCS estimates calculated previously generate rough estimate number birds affected fireworks disturbance.","code":""},{"path":"context-1-number-of-birds-affected.html","id":"processing-environment-13","chapter":"15 Context 1: Number of birds affected","heading":"15.1 Processing environment","text":"First load PPIs timestamp selected scan.create composite PPI filter pixels outside 66km radar.can now calculate total VIR within radar domain number birds corresponds given RCS values:","code":"\nlibrary(bioRad)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(stringr)\nselected_scan <- load(\"data/processed/pvol_selection.RData\")\nscan_dt <- str_extract(basename(pvol_dhl_path), \"[0-9]{12}\")\nscan_dhl <- file.path(\"data/processed/final-ppis\", paste0(\"RAD_NL61_VOL_NA_\", scan_dt, \"_ODIM.RDS\"))\nscan_hrw <- file.path(\"data/processed/final-ppis\", paste0(\"RAD_NL62_VOL_NA_\", scan_dt, \"_ODIM.RDS\"))\nppis_original <- lapply(list(scan_dhl, scan_hrw), function(x) readRDS(x))\nsource(\"R/comp_ppi.R\")\nppis <- ppis_original\nmaxrange <- 66000\n# Set all columns to NA if further than maxrange from radar\nppis[[1]]$data$VIR[ppis[[1]]$data$dist_radar > maxrange] <- NA\nppis[[1]]$data$land[ppis[[1]]$data$dist_radar > maxrange] <- NA\nppis[[2]]$data$VIR[ppis[[2]]$data$dist_radar > maxrange] <- NA\nppis[[2]]$data$land[ppis[[2]]$data$dist_radar > maxrange] <- NA\n\ncppi <- comp_ppi(ppis, param = c(\"VIR\", \"land\"), method = c(\"max\", \"min\"), res = c(500, 500), )## Warning in showSRID(uprojargs, format = \"PROJ\", multiline = \"NO\", prefer_proj\n## = prefer_proj): Discarded datum Unknown based on WGS84 ellipsoid in Proj4\n## definition\n\n## Warning in showSRID(uprojargs, format = \"PROJ\", multiline = \"NO\", prefer_proj\n## = prefer_proj): Discarded datum Unknown based on WGS84 ellipsoid in Proj4\n## definition\n\n## Warning in showSRID(uprojargs, format = \"PROJ\", multiline = \"NO\", prefer_proj\n## = prefer_proj): Discarded datum Unknown based on WGS84 ellipsoid in Proj4\n## definition\n\n## Warning in showSRID(uprojargs, format = \"PROJ\", multiline = \"NO\", prefer_proj\n## = prefer_proj): Discarded datum Unknown based on WGS84 ellipsoid in Proj4\n## definition\n\n## Warning in showSRID(uprojargs, format = \"PROJ\", multiline = \"NO\", prefer_proj\n## = prefer_proj): Discarded datum Unknown based on WGS84 ellipsoid in Proj4\n## definition\ncppi$data$VIR[cppi$data$land == 0] <- NA\nplot(cppi)\nptt_biomass <- readRDS(\"data/processed/sovon/ptt_biomass.RDS\")\ntotal_vir <- sum(cppi$data$VIR, na.rm = TRUE) * 1/4  # Convert to sum of VIR/0.5km2\npaste0(\"Total VIR: \", format(total_vir, scientific = TRUE))\npaste0(\"Response assuming mean RCS of \", round(mean(ptt_biomass$weighted_mean_crs)), \" cm^2: \", \n       round(total_vir / mean(ptt_biomass$weighted_mean_crs)), \" birds.\")\npaste0(\"Response assuming median RCS of \", round(median(ptt_biomass$weighted_mean_crs)), \" cm^2: \", \n       round(total_vir / median(ptt_biomass$weighted_mean_crs)), \" birds.\")\npaste0(\"Response assuming mean RCS of 11 cm^2: \", round(total_vir / 11), \" birds.\")## [1] \"Total VIR: 3.314054e+07\"\n## [1] \"Response assuming mean RCS of 86 cm^2: 383404 birds.\"\n## [1] \"Response assuming median RCS of 82 cm^2: 406339 birds.\"\n## [1] \"Response assuming mean RCS of 11 cm^2: 3012776 birds.\""},{"path":"generating-vps-for-den-helder-radar.html","id":"generating-vps-for-den-helder-radar","chapter":"16 Generating vertical profiles for Den Helder radar","heading":"16 Generating vertical profiles for Den Helder radar","text":"Den Helder radar situated close coast, take-densities derived calculate_vp() function bioRad (Dokter et al. 2019) likely underestimated large swaths sea (North Wadden Sea) contained within volume. correct , select section, defined minimum maximum azimuths, generate vertical profiles .load DBZH polar volume containing peak moment take-Den Helder radar, occurs 23:05 UTC.illustrate problem, let’s plot lowest scan pvol loaded:can seen, large swath sea clutter, roughly azimuths 200 325. Wadden Sea can seen azimuths 45 roughly 90. area majority birds take : mainland North Holland. can visualise focus area cover plotting PPI values azimuths 90 200 set high value. See :Now mind can calculate vps entire area compare one calculated just section (azimuths 90 200).plot corresponding VPs:can see substantial difference density derived VPs focussing main land North Holland vs. look entire radar domain include large swaths North Wadden Sea.","code":"\nlibrary(bioRad)## Welcome to bioRad version 0.5.2## Docker daemon running, Docker functionality enabled (vol2bird version 0.5.0.9169)\npvol_path <- \"data/raw/pvol/fireworks-2017-2018/RAD_NL61_VOL_NA_201712312305_ODIM.h5\"\n\npvol <- read_pvolfile(pvol_path, param = \"DBZH\")\nscan <- get_scan(pvol, 0.3)\nplot(scan)\nscan_section <- scan\nscan_section$params$DBZH[, 90:200] <- 100\n\nppi <- project_as_ppi(scan, grid_size = 100, range_max = 35000)\nppi_section <- project_as_ppi(scan_section, grid_size = 100, range_max = 35000)\n\npar(pty = \"s\", mfrow = c(1, 2))\nplot(ppi)\nplot(ppi_section)\nvp_all_azimuths = calculate_vp(pvol_path, verbose = FALSE)\nvp_land_based_azimuths = calculate_vp(pvol_path, azim_min = 90, azim_max = 200, verbose = FALSE)\nplot(vp_all_azimuths, main = \"VP calculated from the entire Den Helder radar domain\")\nplot(vp_land_based_azimuths, main = \"VP calculated from the main land area covered by Den Helder radar\")"},{"path":"references.html","id":"references","chapter":"17 References","heading":"17 References","text":"","code":""}]
